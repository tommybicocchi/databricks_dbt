[0m18:50:29.476314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E4144E140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E42D7E500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E42D7E290>]}


============================== 18:50:29.483312 | 860c018a-1cd5-4fd9-be31-b4c6c2b76c39 ==============================
[0m18:50:29.483312 [info ] [MainThread]: Running with dbt=1.9.2
[0m18:50:29.484310 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\tbicocch\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt init dbt_databricks_capgemini_I', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:50:29.511314 [debug] [MainThread]: Starter project path: C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\include\starter_project
[0m18:50:29.551816 [info ] [MainThread]: 
Your new dbt project "dbt_databricks_capgemini_I" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m18:50:29.552815 [info ] [MainThread]: Setting up your profile.
[0m18:50:37.098213 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:50:37.099213 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:50:37.099213 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:02:14.108878 [info ] [MainThread]: Profile dbt_databricks_capgemini_I written to C:\Users\tbicocch\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m19:02:14.110895 [debug] [MainThread]: Command `dbt init` succeeded at 19:02:14.110895 after 704.95 seconds
[0m19:02:14.111893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E4144E140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E42D7F250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E42D7E3B0>]}
[0m19:02:14.112895 [debug] [MainThread]: Flushing usage events
[0m19:02:14.676588 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:02:55.377000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B99D4E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B9B67E590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B9B67E320>]}


============================== 19:02:55.381944 | 8f7886f9-336b-41be-95c0-4375a535e807 ==============================
[0m19:02:55.381944 [info ] [MainThread]: Running with dbt=1.9.2
[0m19:02:55.382941 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\tbicocch\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:02:55.412150 [info ] [MainThread]: dbt version: 1.9.2
[0m19:02:55.414153 [info ] [MainThread]: python version: 3.10.11
[0m19:02:55.415147 [info ] [MainThread]: python path: C:\Users\tbicocch\DbtDatabricks\env\Scripts\python.exe
[0m19:02:55.415147 [info ] [MainThread]: os info: Windows-10-10.0.22631-SP0
[0m19:02:56.087271 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:02:56.087271 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:02:56.088266 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:02:56.949677 [info ] [MainThread]: Using profiles dir at C:\Users\tbicocch\.dbt
[0m19:02:56.950232 [info ] [MainThread]: Using profiles.yml file at C:\Users\tbicocch\.dbt\profiles.yml
[0m19:02:56.951256 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\tbicocch\DbtDatabricks\dbt_project.yml
[0m19:02:56.952245 [info ] [MainThread]: adapter type: databricks
[0m19:02:56.952245 [info ] [MainThread]: adapter version: 1.9.5
[0m19:02:56.953244 [info ] [MainThread]: Configuration:
[0m19:02:56.953244 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m19:02:56.954247 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m19:02:56.955244 [info ] [MainThread]: Required dependencies:
[0m19:02:56.955244 [debug] [MainThread]: Executing "git --help"
[0m19:02:57.118387 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:02:57.119395 [debug] [MainThread]: STDERR: "b''"
[0m19:02:57.119395 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m19:02:57.120395 [info ] [MainThread]: Connection:
[0m19:02:57.121401 [info ] [MainThread]:   host: dbc-200ae55c-a8b7.cloud.databricks.com
[0m19:02:57.121401 [info ] [MainThread]:   http_path: /sql/warehouses/44b4e39b1cbff1ff?o=4465281864151379
[0m19:02:57.122399 [info ] [MainThread]:   catalog: workspace
[0m19:02:57.122937 [info ] [MainThread]:   schema: default
[0m19:02:57.123951 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m19:02:57.520940 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2249308519728, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(24096, 31632), compute-name=) - Creating connection
[0m19:02:57.521952 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m19:02:57.521952 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2249308519728, session-id=None, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(24096, 31632), compute-name=) - Acquired connection on thread (24096, 31632), using default compute resource
[0m19:02:57.521952 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2249308519728, session-id=None, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(24096, 31632), compute-name=) - Checking idleness
[0m19:02:57.522942 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2249308519728, session-id=None, name=debug, idle-time=0.0009903907775878906s, acquire-count=1, language=None, thread-identifier=(24096, 31632), compute-name=) - Retrieving connection
[0m19:02:57.522942 [debug] [MainThread]: Using databricks connection "debug"
[0m19:02:57.523940 [debug] [MainThread]: On debug: select 1 as id
[0m19:02:57.523940 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:04:12.904605 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2249308519728, session-id=None, name=debug, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(24096, 31632), compute-name=) - Released connection
[0m19:04:12.905610 [error] [MainThread]: Encountered an error:

[0m19:04:13.013156 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\main.py", line 414, in debug
    results = task.run()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\debug.py", line 144, in run
    connection_status = self.test_connection()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\debug.py", line 465, in test_connection
    connection_result = self.attempt_connection(self.profile)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\debug.py", line 443, in attempt_connection
    adapter.debug_query()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\spark\impl.py", line 517, in debug_query
    self.execute("select 1 as id")
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\impl.py", line 289, in execute
    return super().execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\base\impl.py", line 404, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 314, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 287, in add_query
    handle: DatabricksHandle = connection.handle
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\contracts\connection.py", line 96, in handle
    self._handle.resolve(self)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\contracts\connection.py", line 120, in resolve
    return self.opener(connection)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 450, in open
    return cls.retry_connection(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\base\connections.py", line 237, in retry_connection
    connection.handle = connect()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 428, in connect
    conn = DatabricksHandle.from_connection_args(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\handle.py", line 211, in from_connection_args
    conn = dbsql.connect(**conn_args)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\__init__.py", line 90, in connect
    return Connection(server_hostname, http_path, access_token, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\client.py", line 255, in __init__
    self._open_session_resp = self.thrift_backend.open_session(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_backend.py", line 554, in open_session
    response = self.make_request(self._client.OpenSession, open_session_req)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_backend.py", line 471, in make_request
    response_or_error_info = attempt_request(attempt)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_backend.py", line 381, in attempt_request
    response = method(request)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_api\TCLIService\TCLIService.py", line 204, in OpenSession
    self.send_OpenSession(req)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_api\TCLIService\TCLIService.py", line 213, in send_OpenSession
    self._oprot.trans.flush()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\auth\thrift_http_client.py", line 186, in flush
    self.__resp = self.__pool.request(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\_request_methods.py", line 143, in request
    return self.request_encode_body(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\connectionpool.py", line 942, in urlopen
    return self.urlopen(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\connectionpool.py", line 940, in urlopen
    retries.sleep(response)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\util\retry.py", line 359, in sleep
    slept = self.sleep_for_retry(response)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\auth\retry.py", line 296, in sleep_for_retry
    time.sleep(proposed_wait)
KeyboardInterrupt

[0m19:04:13.017165 [debug] [MainThread]: Command `dbt debug` failed at 19:04:13.017165 after 77.82 seconds
[0m19:04:13.018166 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m19:04:13.018166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020B99D4E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BB59CA6B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020BB59CA020>]}
[0m19:04:13.019165 [debug] [MainThread]: Flushing usage events
[0m19:04:13.537396 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:08:57.008558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262C5C4E1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262C757E590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262C757E3B0>]}


============================== 19:08:57.014378 | 7e1dfeac-7868-4dd9-aaef-73c5ac761a83 ==============================
[0m19:08:57.014378 [info ] [MainThread]: Running with dbt=1.9.2
[0m19:08:57.015380 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\tbicocch\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m19:08:57.042706 [info ] [MainThread]: dbt version: 1.9.2
[0m19:08:57.043706 [info ] [MainThread]: python version: 3.10.11
[0m19:08:57.045707 [info ] [MainThread]: python path: C:\Users\tbicocch\DbtDatabricks\env\Scripts\python.exe
[0m19:08:57.046705 [info ] [MainThread]: os info: Windows-10-10.0.22631-SP0
[0m19:08:57.728119 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:08:57.728119 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:08:57.729120 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:08:58.749774 [info ] [MainThread]: Using profiles dir at C:\Users\tbicocch\.dbt
[0m19:08:58.751777 [info ] [MainThread]: Using profiles.yml file at C:\Users\tbicocch\.dbt\profiles.yml
[0m19:08:58.752112 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\tbicocch\DbtDatabricks\dbt_project.yml
[0m19:08:58.753143 [info ] [MainThread]: adapter type: databricks
[0m19:08:58.753143 [info ] [MainThread]: adapter version: 1.9.5
[0m19:08:58.754128 [info ] [MainThread]: Configuration:
[0m19:08:58.754128 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m19:08:58.755124 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m19:08:58.756124 [info ] [MainThread]: Required dependencies:
[0m19:08:58.756124 [debug] [MainThread]: Executing "git --help"
[0m19:08:58.905154 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:08:58.907160 [debug] [MainThread]: STDERR: "b''"
[0m19:08:58.908157 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m19:08:58.910154 [info ] [MainThread]: Connection:
[0m19:08:58.911155 [info ] [MainThread]:   host: dbc-200ae55c-a8b7.cloud.databricks.com
[0m19:08:58.911155 [info ] [MainThread]:   http_path: /sql/warehouses/44b4e39b1cbff1ff?o=4465281864151379
[0m19:08:58.912156 [info ] [MainThread]:   catalog: workspace
[0m19:08:58.913154 [info ] [MainThread]:   schema: default
[0m19:08:58.914154 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m19:08:59.310809 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623708757296, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(11516, 33668), compute-name=) - Creating connection
[0m19:08:59.311810 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m19:08:59.312815 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623708757296, session-id=None, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(11516, 33668), compute-name=) - Acquired connection on thread (11516, 33668), using default compute resource
[0m19:08:59.312815 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623708757296, session-id=None, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(11516, 33668), compute-name=) - Checking idleness
[0m19:08:59.313810 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623708757296, session-id=None, name=debug, idle-time=0.0009949207305908203s, acquire-count=1, language=None, thread-identifier=(11516, 33668), compute-name=) - Retrieving connection
[0m19:08:59.313810 [debug] [MainThread]: Using databricks connection "debug"
[0m19:08:59.314813 [debug] [MainThread]: On debug: select 1 as id
[0m19:08:59.314813 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:10:43.738153 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2623708757296, session-id=None, name=debug, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(11516, 33668), compute-name=) - Released connection
[0m19:10:43.740154 [error] [MainThread]: Encountered an error:

[0m19:10:43.767958 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\main.py", line 414, in debug
    results = task.run()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\debug.py", line 144, in run
    connection_status = self.test_connection()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\debug.py", line 465, in test_connection
    connection_result = self.attempt_connection(self.profile)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\debug.py", line 443, in attempt_connection
    adapter.debug_query()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\spark\impl.py", line 517, in debug_query
    self.execute("select 1 as id")
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\impl.py", line 289, in execute
    return super().execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\base\impl.py", line 404, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 314, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 287, in add_query
    handle: DatabricksHandle = connection.handle
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\contracts\connection.py", line 96, in handle
    self._handle.resolve(self)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\contracts\connection.py", line 120, in resolve
    return self.opener(connection)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 450, in open
    return cls.retry_connection(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\base\connections.py", line 237, in retry_connection
    connection.handle = connect()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 428, in connect
    conn = DatabricksHandle.from_connection_args(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\handle.py", line 211, in from_connection_args
    conn = dbsql.connect(**conn_args)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\__init__.py", line 90, in connect
    return Connection(server_hostname, http_path, access_token, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\client.py", line 255, in __init__
    self._open_session_resp = self.thrift_backend.open_session(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_backend.py", line 554, in open_session
    response = self.make_request(self._client.OpenSession, open_session_req)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_backend.py", line 471, in make_request
    response_or_error_info = attempt_request(attempt)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_backend.py", line 381, in attempt_request
    response = method(request)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_api\TCLIService\TCLIService.py", line 204, in OpenSession
    self.send_OpenSession(req)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_api\TCLIService\TCLIService.py", line 213, in send_OpenSession
    self._oprot.trans.flush()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\auth\thrift_http_client.py", line 186, in flush
    self.__resp = self.__pool.request(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\_request_methods.py", line 143, in request
    return self.request_encode_body(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\connectionpool.py", line 942, in urlopen
    return self.urlopen(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\connectionpool.py", line 940, in urlopen
    retries.sleep(response)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\util\retry.py", line 359, in sleep
    slept = self.sleep_for_retry(response)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\auth\retry.py", line 296, in sleep_for_retry
    time.sleep(proposed_wait)
KeyboardInterrupt

[0m19:10:43.773961 [debug] [MainThread]: Command `dbt debug` failed at 19:10:43.772958 after 106.92 seconds
[0m19:10:43.776959 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m19:10:43.776959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262C5C4E1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262E19AE710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000262E19AE080>]}
[0m19:10:43.778968 [debug] [MainThread]: Flushing usage events
[0m19:10:44.326034 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:37:02.526711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D33444E140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D335B7E4D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D335B7E2C0>]}


============================== 19:37:02.534711 | e7c62a7a-38f7-449f-be8c-6bcf9a54986a ==============================
[0m19:37:02.534711 [info ] [MainThread]: Running with dbt=1.9.2
[0m19:37:02.536712 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'fail_fast': 'False', 'profiles_dir': 'dbt_databricks_capgemini', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m19:37:02.573755 [info ] [MainThread]: dbt version: 1.9.2
[0m19:37:02.574757 [info ] [MainThread]: python version: 3.10.11
[0m19:37:02.575756 [info ] [MainThread]: python path: C:\Users\tbicocch\DbtDatabricks\env\Scripts\python.exe
[0m19:37:02.576758 [info ] [MainThread]: os info: Windows-10-10.0.22631-SP0
[0m19:37:02.577761 [info ] [MainThread]: Using profiles dir at dbt_databricks_capgemini
[0m19:37:02.578764 [info ] [MainThread]: Using profiles.yml file at dbt_databricks_capgemini\profiles.yml
[0m19:37:02.579758 [info ] [MainThread]: Using dbt_project.yml file at dbt_databricks_capgemini\dbt_project.yml
[0m19:37:02.713794 [info ] [MainThread]: Configuration:
[0m19:37:02.714793 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m19:37:02.715793 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m19:37:02.716835 [info ] [MainThread]: Required dependencies:
[0m19:37:02.717798 [debug] [MainThread]: Executing "git --help"
[0m19:37:02.918222 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:37:02.919213 [debug] [MainThread]: STDERR: "b''"
[0m19:37:02.919213 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m19:37:02.921213 [info ] [MainThread]: Connection test skipped since no profile was found
[0m19:37:02.922213 [info ] [MainThread]: [31m1 check failed:[0m
[0m19:37:02.923219 [info ] [MainThread]: dbt looked for a profiles.yml file in dbt_databricks_capgemini\profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m19:37:02.925228 [debug] [MainThread]: Command `dbt debug` failed at 19:37:02.925228 after 0.62 seconds
[0m19:37:02.927231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D33444E140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D3354E95D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D334593100>]}
[0m19:37:02.927231 [debug] [MainThread]: Flushing usage events
[0m19:37:03.529542 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:42:53.473884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248C9F4E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248CB8CA4A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248CB8CA2F0>]}


============================== 19:42:53.478891 | 0f923d40-8470-4334-b0d9-f9c3c4bc7da9 ==============================
[0m19:42:53.478891 [info ] [MainThread]: Running with dbt=1.9.2
[0m19:42:53.479875 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'profiles_dir': 'dbt_databricks_capgemini', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:42:53.504819 [info ] [MainThread]: dbt version: 1.9.2
[0m19:42:53.505992 [info ] [MainThread]: python version: 3.10.11
[0m19:42:53.507010 [info ] [MainThread]: python path: C:\Users\tbicocch\DbtDatabricks\env\Scripts\python.exe
[0m19:42:53.507010 [info ] [MainThread]: os info: Windows-10-10.0.22631-SP0
[0m19:42:53.511997 [info ] [MainThread]: Using profiles dir at dbt_databricks_capgemini
[0m19:42:53.513998 [info ] [MainThread]: Using profiles.yml file at dbt_databricks_capgemini\profiles.yml
[0m19:42:53.516020 [info ] [MainThread]: Using dbt_project.yml file at dbt_databricks_capgemini\dbt_project.yml
[0m19:42:53.594389 [info ] [MainThread]: Configuration:
[0m19:42:53.595361 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m19:42:53.596356 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m19:42:53.597373 [info ] [MainThread]: Required dependencies:
[0m19:42:53.598353 [debug] [MainThread]: Executing "git --help"
[0m19:42:53.752222 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:42:53.753222 [debug] [MainThread]: STDERR: "b''"
[0m19:42:53.754217 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m19:42:53.755754 [info ] [MainThread]: Connection test skipped since no profile was found
[0m19:42:53.756751 [info ] [MainThread]: [31m1 check failed:[0m
[0m19:42:53.757099 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Could not find profile named 'dbt_databricks_capgemini_I'


[0m19:42:53.759110 [debug] [MainThread]: Command `dbt debug` failed at 19:42:53.759110 after 0.53 seconds
[0m19:42:53.760108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248C9F4E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248CB99A740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248CB1EBE80>]}
[0m19:42:53.760108 [debug] [MainThread]: Flushing usage events
[0m19:42:54.326091 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:43:57.167955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000162BF64E140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000162C0F7E500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000162C0F7E320>]}


============================== 19:43:57.174971 | 27653161-0f4d-4a06-a961-2456e1784f47 ==============================
[0m19:43:57.174971 [info ] [MainThread]: Running with dbt=1.9.2
[0m19:43:57.175967 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\tbicocch\\.dbt', 'log_path': 'logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt init dbt_italy', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:43:57.214516 [debug] [MainThread]: Starter project path: C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\include\starter_project
[0m19:43:57.250557 [info ] [MainThread]: 
Your new dbt project "dbt_italy" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m19:43:57.254547 [info ] [MainThread]: Setting up your profile.
[0m19:44:06.057789 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:44:06.058787 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:44:06.059789 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:51:45.344560 [info ] [MainThread]: Profile dbt_italy written to C:\Users\tbicocch\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m19:51:45.346601 [debug] [MainThread]: Command `dbt init` succeeded at 19:51:45.346601 after 468.62 seconds
[0m19:51:45.347608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000162BF64E140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000162C0F5F0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000162C0F7E2C0>]}
[0m19:51:45.348599 [debug] [MainThread]: Flushing usage events
[0m19:51:45.924284 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:52:56.323444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229DA24E1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229DBBCA4A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229DBBCA710>]}


============================== 19:52:56.327444 | 2e5b5193-61a2-4c29-9c5f-0eeff4a050dc ==============================
[0m19:52:56.327444 [info ] [MainThread]: Running with dbt=1.9.2
[0m19:52:56.328439 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:52:56.348440 [info ] [MainThread]: dbt version: 1.9.2
[0m19:52:56.349441 [info ] [MainThread]: python version: 3.10.11
[0m19:52:56.350446 [info ] [MainThread]: python path: C:\Users\tbicocch\DbtDatabricks\env\Scripts\python.exe
[0m19:52:56.351440 [info ] [MainThread]: os info: Windows-10-10.0.22631-SP0
[0m19:52:56.356438 [info ] [MainThread]: Using profiles dir at dbt_italy
[0m19:52:56.356438 [info ] [MainThread]: Using profiles.yml file at dbt_italy\profiles.yml
[0m19:52:56.357439 [info ] [MainThread]: Using dbt_project.yml file at dbt_italy\dbt_project.yml
[0m19:52:56.435969 [info ] [MainThread]: Configuration:
[0m19:52:56.437970 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m19:52:56.437970 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m19:52:56.438968 [info ] [MainThread]: Required dependencies:
[0m19:52:56.439971 [debug] [MainThread]: Executing "git --help"
[0m19:52:56.588910 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:52:56.589904 [debug] [MainThread]: STDERR: "b''"
[0m19:52:56.589904 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m19:52:56.590905 [info ] [MainThread]: Connection test skipped since no profile was found
[0m19:52:56.591903 [info ] [MainThread]: [31m1 check failed:[0m
[0m19:52:56.592446 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Could not find profile named 'dbt_italy'


[0m19:52:56.593460 [debug] [MainThread]: Command `dbt debug` failed at 19:52:56.593460 after 0.43 seconds
[0m19:52:56.594462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229DA24E1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229D7D7CEE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229DBB23B20>]}
[0m19:52:56.595461 [debug] [MainThread]: Flushing usage events
[0m19:52:57.145919 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:53:21.807805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F13D4E200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F156CA530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F156CA230>]}


============================== 19:53:21.814806 | 6df593d0-92d9-4035-a194-7ab18b49954f ==============================
[0m19:53:21.814806 [info ] [MainThread]: Running with dbt=1.9.2
[0m19:53:21.816814 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'dbt_italy', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m19:53:21.840339 [info ] [MainThread]: dbt version: 1.9.2
[0m19:53:21.841333 [info ] [MainThread]: python version: 3.10.11
[0m19:53:21.841333 [info ] [MainThread]: python path: C:\Users\tbicocch\DbtDatabricks\env\Scripts\python.exe
[0m19:53:21.842337 [info ] [MainThread]: os info: Windows-10-10.0.22631-SP0
[0m19:53:22.493466 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:53:22.493466 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:53:22.494469 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:53:23.231119 [info ] [MainThread]: Using profiles dir at dbt_italy
[0m19:53:23.233149 [info ] [MainThread]: Using profiles.yml file at dbt_italy\profiles.yml
[0m19:53:23.234143 [info ] [MainThread]: Using dbt_project.yml file at dbt_italy\dbt_project.yml
[0m19:53:23.234143 [info ] [MainThread]: adapter type: databricks
[0m19:53:23.235167 [info ] [MainThread]: adapter version: 1.9.5
[0m19:53:23.302179 [info ] [MainThread]: Configuration:
[0m19:53:23.302971 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m19:53:23.304001 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m19:53:23.304985 [info ] [MainThread]: Required dependencies:
[0m19:53:23.304985 [debug] [MainThread]: Executing "git --help"
[0m19:53:23.454135 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m19:53:23.455137 [debug] [MainThread]: STDERR: "b''"
[0m19:53:23.455137 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m19:53:23.456664 [info ] [MainThread]: Connection:
[0m19:53:23.457683 [info ] [MainThread]:   host: dbc-200ae55c-a8b7.cloud.databricks.com
[0m19:53:23.457683 [info ] [MainThread]:   http_path: /sql/warehouses/44b4e39b1cbff1ff?o=4465281864151379
[0m19:53:23.458685 [info ] [MainThread]:   catalog: workspace
[0m19:53:23.459690 [info ] [MainThread]:   schema: default
[0m19:53:23.460682 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m19:53:23.842490 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2539129384304, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(10444, 23260), compute-name=) - Creating connection
[0m19:53:23.843493 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m19:53:23.843493 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2539129384304, session-id=None, name=debug, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(10444, 23260), compute-name=) - Acquired connection on thread (10444, 23260), using default compute resource
[0m19:53:23.844493 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2539129384304, session-id=None, name=debug, idle-time=0.0010001659393310547s, acquire-count=1, language=None, thread-identifier=(10444, 23260), compute-name=) - Checking idleness
[0m19:53:23.844493 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2539129384304, session-id=None, name=debug, idle-time=0.0010001659393310547s, acquire-count=1, language=None, thread-identifier=(10444, 23260), compute-name=) - Retrieving connection
[0m19:53:23.845491 [debug] [MainThread]: Using databricks connection "debug"
[0m19:53:23.845491 [debug] [MainThread]: On debug: select 1 as id
[0m19:53:23.845491 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:54:13.744129 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2539129384304, session-id=None, name=debug, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(10444, 23260), compute-name=) - Released connection
[0m19:54:13.745129 [error] [MainThread]: Encountered an error:

[0m19:54:13.754130 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\main.py", line 414, in debug
    results = task.run()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\debug.py", line 144, in run
    connection_status = self.test_connection()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\debug.py", line 465, in test_connection
    connection_result = self.attempt_connection(self.profile)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\debug.py", line 443, in attempt_connection
    adapter.debug_query()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\spark\impl.py", line 517, in debug_query
    self.execute("select 1 as id")
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\impl.py", line 289, in execute
    return super().execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\base\impl.py", line 404, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 314, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 287, in add_query
    handle: DatabricksHandle = connection.handle
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\contracts\connection.py", line 96, in handle
    self._handle.resolve(self)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\contracts\connection.py", line 120, in resolve
    return self.opener(connection)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 450, in open
    return cls.retry_connection(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\base\connections.py", line 237, in retry_connection
    connection.handle = connect()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\connections.py", line 428, in connect
    conn = DatabricksHandle.from_connection_args(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\adapters\databricks\handle.py", line 211, in from_connection_args
    conn = dbsql.connect(**conn_args)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\__init__.py", line 90, in connect
    return Connection(server_hostname, http_path, access_token, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\client.py", line 255, in __init__
    self._open_session_resp = self.thrift_backend.open_session(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_backend.py", line 554, in open_session
    response = self.make_request(self._client.OpenSession, open_session_req)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_backend.py", line 471, in make_request
    response_or_error_info = attempt_request(attempt)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_backend.py", line 381, in attempt_request
    response = method(request)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_api\TCLIService\TCLIService.py", line 204, in OpenSession
    self.send_OpenSession(req)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\thrift_api\TCLIService\TCLIService.py", line 213, in send_OpenSession
    self._oprot.trans.flush()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\auth\thrift_http_client.py", line 186, in flush
    self.__resp = self.__pool.request(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\_request_methods.py", line 143, in request
    return self.request_encode_body(
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\connectionpool.py", line 940, in urlopen
    retries.sleep(response)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\urllib3\util\retry.py", line 359, in sleep
    slept = self.sleep_for_retry(response)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\databricks\sql\auth\retry.py", line 296, in sleep_for_retry
    time.sleep(proposed_wait)
KeyboardInterrupt

[0m19:54:13.762129 [debug] [MainThread]: Command `dbt debug` failed at 19:54:13.762129 after 52.15 seconds
[0m19:54:13.763132 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m19:54:13.764130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F13D4E200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F2F6AB4C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024F2F6A9C00>]}
[0m19:54:13.765129 [debug] [MainThread]: Flushing usage events
[0m19:54:14.482741 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:45:45.278456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D00D74E140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D00F0CA5C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D00F0CA2C0>]}


============================== 21:45:45.284481 | 118a22ab-cb19-4d54-bb69-89f4e846632d ==============================
[0m21:45:45.284481 [info ] [MainThread]: Running with dbt=1.9.2
[0m21:45:45.285274 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'version_check': 'True', 'profiles_dir': 'dbt_italy', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:45:46.188708 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:45:46.189710 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:45:46.189710 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:45:47.921027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '118a22ab-cb19-4d54-bb69-89f4e846632d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D00F090040>]}
[0m21:45:47.961607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '118a22ab-cb19-4d54-bb69-89f4e846632d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D0105568F0>]}
[0m21:45:47.962609 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m21:45:48.392378 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m21:45:48.393379 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m21:45:48.394200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '118a22ab-cb19-4d54-bb69-89f4e846632d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D029029990>]}
[0m21:45:49.955645 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m21:45:49.968638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '118a22ab-cb19-4d54-bb69-89f4e846632d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D02A02BFA0>]}
[0m21:45:50.062080 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m21:45:50.066114 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m21:45:50.113386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '118a22ab-cb19-4d54-bb69-89f4e846632d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D00F05DF60>]}
[0m21:45:50.113386 [info ] [MainThread]: Found 1 model, 2 data tests, 1 source, 607 macros
[0m21:45:50.115389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '118a22ab-cb19-4d54-bb69-89f4e846632d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D00F05E170>]}
[0m21:45:50.116386 [info ] [MainThread]: 
[0m21:45:50.117411 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:45:50.118394 [info ] [MainThread]: 
[0m21:45:50.119413 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1993116860624, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(26536, 29556), compute-name=) - Creating connection
[0m21:45:50.120411 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:45:50.120411 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1993116860624, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(26536, 29556), compute-name=) - Acquired connection on thread (26536, 29556), using default compute resource
[0m21:45:50.122407 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1993568644944, session-id=None, name=list_workspace, idle-time=0s, acquire-count=0, language=None, thread-identifier=(26536, 10052), compute-name=) - Creating connection
[0m21:45:50.122407 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m21:45:50.123398 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1993568644944, session-id=None, name=list_workspace, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(26536, 10052), compute-name=) - Acquired connection on thread (26536, 10052), using default compute resource
[0m21:45:50.123398 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1993568644944, session-id=None, name=list_workspace, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(26536, 10052), compute-name=) - Checking idleness
[0m21:45:50.124396 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1993568644944, session-id=None, name=list_workspace, idle-time=0.000997781753540039s, acquire-count=1, language=None, thread-identifier=(26536, 10052), compute-name=) - Retrieving connection
[0m21:45:50.124396 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m21:45:50.125396 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m21:45:50.126395 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:58:10.961791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196EBA4E1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196ED3CA5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196ED3CA2F0>]}


============================== 21:58:10.965796 | 1e586d7f-b687-4d6b-83a1-e89e74c579fe ==============================
[0m21:58:10.965796 [info ] [MainThread]: Running with dbt=1.9.2
[0m21:58:10.966791 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m21:58:11.610869 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:58:11.611851 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:58:11.611851 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:58:12.472487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e586d7f-b687-4d6b-83a1-e89e74c579fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001968718F310>]}
[0m21:58:12.513478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e586d7f-b687-4d6b-83a1-e89e74c579fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001968718FCD0>]}
[0m21:58:12.514479 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m21:58:12.973055 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m21:58:13.062555 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m21:58:13.063553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1e586d7f-b687-4d6b-83a1-e89e74c579fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196ECC90E50>]}
[0m21:58:14.474865 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m21:58:14.484877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e586d7f-b687-4d6b-83a1-e89e74c579fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196886A0A90>]}
[0m21:58:14.566151 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m21:58:14.569151 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m21:58:14.593249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e586d7f-b687-4d6b-83a1-e89e74c579fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196886789D0>]}
[0m21:58:14.594266 [info ] [MainThread]: Found 1 model, 2 data tests, 1 source, 607 macros
[0m21:58:14.595165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e586d7f-b687-4d6b-83a1-e89e74c579fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196883DB190>]}
[0m21:58:14.597202 [info ] [MainThread]: 
[0m21:58:14.598183 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:58:14.599185 [info ] [MainThread]: 
[0m21:58:14.600191 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(20668, 30288), compute-name=) - Creating connection
[0m21:58:14.600191 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:58:14.601197 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(20668, 30288), compute-name=) - Acquired connection on thread (20668, 30288), using default compute resource
[0m21:58:14.602198 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045242144, session-id=None, name=list_workspace, idle-time=0s, acquire-count=0, language=None, thread-identifier=(20668, 5020), compute-name=) - Creating connection
[0m21:58:14.603195 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m21:58:14.604197 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045242144, session-id=None, name=list_workspace, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(20668, 5020), compute-name=) - Acquired connection on thread (20668, 5020), using default compute resource
[0m21:58:14.605196 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045242144, session-id=None, name=list_workspace, idle-time=0.0009984970092773438s, acquire-count=1, language=None, thread-identifier=(20668, 5020), compute-name=) - Checking idleness
[0m21:58:14.605196 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045242144, session-id=None, name=list_workspace, idle-time=0.0009984970092773438s, acquire-count=1, language=None, thread-identifier=(20668, 5020), compute-name=) - Retrieving connection
[0m21:58:14.606196 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m21:58:14.606196 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m21:58:14.607195 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:58:15.279827 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff096-9179-1aa9-abe2-57924e76f9cb) - Created
[0m21:59:17.488120 [debug] [ThreadPool]: SQL status: OK in 62.880 seconds
[0m21:59:17.491123 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff096-9179-1aa9-abe2-57924e76f9cb, command-id=01eff096-b579-1e14-9525-a3ca3bbd2316) - Closing
[0m21:59:17.491123 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045242144, session-id=01eff096-9179-1aa9-abe2-57924e76f9cb, name=list_workspace, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(20668, 5020), compute-name=) - Released connection
[0m21:59:17.494120 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045240704, session-id=None, name=list_workspace_default, idle-time=0s, acquire-count=0, language=None, thread-identifier=(20668, 14664), compute-name=) - Creating connection
[0m21:59:17.494120 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m21:59:17.495121 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045240704, session-id=None, name=list_workspace_default, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(20668, 14664), compute-name=) - Acquired connection on thread (20668, 14664), using default compute resource
[0m21:59:17.504122 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045240704, session-id=None, name=list_workspace_default, idle-time=0.00900125503540039s, acquire-count=1, language=None, thread-identifier=(20668, 14664), compute-name=) - Checking idleness
[0m21:59:17.505119 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045240704, session-id=None, name=list_workspace_default, idle-time=0.009998083114624023s, acquire-count=1, language=None, thread-identifier=(20668, 14664), compute-name=) - Retrieving connection
[0m21:59:17.505119 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045240704, session-id=None, name=list_workspace_default, idle-time=0.009998083114624023s, acquire-count=1, language=None, thread-identifier=(20668, 14664), compute-name=) - Checking idleness
[0m21:59:17.506122 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045240704, session-id=None, name=list_workspace_default, idle-time=0.011000871658325195s, acquire-count=1, language=None, thread-identifier=(20668, 14664), compute-name=) - Retrieving connection
[0m21:59:17.506122 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m21:59:17.507121 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m21:59:17.507121 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_workspace_default"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'workspace'
      and table_schema = 'default'
    
  
[0m21:59:17.508121 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:59:17.838102 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff096-b6e8-1232-8501-602942c0e7c0) - Created
[0m21:59:19.385283 [debug] [ThreadPool]: SQL status: OK in 1.880 seconds
[0m21:59:19.396751 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff096-b6e8-1232-8501-602942c0e7c0, command-id=01eff096-b6f6-10c1-b79c-4f7ba53ed7e3) - Closing
[0m21:59:19.396751 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1746045240704, session-id=01eff096-b6e8-1232-8501-602942c0e7c0, name=list_workspace_default, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(20668, 14664), compute-name=) - Released connection
[0m21:59:19.397752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e586d7f-b687-4d6b-83a1-e89e74c579fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019688680E20>]}
[0m21:59:19.398753 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=64.79856133460999s, acquire-count=1, language=None, thread-identifier=(20668, 30288), compute-name=) - Checking idleness
[0m21:59:19.399753 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=64.7995617389679s, acquire-count=1, language=None, thread-identifier=(20668, 30288), compute-name=) - Retrieving connection
[0m21:59:19.400753 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=64.8005621433258s, acquire-count=1, language=None, thread-identifier=(20668, 30288), compute-name=) - Checking idleness
[0m21:59:19.400753 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=64.8005621433258s, acquire-count=1, language=None, thread-identifier=(20668, 30288), compute-name=) - Retrieving connection
[0m21:59:19.401751 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m21:59:19.401751 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m21:59:19.402750 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(20668, 30288), compute-name=) - Released connection
[0m21:59:19.406751 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_sales_customer
[0m21:59:19.407749 [info ] [Thread-1 (]: 1 of 1 START sql incremental model default.stg_sales_customer .................. [RUN]
[0m21:59:19.408750 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1746045243632, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(20668, 17436), compute-name=) - Creating connection
[0m21:59:19.409750 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_sales_customer'
[0m21:59:19.410750 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1746045243632, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(20668, 17436), compute-name=) - Acquired connection on thread (20668, 17436), using default compute resource for model '`workspace`.`default`.`stg_sales_customer`'
[0m21:59:19.410750 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_sales_customer
[0m21:59:19.420748 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_sales_customer"
[0m21:59:19.425746 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_sales_customer
[0m21:59:19.513258 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_sales_customer"
[0m21:59:19.520651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1746045243632, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.1109011173248291s, acquire-count=1, language=sql, thread-identifier=(20668, 17436), compute-name=) - Checking idleness
[0m21:59:19.521651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1746045243632, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.1109011173248291s, acquire-count=1, language=sql, thread-identifier=(20668, 17436), compute-name=) - Retrieving connection
[0m21:59:19.521651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1746045243632, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.11190128326416016s, acquire-count=1, language=sql, thread-identifier=(20668, 17436), compute-name=) - Checking idleness
[0m21:59:19.522651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1746045243632, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.1129004955291748s, acquire-count=1, language=sql, thread-identifier=(20668, 17436), compute-name=) - Retrieving connection
[0m21:59:19.522651 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m21:59:19.523650 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_sales_customer"
[0m21:59:19.523650 [debug] [Thread-1 (]: On model.dbt_italy.stg_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_sales_customer"} */

  
    
        create or replace table `workspace`.`default`.`stg_sales_customer`
      
      using delta
      
      
      
      
      
      
      
      as
      


SELECT *
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m21:59:19.524651 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:59:19.847934 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff096-b81d-1293-8fe2-c258603ed59a) - Created
[0m21:59:37.789978 [debug] [Thread-1 (]: SQL status: OK in 18.260 seconds
[0m21:59:37.791979 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff096-b81d-1293-8fe2-c258603ed59a, command-id=01eff096-b828-1c10-84dd-ac45f5b7f38a) - Closing
[0m21:59:37.972493 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1746045243632, session-id=01eff096-b81d-1293-8fe2-c258603ed59a, name=model.dbt_italy.stg_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(20668, 17436), compute-name=) - Released connection
[0m21:59:37.973492 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1746045243632, session-id=01eff096-b81d-1293-8fe2-c258603ed59a, name=model.dbt_italy.stg_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(20668, 17436), compute-name=) - Released connection
[0m21:59:37.976492 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e586d7f-b687-4d6b-83a1-e89e74c579fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196EA63B1C0>]}
[0m21:59:37.978492 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model default.stg_sales_customer ............. [[32mOK[0m in 18.57s]
[0m21:59:37.979492 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_sales_customer
[0m21:59:37.982491 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=18.57974100112915s, acquire-count=0, language=None, thread-identifier=(20668, 30288), compute-name=) - Checking idleness
[0m21:59:37.982491 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=18.57974100112915s, acquire-count=0, language=None, thread-identifier=(20668, 30288), compute-name=) - Reusing connection previously named master
[0m21:59:37.983491 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=18.58074116706848s, acquire-count=1, language=None, thread-identifier=(20668, 30288), compute-name=) - Acquired connection on thread (20668, 30288), using default compute resource
[0m21:59:37.984490 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=18.581740140914917s, acquire-count=1, language=None, thread-identifier=(20668, 30288), compute-name=) - Checking idleness
[0m21:59:37.984490 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=None, name=master, idle-time=18.581740140914917s, acquire-count=1, language=None, thread-identifier=(20668, 30288), compute-name=) - Retrieving connection
[0m21:59:37.985490 [debug] [MainThread]: On master: ROLLBACK
[0m21:59:37.986490 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:59:38.366435 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff096-c324-1886-a020-81efa85fc219) - Created
[0m21:59:38.367432 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m21:59:38.368432 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=01eff096-c324-1886-a020-81efa85fc219, name=master, idle-time=0.00099945068359375s, acquire-count=1, language=None, thread-identifier=(20668, 30288), compute-name=) - Checking idleness
[0m21:59:38.368432 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=01eff096-c324-1886-a020-81efa85fc219, name=master, idle-time=0.00099945068359375s, acquire-count=1, language=None, thread-identifier=(20668, 30288), compute-name=) - Retrieving connection
[0m21:59:38.369431 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m21:59:38.369431 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m21:59:38.370430 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1746045252416, session-id=01eff096-c324-1886-a020-81efa85fc219, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(20668, 30288), compute-name=) - Released connection
[0m21:59:38.370430 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:59:38.371430 [debug] [MainThread]: On master: ROLLBACK
[0m21:59:38.371430 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m21:59:38.372429 [debug] [MainThread]: On master: Close
[0m21:59:38.372429 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff096-c324-1886-a020-81efa85fc219) - Closing
[0m21:59:38.526175 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m21:59:38.527173 [debug] [MainThread]: On list_workspace: Close
[0m21:59:38.528172 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff096-9179-1aa9-abe2-57924e76f9cb) - Closing
[0m21:59:38.655114 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m21:59:38.656101 [debug] [MainThread]: On list_workspace_default: ROLLBACK
[0m21:59:38.657086 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m21:59:38.657086 [debug] [MainThread]: On list_workspace_default: Close
[0m21:59:38.658089 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff096-b6e8-1232-8501-602942c0e7c0) - Closing
[0m21:59:38.785569 [debug] [MainThread]: Connection 'model.dbt_italy.stg_sales_customer' was properly closed.
[0m21:59:38.786569 [debug] [MainThread]: On model.dbt_italy.stg_sales_customer: ROLLBACK
[0m21:59:38.786569 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m21:59:38.787567 [debug] [MainThread]: On model.dbt_italy.stg_sales_customer: Close
[0m21:59:38.787567 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff096-b81d-1293-8fe2-c258603ed59a) - Closing
[0m21:59:38.915135 [info ] [MainThread]: 
[0m21:59:38.915966 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 1 minutes and 24.31 seconds (84.31s).
[0m21:59:38.916984 [debug] [MainThread]: Command end result
[0m21:59:38.946251 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m21:59:38.950252 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m21:59:38.959249 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m21:59:38.960251 [info ] [MainThread]: 
[0m21:59:38.963374 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:59:38.963374 [info ] [MainThread]: 
[0m21:59:38.964365 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:59:38.966372 [debug] [MainThread]: Command `dbt run` succeeded at 21:59:38.966372 after 88.19 seconds
[0m21:59:38.968367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196EBA4E1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001968718F310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196885DE320>]}
[0m21:59:38.969364 [debug] [MainThread]: Flushing usage events
[0m21:59:39.624535 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:00:11.272483 [error] [ThreadPool]: Databricks adapter: Connection(session-id=Unknown) - Exception while trying to create connection: Error during request to server. Retry request would exceed Retry policy max retry duration of 900.0 seconds
Error properties: attempt=1/30, bounded-retry-delay=None, elapsed-seconds=861.1222867965698/900.0, error-message=, http-code=None, method=OpenSession, no-retry-reason=non-retryable error, original-exception=Retry request would exceed Retry policy max retry duration of 900.0 seconds, query-id=None, session-id=None
[0m22:00:11.275491 [debug] [ThreadPool]: Databricks adapter: Exception while trying to execute query
GetSchemas(database=workspace, schema=None)
: Database Error
  Error during request to server. Retry request would exceed Retry policy max retry duration of 900.0 seconds
[0m22:00:11.276492 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1993568644944, session-id=None, name=list_workspace, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(26536, 10052), compute-name=) - Released connection
[0m22:00:11.277492 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1993116860624, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(26536, 29556), compute-name=) - Released connection
[0m22:00:11.278491 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:00:11.279492 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m22:00:11.280490 [debug] [MainThread]: On list_workspace: No close available on handle
[0m22:00:11.280490 [info ] [MainThread]: 
[0m22:00:11.281490 [info ] [MainThread]: Finished running  in 0 hours 14 minutes and 21.16 seconds (861.16s).
[0m22:00:11.282488 [error] [MainThread]: Encountered an error:

[0m22:00:11.301010 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 235, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 264, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\requires.py", line 328, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\cli\main.py", line 578, in run
    results = task.run()
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\runnable.py", line 588, in run
    result = self.execute_with_hooks(selected_uids)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\runnable.py", line 526, in execute_with_hooks
    before_run_status = self.before_run(adapter, selected_uids)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\run.py", line 994, in before_run
    self.create_schemas(adapter, required_schemas)
  File "C:\Users\tbicocch\DbtDatabricks\env\lib\site-packages\dbt\task\runnable.py", line 694, in create_schemas
    for ls_future in as_completed(list_futures):
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\lib\concurrent\futures\_base.py", line 245, in as_completed
    waiter.event.wait(wait_timeout)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\lib\threading.py", line 607, in wait
    signaled = self._cond.wait(timeout)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\lib\threading.py", line 320, in wait
    waiter.acquire()
KeyboardInterrupt

[0m22:00:11.306011 [debug] [MainThread]: Command `dbt run` failed at 22:00:11.306011 after 866.39 seconds
[0m22:00:11.307015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D00D74E140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D00F05FB50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D02A253520>]}
[0m22:00:11.308011 [debug] [MainThread]: Flushing usage events
[0m22:00:11.857216 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:07:58.414376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257D2D4E110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257D46CA530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257D46CA230>]}


============================== 22:07:58.419366 | ad932cf2-0c4e-4fed-ad96-b1f03d9598c0 ==============================
[0m22:07:58.419366 [info ] [MainThread]: Running with dbt=1.9.2
[0m22:07:58.421364 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:07:59.024977 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m22:07:59.024977 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m22:07:59.025977 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m22:07:59.853744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ad932cf2-0c4e-4fed-ad96-b1f03d9598c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257EE57AEC0>]}
[0m22:07:59.895346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ad932cf2-0c4e-4fed-ad96-b1f03d9598c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257D3283EE0>]}
[0m22:07:59.897333 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m22:08:00.348563 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m22:08:00.562555 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:08:00.563555 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\stg_sales_customer.yml
[0m22:08:00.962620 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m22:08:00.974623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad932cf2-0c4e-4fed-ad96-b1f03d9598c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257EF53CD90>]}
[0m22:08:01.078185 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m22:08:01.081184 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m22:08:01.107196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ad932cf2-0c4e-4fed-ad96-b1f03d9598c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257EE57A4A0>]}
[0m22:08:01.108179 [info ] [MainThread]: Found 1 model, 2 data tests, 1 source, 607 macros
[0m22:08:01.108634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad932cf2-0c4e-4fed-ad96-b1f03d9598c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257EE57B580>]}
[0m22:08:01.109645 [info ] [MainThread]: 
[0m22:08:01.110650 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:08:01.111648 [info ] [MainThread]: 
[0m22:08:01.111648 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(30632, 18276), compute-name=) - Creating connection
[0m22:08:01.112645 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:08:01.112645 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(30632, 18276), compute-name=) - Acquired connection on thread (30632, 18276), using default compute resource
[0m22:08:01.114644 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(30632, 29612), compute-name=) - Creating connection
[0m22:08:01.114644 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m22:08:01.115643 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(30632, 29612), compute-name=) - Acquired connection on thread (30632, 29612), using default compute resource
[0m22:08:01.115643 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(30632, 29612), compute-name=) - Checking idleness
[0m22:08:01.116642 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=None, name=list_bronze, idle-time=0.0009992122650146484s, acquire-count=1, language=None, thread-identifier=(30632, 29612), compute-name=) - Retrieving connection
[0m22:08:01.116642 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m22:08:01.117641 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m22:08:01.118648 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:08:02.050075 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3) - Created
[0m22:08:02.491730 [debug] [ThreadPool]: SQL status: OK in 1.370 seconds
[0m22:08:02.492726 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, command-id=01eff097-ef69-1e20-8248-76723c595b70) - Closing
[0m22:08:02.493725 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(30632, 29612), compute-name=) - Released connection
[0m22:08:02.494696 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=list_bronze, idle-time=0.0009701251983642578s, acquire-count=0, language=None, thread-identifier=(30632, 29612), compute-name=) - Checking idleness
[0m22:08:02.494696 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_bronze, now create_bronze_default_sal)
[0m22:08:02.495694 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=create_bronze_default_sal, idle-time=0.0019690990447998047s, acquire-count=0, language=None, thread-identifier=(30632, 29612), compute-name=) - Reusing connection previously named list_bronze
[0m22:08:02.495694 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=create_bronze_default_sal, idle-time=0.0019690990447998047s, acquire-count=1, language=None, thread-identifier=(30632, 29612), compute-name=) - Acquired connection on thread (30632, 29612), using default compute resource
[0m22:08:02.496693 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=create_bronze_default_sal, idle-time=0.00296783447265625s, acquire-count=1, language=None, thread-identifier=(30632, 29612), compute-name=) - Checking idleness
[0m22:08:02.497692 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=create_bronze_default_sal, idle-time=0.00296783447265625s, acquire-count=2, language=None, thread-identifier=(30632, 29612), compute-name=) - Acquired connection on thread (30632, 29612), using default compute resource
[0m22:08:02.506947 [debug] [ThreadPool]: Creating schema "database: "bronze"
schema: "default_sal"
"
[0m22:08:02.515956 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=create_bronze_default_sal, idle-time=0.022230148315429688s, acquire-count=2, language=None, thread-identifier=(30632, 29612), compute-name=) - Checking idleness
[0m22:08:02.516956 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=create_bronze_default_sal, idle-time=0.02323007583618164s, acquire-count=2, language=None, thread-identifier=(30632, 29612), compute-name=) - Retrieving connection
[0m22:08:02.517956 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=create_bronze_default_sal, idle-time=0.0242307186126709s, acquire-count=2, language=None, thread-identifier=(30632, 29612), compute-name=) - Checking idleness
[0m22:08:02.517956 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=create_bronze_default_sal, idle-time=0.0242307186126709s, acquire-count=2, language=None, thread-identifier=(30632, 29612), compute-name=) - Retrieving connection
[0m22:08:02.518970 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m22:08:02.518970 [debug] [ThreadPool]: Using databricks connection "create_bronze_default_sal"
[0m22:08:02.519969 [debug] [ThreadPool]: On create_bronze_default_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "create_bronze_default_sal"} */
create schema if not exists `bronze`.`default_sal`
  
[0m22:08:03.202518 [debug] [ThreadPool]: SQL status: OK in 0.680 seconds
[0m22:08:03.203517 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, command-id=01eff097-efa9-1454-82ef-4c504a982175) - Closing
[0m22:08:03.204517 [debug] [ThreadPool]: Spark adapter: NotImplemented: commit
[0m22:08:03.205515 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=create_bronze_default_sal, idle-time=0.7117893695831299s, acquire-count=1, language=None, thread-identifier=(30632, 29612), compute-name=) - Released connection
[0m22:08:03.205515 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576684134416, session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3, name=create_bronze_default_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(30632, 29612), compute-name=) - Released connection
[0m22:08:03.207533 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576700661216, session-id=None, name=list_bronze_default_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(30632, 29644), compute-name=) - Creating connection
[0m22:08:03.207533 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_default_sal'
[0m22:08:03.208518 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576700661216, session-id=None, name=list_bronze_default_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(30632, 29644), compute-name=) - Acquired connection on thread (30632, 29644), using default compute resource
[0m22:08:03.213515 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576700661216, session-id=None, name=list_bronze_default_sal, idle-time=0.004996299743652344s, acquire-count=1, language=None, thread-identifier=(30632, 29644), compute-name=) - Checking idleness
[0m22:08:03.214512 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576700661216, session-id=None, name=list_bronze_default_sal, idle-time=0.0059931278228759766s, acquire-count=1, language=None, thread-identifier=(30632, 29644), compute-name=) - Retrieving connection
[0m22:08:03.214512 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576700661216, session-id=None, name=list_bronze_default_sal, idle-time=0.0059931278228759766s, acquire-count=1, language=None, thread-identifier=(30632, 29644), compute-name=) - Checking idleness
[0m22:08:03.215513 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576700661216, session-id=None, name=list_bronze_default_sal, idle-time=0.0069942474365234375s, acquire-count=1, language=None, thread-identifier=(30632, 29644), compute-name=) - Retrieving connection
[0m22:08:03.215513 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m22:08:03.216511 [debug] [ThreadPool]: Using databricks connection "list_bronze_default_sal"
[0m22:08:03.216511 [debug] [ThreadPool]: On list_bronze_default_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_default_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'default_sal'
    
  
[0m22:08:03.217510 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:08:03.602093 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff097-f03f-167e-9e95-1ee20ae8d708) - Created
[0m22:08:04.001665 [debug] [ThreadPool]: SQL status: OK in 0.780 seconds
[0m22:08:04.008678 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff097-f03f-167e-9e95-1ee20ae8d708, command-id=01eff097-f04f-1614-bd65-e61587f0c67e) - Closing
[0m22:08:04.009691 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2576700661216, session-id=01eff097-f03f-167e-9e95-1ee20ae8d708, name=list_bronze_default_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(30632, 29644), compute-name=) - Released connection
[0m22:08:04.010665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad932cf2-0c4e-4fed-ad96-b1f03d9598c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257D4534460>]}
[0m22:08:04.010665 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=2.898019790649414s, acquire-count=1, language=None, thread-identifier=(30632, 18276), compute-name=) - Checking idleness
[0m22:08:04.011676 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=2.899030923843384s, acquire-count=1, language=None, thread-identifier=(30632, 18276), compute-name=) - Retrieving connection
[0m22:08:04.012660 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=2.900014877319336s, acquire-count=1, language=None, thread-identifier=(30632, 18276), compute-name=) - Checking idleness
[0m22:08:04.012660 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=2.900014877319336s, acquire-count=1, language=None, thread-identifier=(30632, 18276), compute-name=) - Retrieving connection
[0m22:08:04.012660 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m22:08:04.013661 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m22:08:04.014658 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(30632, 18276), compute-name=) - Released connection
[0m22:08:04.017157 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_sales_customer
[0m22:08:04.017157 [info ] [Thread-1 (]: 1 of 1 START sql incremental model bronze.default_sal.stg_sales_customer ....... [RUN]
[0m22:08:04.018169 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2576703126880, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(30632, 1472), compute-name=) - Creating connection
[0m22:08:04.019171 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_sales_customer'
[0m22:08:04.020168 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2576703126880, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(30632, 1472), compute-name=) - Acquired connection on thread (30632, 1472), using default compute resource for model '`bronze`.`default_sal`.`stg_sales_customer`'
[0m22:08:04.020168 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_sales_customer
[0m22:08:04.028165 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_sales_customer"
[0m22:08:04.029163 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_sales_customer
[0m22:08:04.105658 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_sales_customer"
[0m22:08:04.109660 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2576703126880, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.08849000930786133s, acquire-count=1, language=sql, thread-identifier=(30632, 1472), compute-name=) - Checking idleness
[0m22:08:04.109660 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2576703126880, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.08949160575866699s, acquire-count=1, language=sql, thread-identifier=(30632, 1472), compute-name=) - Retrieving connection
[0m22:08:04.110657 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2576703126880, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.09048891067504883s, acquire-count=1, language=sql, thread-identifier=(30632, 1472), compute-name=) - Checking idleness
[0m22:08:04.110657 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2576703126880, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.09048891067504883s, acquire-count=1, language=sql, thread-identifier=(30632, 1472), compute-name=) - Retrieving connection
[0m22:08:04.111657 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m22:08:04.111657 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_sales_customer"
[0m22:08:04.112656 [debug] [Thread-1 (]: On model.dbt_italy.stg_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_sales_customer"} */

  
    
        create or replace table `bronze`.`default_sal`.`stg_sales_customer`
      
      using delta
      
      
      
      
      
      
      
      as
      


SELECT *
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m22:08:04.113656 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:08:04.453512 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff097-f0c2-1de6-94c0-c7a8ccf2be2d) - Created
[0m22:08:11.058280 [debug] [Thread-1 (]: SQL status: OK in 6.950 seconds
[0m22:08:11.060280 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff097-f0c2-1de6-94c0-c7a8ccf2be2d, command-id=01eff097-f0d1-11bb-98a7-c2e1d4ad6c4e) - Closing
[0m22:08:11.198457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2576703126880, session-id=01eff097-f0c2-1de6-94c0-c7a8ccf2be2d, name=model.dbt_italy.stg_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(30632, 1472), compute-name=) - Released connection
[0m22:08:11.199438 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2576703126880, session-id=01eff097-f0c2-1de6-94c0-c7a8ccf2be2d, name=model.dbt_italy.stg_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(30632, 1472), compute-name=) - Released connection
[0m22:08:11.201436 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad932cf2-0c4e-4fed-ad96-b1f03d9598c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257D1490280>]}
[0m22:08:11.202435 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model bronze.default_sal.stg_sales_customer .. [[32mOK[0m in 7.18s]
[0m22:08:11.204437 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_sales_customer
[0m22:08:11.205436 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=7.191775798797607s, acquire-count=0, language=None, thread-identifier=(30632, 18276), compute-name=) - Checking idleness
[0m22:08:11.206447 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=7.19278621673584s, acquire-count=0, language=None, thread-identifier=(30632, 18276), compute-name=) - Reusing connection previously named master
[0m22:08:11.207434 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=7.193772792816162s, acquire-count=1, language=None, thread-identifier=(30632, 18276), compute-name=) - Acquired connection on thread (30632, 18276), using default compute resource
[0m22:08:11.208434 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=7.194773197174072s, acquire-count=1, language=None, thread-identifier=(30632, 18276), compute-name=) - Checking idleness
[0m22:08:11.209442 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=None, name=master, idle-time=7.195781707763672s, acquire-count=1, language=None, thread-identifier=(30632, 18276), compute-name=) - Retrieving connection
[0m22:08:11.209442 [debug] [MainThread]: On master: ROLLBACK
[0m22:08:11.210450 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:08:11.587406 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff097-f503-1ecd-932d-879ebf05fde2) - Created
[0m22:08:11.588404 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m22:08:11.589401 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=01eff097-f503-1ecd-932d-879ebf05fde2, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(30632, 18276), compute-name=) - Checking idleness
[0m22:08:11.589401 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=01eff097-f503-1ecd-932d-879ebf05fde2, name=master, idle-time=0.0009961128234863281s, acquire-count=1, language=None, thread-identifier=(30632, 18276), compute-name=) - Retrieving connection
[0m22:08:11.590401 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m22:08:11.590401 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m22:08:11.591403 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2576700627056, session-id=01eff097-f503-1ecd-932d-879ebf05fde2, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(30632, 18276), compute-name=) - Released connection
[0m22:08:11.591403 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:08:11.592401 [debug] [MainThread]: On master: ROLLBACK
[0m22:08:11.592401 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m22:08:11.593401 [debug] [MainThread]: On master: Close
[0m22:08:11.594399 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff097-f503-1ecd-932d-879ebf05fde2) - Closing
[0m22:08:11.747287 [debug] [MainThread]: Connection 'create_bronze_default_sal' was properly closed.
[0m22:08:11.747287 [debug] [MainThread]: On create_bronze_default_sal: ROLLBACK
[0m22:08:11.748289 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m22:08:11.749285 [debug] [MainThread]: On create_bronze_default_sal: Close
[0m22:08:11.750285 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff097-ef51-11ec-9d4c-a5814c8949e3) - Closing
[0m22:08:11.885180 [debug] [MainThread]: Connection 'list_bronze_default_sal' was properly closed.
[0m22:08:11.886174 [debug] [MainThread]: On list_bronze_default_sal: ROLLBACK
[0m22:08:11.887171 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m22:08:11.888309 [debug] [MainThread]: On list_bronze_default_sal: Close
[0m22:08:11.889179 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff097-f03f-167e-9e95-1ee20ae8d708) - Closing
[0m22:08:12.042273 [debug] [MainThread]: Connection 'model.dbt_italy.stg_sales_customer' was properly closed.
[0m22:08:12.043272 [debug] [MainThread]: On model.dbt_italy.stg_sales_customer: ROLLBACK
[0m22:08:12.044272 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m22:08:12.045271 [debug] [MainThread]: On model.dbt_italy.stg_sales_customer: Close
[0m22:08:12.045271 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff097-f0c2-1de6-94c0-c7a8ccf2be2d) - Closing
[0m22:08:12.187058 [info ] [MainThread]: 
[0m22:08:12.189105 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 11.07 seconds (11.07s).
[0m22:08:12.191099 [debug] [MainThread]: Command end result
[0m22:08:12.241667 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m22:08:12.248661 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m22:08:12.258654 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m22:08:12.259653 [info ] [MainThread]: 
[0m22:08:12.260653 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:08:12.261653 [info ] [MainThread]: 
[0m22:08:12.263654 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:08:12.265651 [debug] [MainThread]: Command `dbt run` succeeded at 22:08:12.265651 after 14.02 seconds
[0m22:08:12.266650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257D2D4E110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257EF77BC40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000257D3276AA0>]}
[0m22:08:12.267650 [debug] [MainThread]: Flushing usage events
[0m22:08:12.869251 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:16:31.845509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227E9F5E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227EB9CE5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227EB9CE2F0>]}


============================== 22:16:31.849512 | 6729e397-ce7e-43d4-8027-a6af8f85a4dd ==============================
[0m22:16:31.849512 [info ] [MainThread]: Running with dbt=1.9.2
[0m22:16:31.851687 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m22:16:32.457708 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m22:16:32.458708 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m22:16:32.458708 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m22:16:33.365871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6729e397-ce7e-43d4-8027-a6af8f85a4dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227ECE6E320>]}
[0m22:16:33.407890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6729e397-ce7e-43d4-8027-a6af8f85a4dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227ED387610>]}
[0m22:16:33.408890 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m22:16:33.883369 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m22:16:33.970870 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m22:16:33.972852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6729e397-ce7e-43d4-8027-a6af8f85a4dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227EB2942B0>]}
[0m22:16:34.898701 [error] [MainThread]: Encountered an error:
Parsing Error
  at path ['schema']: None is not of type 'string'
[0m22:16:34.901924 [debug] [MainThread]: Command `dbt run` failed at 22:16:34.901924 after 3.22 seconds
[0m22:16:34.901924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227E9F5E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227866C4550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227866C5720>]}
[0m22:16:34.902922 [debug] [MainThread]: Flushing usage events
[0m22:16:35.460922 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:29:34.302115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235FF24E1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023580BCA620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023580BCA320>]}


============================== 22:29:34.307675 | 7c337f5b-bcd9-4689-9415-e4d77e0846cb ==============================
[0m22:29:34.307675 [info ] [MainThread]: Running with dbt=1.9.2
[0m22:29:34.308677 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:29:35.168937 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m22:29:35.169939 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m22:29:35.170936 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m22:29:36.608956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7c337f5b-bcd9-4689-9415-e4d77e0846cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235FCD5CEE0>]}
[0m22:29:36.646970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7c337f5b-bcd9-4689-9415-e4d77e0846cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023582057040>]}
[0m22:29:36.647972 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m22:29:37.076132 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m22:29:37.160524 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m22:29:37.161524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7c337f5b-bcd9-4689-9415-e4d77e0846cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235804942B0>]}
[0m22:29:38.105196 [error] [MainThread]: Encountered an error:
Parsing Error
  at path ['schema']: None is not of type 'string'
[0m22:29:38.107227 [debug] [MainThread]: Command `dbt run` failed at 22:29:38.107227 after 3.97 seconds
[0m22:29:38.108212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235FF24E1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002359B905720>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002359B905600>]}
[0m22:29:38.108212 [debug] [MainThread]: Flushing usage events
[0m22:29:38.806672 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:29:47.703252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A02B4E1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A044CA5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A044CA2F0>]}


============================== 22:29:47.706778 | 5e0d9605-e4e4-4d4d-918d-92d6149feda4 ==============================
[0m22:29:47.706778 [info ] [MainThread]: Running with dbt=1.9.2
[0m22:29:47.707777 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'dbt_italy', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m22:29:48.344475 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m22:29:48.345482 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m22:29:48.345482 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m22:29:49.223496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5e0d9605-e4e4-4d4d-918d-92d6149feda4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A01758EE0>]}
[0m22:29:49.263472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5e0d9605-e4e4-4d4d-918d-92d6149feda4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A05EC3130>]}
[0m22:29:49.264475 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m22:29:49.687438 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m22:29:49.903130 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m22:29:49.904637 [debug] [MainThread]: Partial parsing: added file: dbt_italy://macros\generate_schema_name.sql
[0m22:29:49.905647 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\stg_sales_customer.yml
[0m22:29:49.907644 [info ] [MainThread]: Unable to do partial parsing because change detected to override macro. Starting full parse.
[0m22:29:51.265128 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m22:29:51.280110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e0d9605-e4e4-4d4d-918d-92d6149feda4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A1F8CD360>]}
[0m22:29:51.364299 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m22:29:51.376077 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m22:29:51.415328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e0d9605-e4e4-4d4d-918d-92d6149feda4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A1EDF0EB0>]}
[0m22:29:51.416326 [info ] [MainThread]: Found 1 model, 2 data tests, 1 source, 608 macros
[0m22:29:51.417329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e0d9605-e4e4-4d4d-918d-92d6149feda4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A1EDF0E20>]}
[0m22:29:51.418325 [info ] [MainThread]: 
[0m22:29:51.419326 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:29:51.420328 [info ] [MainThread]: 
[0m22:29:51.421325 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(18024, 30744), compute-name=) - Creating connection
[0m22:29:51.422325 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m22:29:51.422325 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(18024, 30744), compute-name=) - Acquired connection on thread (18024, 30744), using default compute resource
[0m22:29:51.423890 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368778000, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(18024, 34616), compute-name=) - Creating connection
[0m22:29:51.423890 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m22:29:51.424941 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368778000, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(18024, 34616), compute-name=) - Acquired connection on thread (18024, 34616), using default compute resource
[0m22:29:51.425916 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368778000, session-id=None, name=list_bronze, idle-time=0.0009746551513671875s, acquire-count=1, language=None, thread-identifier=(18024, 34616), compute-name=) - Checking idleness
[0m22:29:51.426930 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368778000, session-id=None, name=list_bronze, idle-time=0.0019893646240234375s, acquire-count=1, language=None, thread-identifier=(18024, 34616), compute-name=) - Retrieving connection
[0m22:29:51.426930 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m22:29:51.427930 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m22:29:51.427930 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:29:52.074088 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff09a-fbf5-12e9-bee3-26bee8ebecda) - Created
[0m22:30:53.820668 [debug] [ThreadPool]: SQL status: OK in 62.390 seconds
[0m22:30:53.822668 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff09a-fbf5-12e9-bee3-26bee8ebecda, command-id=01eff09b-1fff-18da-a6cf-1c31f6337795) - Closing
[0m22:30:53.822668 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368778000, session-id=01eff09a-fbf5-12e9-bee3-26bee8ebecda, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(18024, 34616), compute-name=) - Released connection
[0m22:30:53.824666 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368769408, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(18024, 1976), compute-name=) - Creating connection
[0m22:30:53.825666 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m22:30:53.826664 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368769408, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(18024, 1976), compute-name=) - Acquired connection on thread (18024, 1976), using default compute resource
[0m22:30:53.833661 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368769408, session-id=None, name=list_bronze_sal, idle-time=0.007995843887329102s, acquire-count=1, language=None, thread-identifier=(18024, 1976), compute-name=) - Checking idleness
[0m22:30:53.833661 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368769408, session-id=None, name=list_bronze_sal, idle-time=0.007995843887329102s, acquire-count=1, language=None, thread-identifier=(18024, 1976), compute-name=) - Retrieving connection
[0m22:30:53.834664 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368769408, session-id=None, name=list_bronze_sal, idle-time=0.008998632431030273s, acquire-count=1, language=None, thread-identifier=(18024, 1976), compute-name=) - Checking idleness
[0m22:30:53.834664 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368769408, session-id=None, name=list_bronze_sal, idle-time=0.008998632431030273s, acquire-count=1, language=None, thread-identifier=(18024, 1976), compute-name=) - Retrieving connection
[0m22:30:53.835659 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m22:30:53.835659 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m22:30:53.836658 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m22:30:53.836658 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:30:54.166272 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff09b-2123-1f67-ada7-bb10728d7e3e) - Created
[0m22:30:55.630577 [debug] [ThreadPool]: SQL status: OK in 1.790 seconds
[0m22:30:55.642572 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff09b-2123-1f67-ada7-bb10728d7e3e, command-id=01eff09b-2133-1681-bb97-f78b6bff1632) - Closing
[0m22:30:55.642572 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2517368769408, session-id=01eff09b-2123-1f67-ada7-bb10728d7e3e, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(18024, 1976), compute-name=) - Released connection
[0m22:30:55.643569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e0d9605-e4e4-4d4d-918d-92d6149feda4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A1EDF3F10>]}
[0m22:30:55.644567 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=64.22224164009094s, acquire-count=1, language=None, thread-identifier=(18024, 30744), compute-name=) - Checking idleness
[0m22:30:55.644567 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=64.22224164009094s, acquire-count=1, language=None, thread-identifier=(18024, 30744), compute-name=) - Retrieving connection
[0m22:30:55.645567 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=64.22324204444885s, acquire-count=1, language=None, thread-identifier=(18024, 30744), compute-name=) - Checking idleness
[0m22:30:55.645567 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=64.22324204444885s, acquire-count=1, language=None, thread-identifier=(18024, 30744), compute-name=) - Retrieving connection
[0m22:30:55.646567 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m22:30:55.646567 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m22:30:55.647565 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(18024, 30744), compute-name=) - Released connection
[0m22:30:55.649460 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_sales_customer
[0m22:30:55.649969 [info ] [Thread-1 (]: 1 of 1 START sql incremental model bronze.sal.stg_sales_customer ............... [RUN]
[0m22:30:55.650974 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2517368771232, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(18024, 10624), compute-name=) - Creating connection
[0m22:30:55.651982 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_sales_customer'
[0m22:30:55.651982 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2517368771232, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(18024, 10624), compute-name=) - Acquired connection on thread (18024, 10624), using default compute resource for model '`bronze`.`sal`.`stg_sales_customer`'
[0m22:30:55.652979 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_sales_customer
[0m22:30:55.658972 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_sales_customer"
[0m22:30:55.660971 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_sales_customer
[0m22:30:55.740456 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_sales_customer"
[0m22:30:55.742453 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2517368771232, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.09047055244445801s, acquire-count=1, language=sql, thread-identifier=(18024, 10624), compute-name=) - Checking idleness
[0m22:30:55.743454 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2517368771232, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.09147167205810547s, acquire-count=1, language=sql, thread-identifier=(18024, 10624), compute-name=) - Retrieving connection
[0m22:30:55.744453 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2517368771232, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.09247064590454102s, acquire-count=1, language=sql, thread-identifier=(18024, 10624), compute-name=) - Checking idleness
[0m22:30:55.744453 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2517368771232, session-id=None, name=model.dbt_italy.stg_sales_customer, idle-time=0.09247064590454102s, acquire-count=1, language=sql, thread-identifier=(18024, 10624), compute-name=) - Retrieving connection
[0m22:30:55.745457 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m22:30:55.745457 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_sales_customer"
[0m22:30:55.746457 [debug] [Thread-1 (]: On model.dbt_italy.stg_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_sales_customer"} */

  
    
        create or replace table `bronze`.`sal`.`stg_sales_customer`
      
      using delta
      
      
      
      
      
      
      
      as
      


SELECT *
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m22:30:55.747457 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:30:56.062691 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff09b-2242-1eba-afe0-5fef660f0f0b) - Created
[0m22:31:13.752413 [debug] [Thread-1 (]: SQL status: OK in 18.000 seconds
[0m22:31:13.753405 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff09b-2242-1eba-afe0-5fef660f0f0b, command-id=01eff09b-2254-1824-8ccb-bda090702242) - Closing
[0m22:31:14.006676 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2517368771232, session-id=01eff09b-2242-1eba-afe0-5fef660f0f0b, name=model.dbt_italy.stg_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(18024, 10624), compute-name=) - Released connection
[0m22:31:14.007674 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2517368771232, session-id=01eff09b-2242-1eba-afe0-5fef660f0f0b, name=model.dbt_italy.stg_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(18024, 10624), compute-name=) - Released connection
[0m22:31:14.009670 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e0d9605-e4e4-4d4d-918d-92d6149feda4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A1F2E6860>]}
[0m22:31:14.010669 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model bronze.sal.stg_sales_customer .......... [[32mOK[0m in 18.36s]
[0m22:31:14.011670 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_sales_customer
[0m22:31:14.012668 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=18.365102291107178s, acquire-count=0, language=None, thread-identifier=(18024, 30744), compute-name=) - Checking idleness
[0m22:31:14.012668 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=18.365102291107178s, acquire-count=0, language=None, thread-identifier=(18024, 30744), compute-name=) - Reusing connection previously named master
[0m22:31:14.014175 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=18.365102291107178s, acquire-count=1, language=None, thread-identifier=(18024, 30744), compute-name=) - Acquired connection on thread (18024, 30744), using default compute resource
[0m22:31:14.014175 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=18.36660933494568s, acquire-count=1, language=None, thread-identifier=(18024, 30744), compute-name=) - Checking idleness
[0m22:31:14.014175 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=None, name=master, idle-time=18.36660933494568s, acquire-count=1, language=None, thread-identifier=(18024, 30744), compute-name=) - Retrieving connection
[0m22:31:14.015184 [debug] [MainThread]: On master: ROLLBACK
[0m22:31:14.015184 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:31:14.709730 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff09b-2d60-10f3-ba17-0125bba2b5f7) - Created
[0m22:31:14.710711 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m22:31:14.711704 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=01eff09b-2d60-10f3-ba17-0125bba2b5f7, name=master, idle-time=0.0009930133819580078s, acquire-count=1, language=None, thread-identifier=(18024, 30744), compute-name=) - Checking idleness
[0m22:31:14.711704 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=01eff09b-2d60-10f3-ba17-0125bba2b5f7, name=master, idle-time=0.0009930133819580078s, acquire-count=1, language=None, thread-identifier=(18024, 30744), compute-name=) - Retrieving connection
[0m22:31:14.712704 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m22:31:14.713702 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m22:31:14.713702 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2517368776176, session-id=01eff09b-2d60-10f3-ba17-0125bba2b5f7, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(18024, 30744), compute-name=) - Released connection
[0m22:31:14.714703 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:31:14.715707 [debug] [MainThread]: On master: ROLLBACK
[0m22:31:14.716845 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m22:31:14.716845 [debug] [MainThread]: On master: Close
[0m22:31:14.717879 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff09b-2d60-10f3-ba17-0125bba2b5f7) - Closing
[0m22:31:14.908345 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m22:31:14.909346 [debug] [MainThread]: On list_bronze: Close
[0m22:31:14.910347 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff09a-fbf5-12e9-bee3-26bee8ebecda) - Closing
[0m22:31:15.077625 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m22:31:15.078621 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m22:31:15.079621 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m22:31:15.079621 [debug] [MainThread]: On list_bronze_sal: Close
[0m22:31:15.080620 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff09b-2123-1f67-ada7-bb10728d7e3e) - Closing
[0m22:31:15.249965 [debug] [MainThread]: Connection 'model.dbt_italy.stg_sales_customer' was properly closed.
[0m22:31:15.250963 [debug] [MainThread]: On model.dbt_italy.stg_sales_customer: ROLLBACK
[0m22:31:15.251964 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m22:31:15.252961 [debug] [MainThread]: On model.dbt_italy.stg_sales_customer: Close
[0m22:31:15.253961 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff09b-2242-1eba-afe0-5fef660f0f0b) - Closing
[0m22:31:15.489708 [info ] [MainThread]: 
[0m22:31:15.490124 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 1 minutes and 24.07 seconds (84.07s).
[0m22:31:15.491137 [debug] [MainThread]: Command end result
[0m22:31:15.523655 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m22:31:15.526662 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m22:31:15.535655 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m22:31:15.536650 [info ] [MainThread]: 
[0m22:31:15.538653 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:31:15.539651 [info ] [MainThread]: 
[0m22:31:15.540651 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:31:15.542650 [debug] [MainThread]: Command `dbt run` succeeded at 22:31:15.542650 after 88.06 seconds
[0m22:31:15.543644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A02B4E1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A1F73D210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A03091750>]}
[0m22:31:15.544647 [debug] [MainThread]: Flushing usage events
[0m22:31:16.158303 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:18:21.129616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E3124E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E32BCA470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E32BCA770>]}


============================== 23:18:21.139616 | 9c9a9180-caf2-4106-a88f-e1461692495f ==============================
[0m23:18:21.139616 [info ] [MainThread]: Running with dbt=1.9.2
[0m23:18:21.140616 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'version_check': 'True', 'profiles_dir': 'dbt_italy', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:18:22.053574 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:18:22.054619 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:18:22.055639 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:18:23.385076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9c9a9180-caf2-4106-a88f-e1461692495f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E31381D50>]}
[0m23:18:23.423596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9c9a9180-caf2-4106-a88f-e1461692495f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E4CB7BCD0>]}
[0m23:18:23.424596 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m23:18:23.897728 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m23:18:24.175636 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 2 files added, 0 files changed.
[0m23:18:24.176637 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\bronze\stg_bakehouse_sales_customer.yml
[0m23:18:24.176637 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\bronze\stg_bakehouse_sales_customer.sql
[0m23:18:24.177639 [debug] [MainThread]: Partial parsing: deleted file: dbt_italy://models\bronze\stg_sales_customer.sql
[0m23:18:24.639701 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m23:18:24.652700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9c9a9180-caf2-4106-a88f-e1461692495f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E4DB7D4B0>]}
[0m23:18:24.744950 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:18:24.757777 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:18:24.796747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9c9a9180-caf2-4106-a88f-e1461692495f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E4DD909A0>]}
[0m23:18:24.797748 [info ] [MainThread]: Found 1 model, 2 data tests, 1 source, 608 macros
[0m23:18:24.798747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c9a9180-caf2-4106-a88f-e1461692495f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E4DD90910>]}
[0m23:18:24.800751 [info ] [MainThread]: 
[0m23:18:24.800751 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:18:24.801748 [info ] [MainThread]: 
[0m23:18:24.802747 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(22112, 34304), compute-name=) - Creating connection
[0m23:18:24.803747 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:18:24.804747 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(22112, 34304), compute-name=) - Acquired connection on thread (22112, 34304), using default compute resource
[0m23:18:24.805747 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775738800, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(22112, 35624), compute-name=) - Creating connection
[0m23:18:24.806746 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m23:18:24.807747 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775738800, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(22112, 35624), compute-name=) - Acquired connection on thread (22112, 35624), using default compute resource
[0m23:18:24.808748 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775738800, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(22112, 35624), compute-name=) - Checking idleness
[0m23:18:24.808748 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775738800, session-id=None, name=list_bronze, idle-time=0.0010008811950683594s, acquire-count=1, language=None, thread-identifier=(22112, 35624), compute-name=) - Retrieving connection
[0m23:18:24.809747 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m23:18:24.810746 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m23:18:24.810746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:18:25.243924 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a1-c43c-17df-a7cd-038e4b27408f) - Created
[0m23:18:25.768175 [debug] [ThreadPool]: SQL status: OK in 0.960 seconds
[0m23:18:25.769178 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a1-c43c-17df-a7cd-038e4b27408f, command-id=01eff0a1-c44a-1681-b25d-f98b83c0ccc2) - Closing
[0m23:18:25.770175 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775738800, session-id=01eff0a1-c43c-17df-a7cd-038e4b27408f, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(22112, 35624), compute-name=) - Released connection
[0m23:18:25.772176 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775725504, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(22112, 3108), compute-name=) - Creating connection
[0m23:18:25.773176 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m23:18:25.773176 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775725504, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(22112, 3108), compute-name=) - Acquired connection on thread (22112, 3108), using default compute resource
[0m23:18:25.781180 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775725504, session-id=None, name=list_bronze_sal, idle-time=0.008003711700439453s, acquire-count=1, language=None, thread-identifier=(22112, 3108), compute-name=) - Checking idleness
[0m23:18:25.782179 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775725504, session-id=None, name=list_bronze_sal, idle-time=0.009002685546875s, acquire-count=1, language=None, thread-identifier=(22112, 3108), compute-name=) - Retrieving connection
[0m23:18:25.783181 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775725504, session-id=None, name=list_bronze_sal, idle-time=0.010004997253417969s, acquire-count=1, language=None, thread-identifier=(22112, 3108), compute-name=) - Checking idleness
[0m23:18:25.783181 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775725504, session-id=None, name=list_bronze_sal, idle-time=0.010004997253417969s, acquire-count=1, language=None, thread-identifier=(22112, 3108), compute-name=) - Retrieving connection
[0m23:18:25.784178 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m23:18:25.784178 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m23:18:25.785179 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m23:18:25.785179 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:18:26.066990 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a1-c4bb-1697-9ac4-c23d2a59d36a) - Created
[0m23:18:26.842712 [debug] [ThreadPool]: SQL status: OK in 1.060 seconds
[0m23:18:26.852712 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a1-c4bb-1697-9ac4-c23d2a59d36a, command-id=01eff0a1-c4c7-1cc5-85e7-ca3ea1aa40ee) - Closing
[0m23:18:26.853712 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2672775725504, session-id=01eff0a1-c4bb-1697-9ac4-c23d2a59d36a, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(22112, 3108), compute-name=) - Released connection
[0m23:18:26.855713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c9a9180-caf2-4106-a88f-e1461692495f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E4DD902B0>]}
[0m23:18:26.856713 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=2.050966262817383s, acquire-count=1, language=None, thread-identifier=(22112, 34304), compute-name=) - Checking idleness
[0m23:18:26.856713 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=2.0519657135009766s, acquire-count=1, language=None, thread-identifier=(22112, 34304), compute-name=) - Retrieving connection
[0m23:18:26.857711 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=2.052964448928833s, acquire-count=1, language=None, thread-identifier=(22112, 34304), compute-name=) - Checking idleness
[0m23:18:26.857711 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=2.052964448928833s, acquire-count=1, language=None, thread-identifier=(22112, 34304), compute-name=) - Retrieving connection
[0m23:18:26.858714 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:18:26.859715 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:18:26.860712 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(22112, 34304), compute-name=) - Released connection
[0m23:18:26.864712 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:18:26.865713 [info ] [Thread-1 (]: 1 of 1 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m23:18:26.867713 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2672775726608, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(22112, 27700), compute-name=) - Creating connection
[0m23:18:26.867713 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m23:18:26.868713 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2672775726608, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(22112, 27700), compute-name=) - Acquired connection on thread (22112, 27700), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m23:18:26.869713 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:18:26.879718 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:18:26.882720 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:18:26.949887 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:18:26.952507 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2672775726608, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08379387855529785s, acquire-count=1, language=sql, thread-identifier=(22112, 27700), compute-name=) - Checking idleness
[0m23:18:26.952507 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2672775726608, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08379387855529785s, acquire-count=1, language=sql, thread-identifier=(22112, 27700), compute-name=) - Retrieving connection
[0m23:18:26.953531 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2672775726608, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08481836318969727s, acquire-count=1, language=sql, thread-identifier=(22112, 27700), compute-name=) - Checking idleness
[0m23:18:26.954529 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2672775726608, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08481836318969727s, acquire-count=1, language=sql, thread-identifier=(22112, 27700), compute-name=) - Retrieving connection
[0m23:18:26.954529 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m23:18:26.955528 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:18:26.956531 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_customer`
      
      using delta
      
      
      
      
      
      
      
      as
      


SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m23:18:26.957158 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:18:27.338095 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0a1-c579-1f43-8c7f-1a7e1293bf8e) - Created
[0m23:18:43.155671 [debug] [Thread-1 (]: SQL status: OK in 16.200 seconds
[0m23:18:43.157666 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a1-c579-1f43-8c7f-1a7e1293bf8e, command-id=01eff0a1-c58a-1f66-8eb6-0811879a9771) - Closing
[0m23:18:43.309001 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2672775726608, session-id=01eff0a1-c579-1f43-8c7f-1a7e1293bf8e, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(22112, 27700), compute-name=) - Released connection
[0m23:18:43.310997 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2672775726608, session-id=01eff0a1-c579-1f43-8c7f-1a7e1293bf8e, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(22112, 27700), compute-name=) - Released connection
[0m23:18:43.312993 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c9a9180-caf2-4106-a88f-e1461692495f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E34057F10>]}
[0m23:18:43.313988 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 16.44s]
[0m23:18:43.314986 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:18:43.316982 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=16.455275535583496s, acquire-count=0, language=None, thread-identifier=(22112, 34304), compute-name=) - Checking idleness
[0m23:18:43.316982 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=16.45626997947693s, acquire-count=0, language=None, thread-identifier=(22112, 34304), compute-name=) - Reusing connection previously named master
[0m23:18:43.317980 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=16.45626997947693s, acquire-count=1, language=None, thread-identifier=(22112, 34304), compute-name=) - Acquired connection on thread (22112, 34304), using default compute resource
[0m23:18:43.317980 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=16.45726728439331s, acquire-count=1, language=None, thread-identifier=(22112, 34304), compute-name=) - Checking idleness
[0m23:18:43.317980 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=None, name=master, idle-time=16.45726728439331s, acquire-count=1, language=None, thread-identifier=(22112, 34304), compute-name=) - Retrieving connection
[0m23:18:43.318976 [debug] [MainThread]: On master: ROLLBACK
[0m23:18:43.318976 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:18:43.622912 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a1-cf35-127e-984c-c7cf2ba4448e) - Created
[0m23:18:43.623909 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:18:43.624908 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=01eff0a1-cf35-127e-984c-c7cf2ba4448e, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(22112, 34304), compute-name=) - Checking idleness
[0m23:18:43.624908 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=01eff0a1-cf35-127e-984c-c7cf2ba4448e, name=master, idle-time=0.0009987354278564453s, acquire-count=1, language=None, thread-identifier=(22112, 34304), compute-name=) - Retrieving connection
[0m23:18:43.625905 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:18:43.625905 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:18:43.626904 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2672775730016, session-id=01eff0a1-cf35-127e-984c-c7cf2ba4448e, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(22112, 34304), compute-name=) - Released connection
[0m23:18:43.626904 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:18:43.627901 [debug] [MainThread]: On master: ROLLBACK
[0m23:18:43.627901 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:18:43.628901 [debug] [MainThread]: On master: Close
[0m23:18:43.628901 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a1-cf35-127e-984c-c7cf2ba4448e) - Closing
[0m23:18:43.760063 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m23:18:43.760936 [debug] [MainThread]: On list_bronze: Close
[0m23:18:43.761916 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a1-c43c-17df-a7cd-038e4b27408f) - Closing
[0m23:18:44.111294 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m23:18:44.112271 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m23:18:44.113287 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:18:44.113287 [debug] [MainThread]: On list_bronze_sal: Close
[0m23:18:44.114283 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a1-c4bb-1697-9ac4-c23d2a59d36a) - Closing
[0m23:18:44.279413 [debug] [MainThread]: Connection 'model.dbt_italy.stg_bakehouse_sales_customer' was properly closed.
[0m23:18:44.280412 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_customer: ROLLBACK
[0m23:18:44.280412 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:18:44.281395 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_customer: Close
[0m23:18:44.281395 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a1-c579-1f43-8c7f-1a7e1293bf8e) - Closing
[0m23:18:44.409472 [info ] [MainThread]: 
[0m23:18:44.410469 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 19.61 seconds (19.61s).
[0m23:18:44.411465 [debug] [MainThread]: Command end result
[0m23:18:44.439409 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:18:44.445390 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:18:44.460434 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m23:18:44.461431 [info ] [MainThread]: 
[0m23:18:44.463432 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:18:44.463432 [info ] [MainThread]: 
[0m23:18:44.464429 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:18:44.465425 [debug] [MainThread]: Command `dbt run` succeeded at 23:18:44.465425 after 23.55 seconds
[0m23:18:44.466425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E3124E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E4DD8F1F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026E313645E0>]}
[0m23:18:44.467422 [debug] [MainThread]: Flushing usage events
[0m23:18:45.107307 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:36:58.746244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F51324E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F514BCA5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F514BCA2F0>]}


============================== 23:36:58.751282 | 9142f436-50b4-4a4d-a14e-dae4270d4b0e ==============================
[0m23:36:58.751282 [info ] [MainThread]: Running with dbt=1.9.2
[0m23:36:58.752255 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'profiles_dir': 'dbt_italy', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:36:59.331522 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:36:59.332530 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:36:59.332530 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:37:00.199774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9142f436-50b4-4a4d-a14e-dae4270d4b0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F52E9368C0>]}
[0m23:37:00.237805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9142f436-50b4-4a4d-a14e-dae4270d4b0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F51605EBF0>]}
[0m23:37:00.238781 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m23:37:00.657101 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m23:37:00.864226 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 2 files changed.
[0m23:37:00.865227 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\bronze\stg_bakehouse_sales_franchises.sql
[0m23:37:00.866201 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\bronze\stg_bakehouse_sales_franchises.yml
[0m23:37:00.866201 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\_bronze__sources.yml
[0m23:37:00.867227 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\stg_bakehouse_sales_customer.sql
[0m23:37:01.318006 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m23:37:01.327863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9142f436-50b4-4a4d-a14e-dae4270d4b0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5144E8820>]}
[0m23:37:01.415692 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:37:01.417694 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:37:01.440702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9142f436-50b4-4a4d-a14e-dae4270d4b0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F52FDD2110>]}
[0m23:37:01.440702 [info ] [MainThread]: Found 2 models, 4 data tests, 2 sources, 608 macros
[0m23:37:01.441702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9142f436-50b4-4a4d-a14e-dae4270d4b0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F52FDD27D0>]}
[0m23:37:01.443704 [info ] [MainThread]: 
[0m23:37:01.443704 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:37:01.444959 [info ] [MainThread]: 
[0m23:37:01.445968 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(9200, 29672), compute-name=) - Creating connection
[0m23:37:01.445968 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:37:01.446978 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(9200, 29672), compute-name=) - Acquired connection on thread (9200, 29672), using default compute resource
[0m23:37:01.452153 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559924688, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(9200, 31208), compute-name=) - Creating connection
[0m23:37:01.453162 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m23:37:01.454162 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559924688, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(9200, 31208), compute-name=) - Acquired connection on thread (9200, 31208), using default compute resource
[0m23:37:01.455160 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559924688, session-id=None, name=list_bronze, idle-time=0.0009982585906982422s, acquire-count=1, language=None, thread-identifier=(9200, 31208), compute-name=) - Checking idleness
[0m23:37:01.457191 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559924688, session-id=None, name=list_bronze, idle-time=0.0030291080474853516s, acquire-count=1, language=None, thread-identifier=(9200, 31208), compute-name=) - Retrieving connection
[0m23:37:01.459163 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m23:37:01.461162 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m23:37:01.461162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:37:01.944384 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a4-5e36-1b37-8ecf-fa7649273b1e) - Created
[0m23:37:02.427687 [debug] [ThreadPool]: SQL status: OK in 0.970 seconds
[0m23:37:02.429688 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a4-5e36-1b37-8ecf-fa7649273b1e, command-id=01eff0a4-5e4b-19cb-b537-c43e39bda5f1) - Closing
[0m23:37:02.430689 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559924688, session-id=01eff0a4-5e36-1b37-8ecf-fa7649273b1e, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(9200, 31208), compute-name=) - Released connection
[0m23:37:02.432688 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559922000, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(9200, 424), compute-name=) - Creating connection
[0m23:37:02.432688 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m23:37:02.433691 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559922000, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(9200, 424), compute-name=) - Acquired connection on thread (9200, 424), using default compute resource
[0m23:37:02.441699 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559922000, session-id=None, name=list_bronze_sal, idle-time=0.008008003234863281s, acquire-count=1, language=None, thread-identifier=(9200, 424), compute-name=) - Checking idleness
[0m23:37:02.442702 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559922000, session-id=None, name=list_bronze_sal, idle-time=0.009010791778564453s, acquire-count=1, language=None, thread-identifier=(9200, 424), compute-name=) - Retrieving connection
[0m23:37:02.443701 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559922000, session-id=None, name=list_bronze_sal, idle-time=0.010010242462158203s, acquire-count=1, language=None, thread-identifier=(9200, 424), compute-name=) - Checking idleness
[0m23:37:02.443701 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559922000, session-id=None, name=list_bronze_sal, idle-time=0.010010242462158203s, acquire-count=1, language=None, thread-identifier=(9200, 424), compute-name=) - Retrieving connection
[0m23:37:02.443701 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m23:37:02.444698 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m23:37:02.444698 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m23:37:02.445716 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:37:02.732527 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a4-5eb4-1247-8673-8ce41c1000c4) - Created
[0m23:37:03.541054 [debug] [ThreadPool]: SQL status: OK in 1.090 seconds
[0m23:37:03.548079 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a4-5eb4-1247-8673-8ce41c1000c4, command-id=01eff0a4-5ec0-150a-bb1b-c5e53b2b708c) - Closing
[0m23:37:03.549064 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2152559922000, session-id=01eff0a4-5eb4-1247-8673-8ce41c1000c4, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(9200, 424), compute-name=) - Released connection
[0m23:37:03.550064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9142f436-50b4-4a4d-a14e-dae4270d4b0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5165B54B0>]}
[0m23:37:03.551061 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=2.1040830612182617s, acquire-count=1, language=None, thread-identifier=(9200, 29672), compute-name=) - Checking idleness
[0m23:37:03.551061 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=2.1040830612182617s, acquire-count=1, language=None, thread-identifier=(9200, 29672), compute-name=) - Retrieving connection
[0m23:37:03.552060 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=2.10508131980896s, acquire-count=1, language=None, thread-identifier=(9200, 29672), compute-name=) - Checking idleness
[0m23:37:03.552060 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=2.10508131980896s, acquire-count=1, language=None, thread-identifier=(9200, 29672), compute-name=) - Retrieving connection
[0m23:37:03.553064 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:37:03.553064 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:37:03.554062 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(9200, 29672), compute-name=) - Released connection
[0m23:37:03.556567 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:37:03.557578 [info ] [Thread-1 (]: 1 of 2 START sql append model bronze.sal.stg_bakehouse_sales_customer .......... [RUN]
[0m23:37:03.557945 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2152559927184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(9200, 16792), compute-name=) - Creating connection
[0m23:37:03.558963 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m23:37:03.558963 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2152559927184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(9200, 16792), compute-name=) - Acquired connection on thread (9200, 16792), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m23:37:03.559957 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:37:03.568958 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:37:03.571958 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:37:03.576984 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2152559927184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(9200, 16792), compute-name=) - Released connection
[0m23:37:03.581962 [debug] [Thread-1 (]: Compilation Error in model stg_bakehouse_sales_customer (models\bronze\stg_bakehouse_sales_customer.sql)
  No materialization 'append' was found for adapter databricks! (searched types 'default' and 'databricks')
[0m23:37:03.582960 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2152559927184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(9200, 16792), compute-name=) - Released connection
[0m23:37:03.584977 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9142f436-50b4-4a4d-a14e-dae4270d4b0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F52E91D1B0>]}
[0m23:37:03.585976 [error] [Thread-1 (]: 1 of 2 ERROR creating sql append model bronze.sal.stg_bakehouse_sales_customer . [[31mERROR[0m in 0.03s]
[0m23:37:03.588052 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:37:03.588052 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:37:03.589048 [debug] [Thread-4 (]: Marking all children of 'model.dbt_italy.stg_bakehouse_sales_customer' to be skipped because of status 'error'.  Reason: Compilation Error in model stg_bakehouse_sales_customer (models\bronze\stg_bakehouse_sales_customer.sql)
  No materialization 'append' was found for adapter databricks! (searched types 'default' and 'databricks').
[0m23:37:03.589048 [info ] [Thread-1 (]: 2 of 2 START sql append model bronze.sal.stg_bakehouse_sales_franchises ........ [RUN]
[0m23:37:03.591047 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2152559927184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.008086442947387695s, acquire-count=0, language=sql, thread-identifier=(9200, 16792), compute-name=) - Checking idleness
[0m23:37:03.591047 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m23:37:03.592048 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2152559927184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.00908803939819336s, acquire-count=0, language=sql, thread-identifier=(9200, 16792), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m23:37:03.593047 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2152559927184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.00908803939819336s, acquire-count=1, language=sql, thread-identifier=(9200, 16792), compute-name=) - Acquired connection on thread (9200, 16792), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m23:37:03.593047 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:37:03.601049 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:37:03.606060 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:37:03.610085 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2152559927184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(9200, 16792), compute-name=) - Released connection
[0m23:37:03.611064 [debug] [Thread-1 (]: Compilation Error in model stg_bakehouse_sales_franchises (models\bronze\stg_bakehouse_sales_franchises.sql)
  No materialization 'append' was found for adapter databricks! (searched types 'default' and 'databricks')
[0m23:37:03.613062 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2152559927184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(9200, 16792), compute-name=) - Released connection
[0m23:37:03.615063 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9142f436-50b4-4a4d-a14e-dae4270d4b0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F52FE097E0>]}
[0m23:37:03.617061 [error] [Thread-1 (]: 2 of 2 ERROR creating sql append model bronze.sal.stg_bakehouse_sales_franchises  [[31mERROR[0m in 0.02s]
[0m23:37:03.620065 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:37:03.621060 [debug] [Thread-4 (]: Marking all children of 'model.dbt_italy.stg_bakehouse_sales_franchises' to be skipped because of status 'error'.  Reason: Compilation Error in model stg_bakehouse_sales_franchises (models\bronze\stg_bakehouse_sales_franchises.sql)
  No materialization 'append' was found for adapter databricks! (searched types 'default' and 'databricks').
[0m23:37:03.623059 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=0.06800079345703125s, acquire-count=0, language=None, thread-identifier=(9200, 29672), compute-name=) - Checking idleness
[0m23:37:03.623059 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=0.06899738311767578s, acquire-count=0, language=None, thread-identifier=(9200, 29672), compute-name=) - Reusing connection previously named master
[0m23:37:03.624061 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=0.06999874114990234s, acquire-count=1, language=None, thread-identifier=(9200, 29672), compute-name=) - Acquired connection on thread (9200, 29672), using default compute resource
[0m23:37:03.625060 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=0.07099795341491699s, acquire-count=1, language=None, thread-identifier=(9200, 29672), compute-name=) - Checking idleness
[0m23:37:03.625060 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=None, name=master, idle-time=0.07099795341491699s, acquire-count=1, language=None, thread-identifier=(9200, 29672), compute-name=) - Retrieving connection
[0m23:37:03.626062 [debug] [MainThread]: On master: ROLLBACK
[0m23:37:03.626062 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:37:04.033292 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-5f77-1466-a903-863bdd419c2a) - Created
[0m23:37:04.034311 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:37:04.035278 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=01eff0a4-5f77-1466-a903-863bdd419c2a, name=master, idle-time=0.0009670257568359375s, acquire-count=1, language=None, thread-identifier=(9200, 29672), compute-name=) - Checking idleness
[0m23:37:04.036292 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=01eff0a4-5f77-1466-a903-863bdd419c2a, name=master, idle-time=0.0019805431365966797s, acquire-count=1, language=None, thread-identifier=(9200, 29672), compute-name=) - Retrieving connection
[0m23:37:04.036292 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:37:04.037291 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:37:04.037291 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2152581632240, session-id=01eff0a4-5f77-1466-a903-863bdd419c2a, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(9200, 29672), compute-name=) - Released connection
[0m23:37:04.038291 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:37:04.038291 [debug] [MainThread]: On master: ROLLBACK
[0m23:37:04.039303 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:37:04.039303 [debug] [MainThread]: On master: Close
[0m23:37:04.040303 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-5f77-1466-a903-863bdd419c2a) - Closing
[0m23:37:04.164851 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m23:37:04.165850 [debug] [MainThread]: On list_bronze: Close
[0m23:37:04.165850 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-5e36-1b37-8ecf-fa7649273b1e) - Closing
[0m23:37:04.300529 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m23:37:04.301530 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m23:37:04.302527 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:37:04.302527 [debug] [MainThread]: On list_bronze_sal: Close
[0m23:37:04.303521 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-5eb4-1247-8673-8ce41c1000c4) - Closing
[0m23:37:04.428013 [debug] [MainThread]: Connection 'model.dbt_italy.stg_bakehouse_sales_franchises' was properly closed.
[0m23:37:04.430027 [info ] [MainThread]: 
[0m23:37:04.432020 [info ] [MainThread]: Finished running 2 append models in 0 hours 0 minutes and 2.99 seconds (2.99s).
[0m23:37:04.433011 [debug] [MainThread]: Command end result
[0m23:37:04.469634 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:37:04.475696 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:37:04.482628 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m23:37:04.483627 [info ] [MainThread]: 
[0m23:37:04.484626 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m23:37:04.485626 [info ] [MainThread]: 
[0m23:37:04.486693 [error] [MainThread]:   Compilation Error in model stg_bakehouse_sales_customer (models\bronze\stg_bakehouse_sales_customer.sql)
  No materialization 'append' was found for adapter databricks! (searched types 'default' and 'databricks')
[0m23:37:04.487707 [info ] [MainThread]: 
[0m23:37:04.488203 [error] [MainThread]:   Compilation Error in model stg_bakehouse_sales_franchises (models\bronze\stg_bakehouse_sales_franchises.sql)
  No materialization 'append' was found for adapter databricks! (searched types 'default' and 'databricks')
[0m23:37:04.488719 [info ] [MainThread]: 
[0m23:37:04.489725 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=0 TOTAL=2
[0m23:37:04.491731 [debug] [MainThread]: Command `dbt run` failed at 23:37:04.490726 after 5.90 seconds
[0m23:37:04.491731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F51324E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F512C2D270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F52FB665F0>]}
[0m23:37:04.492725 [debug] [MainThread]: Flushing usage events
[0m23:37:05.086755 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:38:02.398106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDB64E1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDCFCA5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDCFCA2F0>]}


============================== 23:38:02.402104 | b6b1cb4b-813d-47f1-8f5d-d2e9e1000d4c ==============================
[0m23:38:02.402104 [info ] [MainThread]: Running with dbt=1.9.2
[0m23:38:02.403538 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'fail_fast': 'False', 'profiles_dir': 'dbt_italy', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:38:03.010948 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:38:03.010948 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:38:03.011949 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:38:03.900299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b6b1cb4b-813d-47f1-8f5d-d2e9e1000d4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDB4BAB60>]}
[0m23:38:03.945396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b6b1cb4b-813d-47f1-8f5d-d2e9e1000d4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFF6E8FB50>]}
[0m23:38:03.947400 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m23:38:04.397031 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m23:38:04.598142 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m23:38:04.598142 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\stg_bakehouse_sales_franchises.sql
[0m23:38:04.599143 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\stg_bakehouse_sales_customer.sql
[0m23:38:04.988492 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m23:38:04.999239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b6b1cb4b-813d-47f1-8f5d-d2e9e1000d4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFF7E5B040>]}
[0m23:38:05.085471 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:38:05.088473 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:38:05.110472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b6b1cb4b-813d-47f1-8f5d-d2e9e1000d4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDAED6470>]}
[0m23:38:05.111471 [info ] [MainThread]: Found 2 models, 4 data tests, 2 sources, 608 macros
[0m23:38:05.112474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b6b1cb4b-813d-47f1-8f5d-d2e9e1000d4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFF7ED9BA0>]}
[0m23:38:05.114475 [info ] [MainThread]: 
[0m23:38:05.114901 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:38:05.115913 [info ] [MainThread]: 
[0m23:38:05.115913 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29616, 32168), compute-name=) - Creating connection
[0m23:38:05.116913 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:38:05.116913 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29616, 32168), compute-name=) - Acquired connection on thread (29616, 32168), using default compute resource
[0m23:38:05.122918 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448024784, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29616, 34856), compute-name=) - Creating connection
[0m23:38:05.123914 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m23:38:05.123914 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448024784, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29616, 34856), compute-name=) - Acquired connection on thread (29616, 34856), using default compute resource
[0m23:38:05.124914 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448024784, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29616, 34856), compute-name=) - Checking idleness
[0m23:38:05.124914 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448024784, session-id=None, name=list_bronze, idle-time=0.0009999275207519531s, acquire-count=1, language=None, thread-identifier=(29616, 34856), compute-name=) - Retrieving connection
[0m23:38:05.125913 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m23:38:05.125913 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m23:38:05.126913 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:38:05.466335 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a4-8413-1ba3-b073-37883b4739c7) - Created
[0m23:38:05.905533 [debug] [ThreadPool]: SQL status: OK in 0.780 seconds
[0m23:38:05.907536 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a4-8413-1ba3-b073-37883b4739c7, command-id=01eff0a4-8422-1d26-b401-e8d10f5936d0) - Closing
[0m23:38:05.908534 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448024784, session-id=01eff0a4-8413-1ba3-b073-37883b4739c7, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29616, 34856), compute-name=) - Released connection
[0m23:38:05.910579 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448023056, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29616, 27772), compute-name=) - Creating connection
[0m23:38:05.910579 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m23:38:05.911593 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448023056, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29616, 27772), compute-name=) - Acquired connection on thread (29616, 27772), using default compute resource
[0m23:38:05.919596 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448023056, session-id=None, name=list_bronze_sal, idle-time=0.008002758026123047s, acquire-count=1, language=None, thread-identifier=(29616, 27772), compute-name=) - Checking idleness
[0m23:38:05.920595 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448023056, session-id=None, name=list_bronze_sal, idle-time=0.009001731872558594s, acquire-count=1, language=None, thread-identifier=(29616, 27772), compute-name=) - Retrieving connection
[0m23:38:05.921596 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448023056, session-id=None, name=list_bronze_sal, idle-time=0.010002613067626953s, acquire-count=1, language=None, thread-identifier=(29616, 27772), compute-name=) - Checking idleness
[0m23:38:05.921596 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448023056, session-id=None, name=list_bronze_sal, idle-time=0.010002613067626953s, acquire-count=1, language=None, thread-identifier=(29616, 27772), compute-name=) - Retrieving connection
[0m23:38:05.921596 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m23:38:05.922596 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m23:38:05.922596 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m23:38:05.923593 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:38:06.221353 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a4-8488-1125-bc3c-c905008d4adc) - Created
[0m23:38:07.106163 [debug] [ThreadPool]: SQL status: OK in 1.180 seconds
[0m23:38:07.113133 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a4-8488-1125-bc3c-c905008d4adc, command-id=01eff0a4-8496-1bbc-a59e-b92d6a4db2b0) - Closing
[0m23:38:07.113133 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2061448023056, session-id=01eff0a4-8488-1125-bc3c-c905008d4adc, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29616, 27772), compute-name=) - Released connection
[0m23:38:07.115147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b6b1cb4b-813d-47f1-8f5d-d2e9e1000d4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDA1C3FA0>]}
[0m23:38:07.116147 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=1.999234676361084s, acquire-count=1, language=None, thread-identifier=(29616, 32168), compute-name=) - Checking idleness
[0m23:38:07.116147 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=1.999234676361084s, acquire-count=1, language=None, thread-identifier=(29616, 32168), compute-name=) - Retrieving connection
[0m23:38:07.117131 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=2.000217914581299s, acquire-count=1, language=None, thread-identifier=(29616, 32168), compute-name=) - Checking idleness
[0m23:38:07.118134 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=2.001221179962158s, acquire-count=1, language=None, thread-identifier=(29616, 32168), compute-name=) - Retrieving connection
[0m23:38:07.118134 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:38:07.119131 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:38:07.119131 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29616, 32168), compute-name=) - Released connection
[0m23:38:07.122445 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:38:07.122445 [info ] [Thread-1 (]: 1 of 2 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m23:38:07.123462 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29616, 34864), compute-name=) - Creating connection
[0m23:38:07.124463 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m23:38:07.124463 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Acquired connection on thread (29616, 34864), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m23:38:07.125462 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:38:07.132463 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:07.135464 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:38:07.185468 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.060004234313964844s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Checking idleness
[0m23:38:07.186467 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.06200456619262695s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Retrieving connection
[0m23:38:07.186467 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.06200456619262695s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Checking idleness
[0m23:38:07.187468 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.06300520896911621s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Retrieving connection
[0m23:38:07.187468 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m23:38:07.187468 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:07.188974 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_customer'
  
[0m23:38:07.188974 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:38:07.495062 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0a4-854b-1c18-8ee7-817f17e90003) - Created
[0m23:38:08.040801 [debug] [Thread-1 (]: SQL status: OK in 0.850 seconds
[0m23:38:08.043815 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, command-id=01eff0a4-8558-1521-8835-50b400c25c14) - Closing
[0m23:38:08.047785 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.5517208576202393s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Checking idleness
[0m23:38:08.048805 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.552741289138794s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Retrieving connection
[0m23:38:08.048805 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:08.049801 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m23:38:08.467367 [debug] [Thread-1 (]: SQL status: OK in 0.420 seconds
[0m23:38:08.469364 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, command-id=01eff0a4-85ac-14c5-8cbc-307c3cd9023e) - Closing
[0m23:38:08.489517 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.993452787399292s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Checking idleness
[0m23:38:08.490518 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.9944539070129395s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Retrieving connection
[0m23:38:08.490518 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:08.491519 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    create or replace temporary view `stg_bakehouse_sales_customer__dbt_tmp` as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m23:38:11.542150 [debug] [Thread-1 (]: SQL status: OK in 3.050 seconds
[0m23:38:11.544151 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, command-id=01eff0a4-85f0-1c72-bc5e-98b0d9cfeaa1) - Closing
[0m23:38:11.571150 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.07508659362793s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Checking idleness
[0m23:38:11.572150 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.0760862827301025s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Retrieving connection
[0m23:38:11.573151 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:11.573151 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m23:38:11.911179 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m23:38:11.915173 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, command-id=01eff0a4-87c6-1ad0-b8f2-79acea13700c) - Closing
[0m23:38:11.921204 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.425140380859375s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Checking idleness
[0m23:38:11.922183 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.426119565963745s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Retrieving connection
[0m23:38:11.922183 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:11.923189 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `stg_bakehouse_sales_customer__dbt_tmp`
  
[0m23:38:12.274191 [debug] [Thread-1 (]: SQL status: OK in 0.350 seconds
[0m23:38:12.277193 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, command-id=01eff0a4-87fb-1ae2-9125-2c28a7dc02dd) - Closing
[0m23:38:12.288198 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:12.291199 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.795134782791138s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Checking idleness
[0m23:38:12.292199 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.796135425567627s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Retrieving connection
[0m23:38:12.293207 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:12.294197 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_customer` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_customer__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m23:38:17.781097 [debug] [Thread-1 (]: SQL status: OK in 5.490 seconds
[0m23:38:17.782106 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, command-id=01eff0a4-8833-1fe0-93d5-2573063bc945) - Closing
[0m23:38:17.926132 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29616, 34864), compute-name=) - Released connection
[0m23:38:17.927129 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29616, 34864), compute-name=) - Released connection
[0m23:38:17.929131 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6b1cb4b-813d-47f1-8f5d-d2e9e1000d4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDA13B1C0>]}
[0m23:38:17.930129 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 10.80s]
[0m23:38:17.932130 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:38:17.932130 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:38:17.933129 [info ] [Thread-1 (]: 2 of 2 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m23:38:17.934127 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.006997823715209961s, acquire-count=0, language=sql, thread-identifier=(29616, 34864), compute-name=) - Checking idleness
[0m23:38:17.935127 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m23:38:17.935127 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007998228073120117s, acquire-count=0, language=sql, thread-identifier=(29616, 34864), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m23:38:17.936129 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.008999824523925781s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Acquired connection on thread (29616, 34864), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m23:38:17.936129 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:38:17.940129 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:38:17.942134 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:38:17.975132 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:38:17.987119 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.059990644454956055s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Checking idleness
[0m23:38:17.988123 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.06099414825439453s, acquire-count=1, language=sql, thread-identifier=(29616, 34864), compute-name=) - Retrieving connection
[0m23:38:17.989121 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:38:17.989121 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m23:38:18.423451 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `franchiseID` cannot be resolved. Did you mean one of the following? [`address`, `city`, `continent`, `gender`, `customerID`]. SQLSTATE: 42703; line 19 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `franchiseID` cannot be resolved. Did you mean one of the following? [`address`, `city`, `continent`, `gender`, `customerID`]. SQLSTATE: 42703; line 19 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:837)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:659)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:504)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:724)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:504)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:91)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:195)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:617)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:729)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:738)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:617)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:615)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:71)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:481)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:467)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:517)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `franchiseID` cannot be resolved. Did you mean one of the following? [`address`, `city`, `continent`, `gender`, `customerID`]. SQLSTATE: 42703; line 19 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:807)
	... 43 more
, operation-id=01eff0a4-8b98-1ee2-80de-edbb6e748b99
[0m23:38:18.424458 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29616, 34864), compute-name=) - Released connection
[0m23:38:18.442045 [debug] [Thread-1 (]: Database Error in model stg_bakehouse_sales_franchises (models\bronze\stg_bakehouse_sales_franchises.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `franchiseID` cannot be resolved. Did you mean one of the following? [`address`, `city`, `continent`, `gender`, `customerID`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target\run\dbt_italy\models\bronze\stg_bakehouse_sales_franchises.sql
[0m23:38:18.443046 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2061448024112, session-id=01eff0a4-854b-1c18-8ee7-817f17e90003, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29616, 34864), compute-name=) - Released connection
[0m23:38:18.444067 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6b1cb4b-813d-47f1-8f5d-d2e9e1000d4c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDA1C3FA0>]}
[0m23:38:18.445073 [error] [Thread-1 (]: 2 of 2 ERROR creating sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[31mERROR[0m in 0.51s]
[0m23:38:18.446048 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:38:18.447064 [debug] [Thread-4 (]: Marking all children of 'model.dbt_italy.stg_bakehouse_sales_franchises' to be skipped because of status 'error'.  Reason: Database Error in model stg_bakehouse_sales_franchises (models\bronze\stg_bakehouse_sales_franchises.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `franchiseID` cannot be resolved. Did you mean one of the following? [`address`, `city`, `continent`, `gender`, `customerID`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target\run\dbt_italy\models\bronze\stg_bakehouse_sales_franchises.sql.
[0m23:38:18.448064 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=11.328933477401733s, acquire-count=0, language=None, thread-identifier=(29616, 32168), compute-name=) - Checking idleness
[0m23:38:18.449050 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=11.32991886138916s, acquire-count=0, language=None, thread-identifier=(29616, 32168), compute-name=) - Reusing connection previously named master
[0m23:38:18.449050 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=11.32991886138916s, acquire-count=1, language=None, thread-identifier=(29616, 32168), compute-name=) - Acquired connection on thread (29616, 32168), using default compute resource
[0m23:38:18.450050 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=11.33091950416565s, acquire-count=1, language=None, thread-identifier=(29616, 32168), compute-name=) - Checking idleness
[0m23:38:18.451047 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=None, name=master, idle-time=11.331915855407715s, acquire-count=1, language=None, thread-identifier=(29616, 32168), compute-name=) - Retrieving connection
[0m23:38:18.451047 [debug] [MainThread]: On master: ROLLBACK
[0m23:38:18.452055 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:38:18.802432 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-8c06-1a86-994f-e54f79870b68) - Created
[0m23:38:18.803430 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:38:18.804429 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=01eff0a4-8c06-1a86-994f-e54f79870b68, name=master, idle-time=0.0009989738464355469s, acquire-count=1, language=None, thread-identifier=(29616, 32168), compute-name=) - Checking idleness
[0m23:38:18.804429 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=01eff0a4-8c06-1a86-994f-e54f79870b68, name=master, idle-time=0.0009989738464355469s, acquire-count=1, language=None, thread-identifier=(29616, 32168), compute-name=) - Retrieving connection
[0m23:38:18.805429 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:38:18.805429 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:38:18.806428 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2061448292016, session-id=01eff0a4-8c06-1a86-994f-e54f79870b68, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29616, 32168), compute-name=) - Released connection
[0m23:38:18.806428 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:38:18.807429 [debug] [MainThread]: On master: ROLLBACK
[0m23:38:18.807429 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:38:18.808430 [debug] [MainThread]: On master: Close
[0m23:38:18.808430 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-8c06-1a86-994f-e54f79870b68) - Closing
[0m23:38:18.953164 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m23:38:18.954163 [debug] [MainThread]: On list_bronze: Close
[0m23:38:18.955164 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-8413-1ba3-b073-37883b4739c7) - Closing
[0m23:38:19.078681 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m23:38:19.079683 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m23:38:19.079683 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:38:19.080680 [debug] [MainThread]: On list_bronze_sal: Close
[0m23:38:19.081682 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-8488-1125-bc3c-c905008d4adc) - Closing
[0m23:38:19.214104 [debug] [MainThread]: Connection 'model.dbt_italy.stg_bakehouse_sales_franchises' was properly closed.
[0m23:38:19.216106 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_franchises: ROLLBACK
[0m23:38:19.216106 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:38:19.216106 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_franchises: Close
[0m23:38:19.217628 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-854b-1c18-8ee7-817f17e90003) - Closing
[0m23:38:19.358666 [info ] [MainThread]: 
[0m23:38:19.360076 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 14.24 seconds (14.24s).
[0m23:38:19.362087 [debug] [MainThread]: Command end result
[0m23:38:19.396483 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:38:19.403493 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:38:19.412491 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m23:38:19.412491 [info ] [MainThread]: 
[0m23:38:19.413723 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:38:19.414739 [info ] [MainThread]: 
[0m23:38:19.415737 [error] [MainThread]:   Database Error in model stg_bakehouse_sales_franchises (models\bronze\stg_bakehouse_sales_franchises.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `franchiseID` cannot be resolved. Did you mean one of the following? [`address`, `city`, `continent`, `gender`, `customerID`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target\run\dbt_italy\models\bronze\stg_bakehouse_sales_franchises.sql
[0m23:38:19.416742 [info ] [MainThread]: 
[0m23:38:19.418246 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m23:38:19.420255 [debug] [MainThread]: Command `dbt run` failed at 23:38:19.420255 after 17.18 seconds
[0m23:38:19.420255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDB64E1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDCF23790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFDAED4790>]}
[0m23:38:19.421255 [debug] [MainThread]: Flushing usage events
[0m23:38:20.089118 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:38:42.812925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E805E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E9ACA5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E9ACA2F0>]}


============================== 23:38:42.816924 | 9abfd2f9-3961-416e-874d-67599dd5b63e ==============================
[0m23:38:42.816924 [info ] [MainThread]: Running with dbt=1.9.2
[0m23:38:42.818211 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m23:38:43.414361 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:38:43.415364 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:38:43.416374 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:38:44.262133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9abfd2f9-3961-416e-874d-67599dd5b63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8EAF57A30>]}
[0m23:38:44.300133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9abfd2f9-3961-416e-874d-67599dd5b63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C88378BCA0>]}
[0m23:38:44.301133 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m23:38:44.733582 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m23:38:44.936460 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:38:44.937462 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\stg_bakehouse_sales_franchises.sql
[0m23:38:45.316930 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m23:38:45.328931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9abfd2f9-3961-416e-874d-67599dd5b63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8849AD180>]}
[0m23:38:45.407543 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:38:45.410545 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:38:45.434543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9abfd2f9-3961-416e-874d-67599dd5b63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C88493C8E0>]}
[0m23:38:45.434543 [info ] [MainThread]: Found 2 models, 4 data tests, 2 sources, 608 macros
[0m23:38:45.435544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9abfd2f9-3961-416e-874d-67599dd5b63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C884AA7E50>]}
[0m23:38:45.437544 [info ] [MainThread]: 
[0m23:38:45.437544 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:38:45.438529 [info ] [MainThread]: 
[0m23:38:45.439543 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(34660, 4460), compute-name=) - Creating connection
[0m23:38:45.439543 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:38:45.440546 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(34660, 4460), compute-name=) - Acquired connection on thread (34660, 4460), using default compute resource
[0m23:38:45.448684 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962452464208, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(34660, 5076), compute-name=) - Creating connection
[0m23:38:45.449696 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m23:38:45.450696 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962452464208, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(34660, 5076), compute-name=) - Acquired connection on thread (34660, 5076), using default compute resource
[0m23:38:45.450696 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962452464208, session-id=None, name=list_bronze, idle-time=0.0010006427764892578s, acquire-count=1, language=None, thread-identifier=(34660, 5076), compute-name=) - Checking idleness
[0m23:38:45.451706 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962452464208, session-id=None, name=list_bronze, idle-time=0.0020105838775634766s, acquire-count=1, language=None, thread-identifier=(34660, 5076), compute-name=) - Retrieving connection
[0m23:38:45.452702 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m23:38:45.452702 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m23:38:45.453696 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:38:45.774728 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a4-9c1b-18ff-abd9-1b0d0797195c) - Created
[0m23:38:46.031885 [debug] [ThreadPool]: SQL status: OK in 0.580 seconds
[0m23:38:46.033889 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a4-9c1b-18ff-abd9-1b0d0797195c, command-id=01eff0a4-9c28-19db-ba77-092d086b519c) - Closing
[0m23:38:46.034888 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962452464208, session-id=01eff0a4-9c1b-18ff-abd9-1b0d0797195c, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(34660, 5076), compute-name=) - Released connection
[0m23:38:46.036812 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962425051328, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(34660, 3180), compute-name=) - Creating connection
[0m23:38:46.036812 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m23:38:46.037823 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962425051328, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(34660, 3180), compute-name=) - Acquired connection on thread (34660, 3180), using default compute resource
[0m23:38:46.045824 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962425051328, session-id=None, name=list_bronze_sal, idle-time=0.008000850677490234s, acquire-count=1, language=None, thread-identifier=(34660, 3180), compute-name=) - Checking idleness
[0m23:38:46.046824 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962425051328, session-id=None, name=list_bronze_sal, idle-time=0.009000539779663086s, acquire-count=1, language=None, thread-identifier=(34660, 3180), compute-name=) - Retrieving connection
[0m23:38:46.046824 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962425051328, session-id=None, name=list_bronze_sal, idle-time=0.009000539779663086s, acquire-count=1, language=None, thread-identifier=(34660, 3180), compute-name=) - Checking idleness
[0m23:38:46.047823 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962425051328, session-id=None, name=list_bronze_sal, idle-time=0.009999990463256836s, acquire-count=1, language=None, thread-identifier=(34660, 3180), compute-name=) - Retrieving connection
[0m23:38:46.047823 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m23:38:46.047823 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m23:38:46.048829 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m23:38:46.048829 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:38:46.336737 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a4-9c70-1dec-9e56-2c8145af97c0) - Created
[0m23:38:47.022967 [debug] [ThreadPool]: SQL status: OK in 0.970 seconds
[0m23:38:47.028966 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a4-9c70-1dec-9e56-2c8145af97c0, command-id=01eff0a4-9c7d-184d-99f7-3021f0154a08) - Closing
[0m23:38:47.029969 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1962425051328, session-id=01eff0a4-9c70-1dec-9e56-2c8145af97c0, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(34660, 3180), compute-name=) - Released connection
[0m23:38:47.030964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9abfd2f9-3961-416e-874d-67599dd5b63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C88493CE80>]}
[0m23:38:47.031964 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=1.5914177894592285s, acquire-count=1, language=None, thread-identifier=(34660, 4460), compute-name=) - Checking idleness
[0m23:38:47.032967 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=1.592421531677246s, acquire-count=1, language=None, thread-identifier=(34660, 4460), compute-name=) - Retrieving connection
[0m23:38:47.032967 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=1.592421531677246s, acquire-count=1, language=None, thread-identifier=(34660, 4460), compute-name=) - Checking idleness
[0m23:38:47.033962 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=1.5934159755706787s, acquire-count=1, language=None, thread-identifier=(34660, 4460), compute-name=) - Retrieving connection
[0m23:38:47.033962 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:38:47.034963 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:38:47.034963 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(34660, 4460), compute-name=) - Released connection
[0m23:38:47.037964 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:38:47.038965 [info ] [Thread-1 (]: 1 of 2 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m23:38:47.039965 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(34660, 18520), compute-name=) - Creating connection
[0m23:38:47.039965 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m23:38:47.040964 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Acquired connection on thread (34660, 18520), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m23:38:47.041969 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:38:47.050977 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:47.053975 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:38:47.114494 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.07352972030639648s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Checking idleness
[0m23:38:47.115496 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.07453107833862305s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Retrieving connection
[0m23:38:47.116495 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0755302906036377s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Checking idleness
[0m23:38:47.117494 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.07652950286865234s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Retrieving connection
[0m23:38:47.118495 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m23:38:47.118495 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:47.119495 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_customer'
  
[0m23:38:47.119495 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:38:47.407834 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd) - Created
[0m23:38:47.802777 [debug] [Thread-1 (]: SQL status: OK in 0.680 seconds
[0m23:38:47.804773 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, command-id=01eff0a4-9d20-1ae8-bf19-1ffbdd0b93d6) - Closing
[0m23:38:47.810786 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.40195584297180176s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Checking idleness
[0m23:38:47.811776 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.40294504165649414s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Retrieving connection
[0m23:38:47.812775 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:47.812775 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m23:38:48.108858 [debug] [Thread-1 (]: SQL status: OK in 0.300 seconds
[0m23:38:48.111839 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, command-id=01eff0a4-9d5e-1fa1-b7aa-98e8b18ae6a4) - Closing
[0m23:38:48.121869 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.7120399475097656s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Checking idleness
[0m23:38:48.121869 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.7130389213562012s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Retrieving connection
[0m23:38:48.122851 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:48.122851 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    create or replace temporary view `stg_bakehouse_sales_customer__dbt_tmp` as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m23:38:48.647399 [debug] [Thread-1 (]: SQL status: OK in 0.520 seconds
[0m23:38:48.649402 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, command-id=01eff0a4-9d8e-14d6-9b61-7224ee0be539) - Closing
[0m23:38:48.669977 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.2611470222473145s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Checking idleness
[0m23:38:48.669977 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.2611470222473145s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Retrieving connection
[0m23:38:48.670999 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:48.670999 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m23:38:49.280140 [debug] [Thread-1 (]: SQL status: OK in 0.610 seconds
[0m23:38:49.283148 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, command-id=01eff0a4-9e13-14cb-830e-71ef49d2e93f) - Closing
[0m23:38:49.286146 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.8773152828216553s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Checking idleness
[0m23:38:49.287145 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.87831449508667s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Retrieving connection
[0m23:38:49.287145 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:49.288145 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `stg_bakehouse_sales_customer__dbt_tmp`
  
[0m23:38:49.560998 [debug] [Thread-1 (]: SQL status: OK in 0.270 seconds
[0m23:38:49.562997 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, command-id=01eff0a4-9e3f-1ec4-91af-3bc03252be44) - Closing
[0m23:38:49.571501 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:49.574510 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=2.1646785736083984s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Checking idleness
[0m23:38:49.574510 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=2.1656792163848877s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Retrieving connection
[0m23:38:49.575511 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:38:49.576509 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_customer` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_customer__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m23:38:54.219832 [debug] [Thread-1 (]: SQL status: OK in 4.640 seconds
[0m23:38:54.221832 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, command-id=01eff0a4-9e6c-11ce-b442-338717f27898) - Closing
[0m23:38:54.240860 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(34660, 18520), compute-name=) - Released connection
[0m23:38:54.241835 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(34660, 18520), compute-name=) - Released connection
[0m23:38:54.243850 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9abfd2f9-3961-416e-874d-67599dd5b63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C88497AAA0>]}
[0m23:38:54.243850 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 7.20s]
[0m23:38:54.245860 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:38:54.245860 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:38:54.246837 [info ] [Thread-1 (]: 2 of 2 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m23:38:54.247624 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0057888031005859375s, acquire-count=0, language=sql, thread-identifier=(34660, 18520), compute-name=) - Checking idleness
[0m23:38:54.248640 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m23:38:54.248640 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.006804704666137695s, acquire-count=0, language=sql, thread-identifier=(34660, 18520), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m23:38:54.249637 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007802009582519531s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Acquired connection on thread (34660, 18520), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m23:38:54.249637 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:38:54.256637 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:38:54.260651 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:38:54.294178 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:38:54.297180 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.054346561431884766s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Checking idleness
[0m23:38:54.298181 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.05634570121765137s, acquire-count=1, language=sql, thread-identifier=(34660, 18520), compute-name=) - Retrieving connection
[0m23:38:54.299182 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:38:54.299182 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m23:39:02.748692 [debug] [Thread-1 (]: SQL status: OK in 8.450 seconds
[0m23:39:02.750690 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, command-id=01eff0a4-a140-12a4-aa17-21217f0ff551) - Closing
[0m23:39:02.883633 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(34660, 18520), compute-name=) - Released connection
[0m23:39:02.884637 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1962425054976, session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(34660, 18520), compute-name=) - Released connection
[0m23:39:02.885635 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9abfd2f9-3961-416e-874d-67599dd5b63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C884CDEDA0>]}
[0m23:39:02.886632 [info ] [Thread-1 (]: 2 of 2 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 8.64s]
[0m23:39:02.887628 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:39:02.889171 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=15.854207754135132s, acquire-count=0, language=None, thread-identifier=(34660, 4460), compute-name=) - Checking idleness
[0m23:39:02.890186 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=15.855222940444946s, acquire-count=0, language=None, thread-identifier=(34660, 4460), compute-name=) - Reusing connection previously named master
[0m23:39:02.891185 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=15.855222940444946s, acquire-count=1, language=None, thread-identifier=(34660, 4460), compute-name=) - Acquired connection on thread (34660, 4460), using default compute resource
[0m23:39:02.891185 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=15.856221199035645s, acquire-count=1, language=None, thread-identifier=(34660, 4460), compute-name=) - Checking idleness
[0m23:39:02.892185 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=None, name=master, idle-time=15.856221199035645s, acquire-count=1, language=None, thread-identifier=(34660, 4460), compute-name=) - Retrieving connection
[0m23:39:02.892185 [debug] [MainThread]: On master: ROLLBACK
[0m23:39:02.892185 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:39:03.258727 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-a67e-1127-9b35-4a8dce34a76d) - Created
[0m23:39:03.259727 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:39:03.260726 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=01eff0a4-a67e-1127-9b35-4a8dce34a76d, name=master, idle-time=0.0009989738464355469s, acquire-count=1, language=None, thread-identifier=(34660, 4460), compute-name=) - Checking idleness
[0m23:39:03.260726 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=01eff0a4-a67e-1127-9b35-4a8dce34a76d, name=master, idle-time=0.0009989738464355469s, acquire-count=1, language=None, thread-identifier=(34660, 4460), compute-name=) - Retrieving connection
[0m23:39:03.261732 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:39:03.261732 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:39:03.262730 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1960729364896, session-id=01eff0a4-a67e-1127-9b35-4a8dce34a76d, name=master, idle-time=0.0009980201721191406s, acquire-count=0, language=None, thread-identifier=(34660, 4460), compute-name=) - Released connection
[0m23:39:03.262730 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:39:03.263727 [debug] [MainThread]: On master: ROLLBACK
[0m23:39:03.263727 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:39:03.263727 [debug] [MainThread]: On master: Close
[0m23:39:03.264724 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-a67e-1127-9b35-4a8dce34a76d) - Closing
[0m23:39:03.664917 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m23:39:03.665920 [debug] [MainThread]: On list_bronze: Close
[0m23:39:03.666930 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-9c1b-18ff-abd9-1b0d0797195c) - Closing
[0m23:39:03.799517 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m23:39:03.800514 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m23:39:03.800514 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:39:03.801499 [debug] [MainThread]: On list_bronze_sal: Close
[0m23:39:03.801499 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-9c70-1dec-9e56-2c8145af97c0) - Closing
[0m23:39:03.936645 [debug] [MainThread]: Connection 'model.dbt_italy.stg_bakehouse_sales_franchises' was properly closed.
[0m23:39:03.938647 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_franchises: ROLLBACK
[0m23:39:03.939644 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:39:03.939644 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_franchises: Close
[0m23:39:03.940645 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a4-9d14-1f6d-aac7-6feff03effbd) - Closing
[0m23:39:04.071976 [info ] [MainThread]: 
[0m23:39:04.073876 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 18.63 seconds (18.63s).
[0m23:39:04.074876 [debug] [MainThread]: Command end result
[0m23:39:04.114934 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:39:04.118932 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:39:04.130931 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m23:39:04.131931 [info ] [MainThread]: 
[0m23:39:04.132932 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:39:04.133933 [info ] [MainThread]: 
[0m23:39:04.134932 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m23:39:04.136945 [debug] [MainThread]: Command `dbt run` succeeded at 23:39:04.136438 after 21.48 seconds
[0m23:39:04.136945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E805E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E6D26770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E8667CA0>]}
[0m23:39:04.138459 [debug] [MainThread]: Flushing usage events
[0m23:39:04.758351 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:45:18.054705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CA514E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CA6ACE5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CA6ACE2F0>]}


============================== 23:45:18.058706 | c5a144d1-32bf-4a4f-b66a-3e4420c31373 ==============================
[0m23:45:18.058706 [info ] [MainThread]: Running with dbt=1.9.2
[0m23:45:18.059338 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --full-refresh', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m23:45:18.648497 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:45:18.650003 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:45:18.650003 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:45:19.478932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c5a144d1-32bf-4a4f-b66a-3e4420c31373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CC0A252A0>]}
[0m23:45:19.523933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c5a144d1-32bf-4a4f-b66a-3e4420c31373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CC0A83700>]}
[0m23:45:19.524932 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m23:45:19.997622 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m23:45:20.244264 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m23:45:20.245264 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\bronze\stg_bakehouse_sales_transaction.sql
[0m23:45:20.245264 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\bronze\stg_bakehouse_sales_transaction.yml
[0m23:45:20.575821 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m23:45:20.588823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c5a144d1-32bf-4a4f-b66a-3e4420c31373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CC1A57A60>]}
[0m23:45:20.685760 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:45:20.688760 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:45:20.712758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c5a144d1-32bf-4a4f-b66a-3e4420c31373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CC1A540D0>]}
[0m23:45:20.713760 [info ] [MainThread]: Found 3 models, 4 data tests, 2 sources, 608 macros
[0m23:45:20.714043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c5a144d1-32bf-4a4f-b66a-3e4420c31373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CC1A56F20>]}
[0m23:45:20.715073 [info ] [MainThread]: 
[0m23:45:20.716264 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:45:20.716973 [info ] [MainThread]: 
[0m23:45:20.718000 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(35008, 31776), compute-name=) - Creating connection
[0m23:45:20.718000 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:45:20.719000 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(35008, 31776), compute-name=) - Acquired connection on thread (35008, 31776), using default compute resource
[0m23:45:20.728984 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=None, name=list_workspace, idle-time=0s, acquire-count=0, language=None, thread-identifier=(35008, 27220), compute-name=) - Creating connection
[0m23:45:20.728984 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m23:45:20.730000 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=None, name=list_workspace, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(35008, 27220), compute-name=) - Acquired connection on thread (35008, 27220), using default compute resource
[0m23:45:20.730984 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=None, name=list_workspace, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(35008, 27220), compute-name=) - Checking idleness
[0m23:45:20.730984 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=None, name=list_workspace, idle-time=0.0009849071502685547s, acquire-count=1, language=None, thread-identifier=(35008, 27220), compute-name=) - Retrieving connection
[0m23:45:20.731987 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m23:45:20.731987 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m23:45:20.733005 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:45:21.132732 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa) - Created
[0m23:45:21.671480 [debug] [ThreadPool]: SQL status: OK in 0.940 seconds
[0m23:45:21.673478 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa, command-id=01eff0a5-87c5-1d73-9351-c8f4510af95f) - Closing
[0m23:45:21.674483 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa, name=list_workspace, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(35008, 27220), compute-name=) - Released connection
[0m23:45:21.675480 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa, name=list_workspace, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(35008, 27220), compute-name=) - Checking idleness
[0m23:45:21.675480 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_workspace, now list_bronze)
[0m23:45:21.675480 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa, name=list_bronze, idle-time=0.0009970664978027344s, acquire-count=0, language=None, thread-identifier=(35008, 27220), compute-name=) - Reusing connection previously named list_workspace
[0m23:45:21.676477 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa, name=list_bronze, idle-time=0.0019943714141845703s, acquire-count=1, language=None, thread-identifier=(35008, 27220), compute-name=) - Acquired connection on thread (35008, 27220), using default compute resource
[0m23:45:21.676477 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa, name=list_bronze, idle-time=0.0019943714141845703s, acquire-count=1, language=None, thread-identifier=(35008, 27220), compute-name=) - Checking idleness
[0m23:45:21.677479 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa, name=list_bronze, idle-time=0.0029959678649902344s, acquire-count=1, language=None, thread-identifier=(35008, 27220), compute-name=) - Retrieving connection
[0m23:45:21.677479 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m23:45:21.678479 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m23:45:21.990750 [debug] [ThreadPool]: SQL status: OK in 0.310 seconds
[0m23:45:21.992754 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa, command-id=01eff0a5-8814-1a58-83e4-76a3e3621126) - Closing
[0m23:45:21.993752 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897561792, session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(35008, 27220), compute-name=) - Released connection
[0m23:45:21.994751 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(35008, 35148), compute-name=) - Creating connection
[0m23:45:21.995754 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m23:45:21.995754 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(35008, 35148), compute-name=) - Acquired connection on thread (35008, 35148), using default compute resource
[0m23:45:22.003751 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=None, name=list_bronze_sal, idle-time=0.007997274398803711s, acquire-count=1, language=None, thread-identifier=(35008, 35148), compute-name=) - Checking idleness
[0m23:45:22.004758 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=None, name=list_bronze_sal, idle-time=0.009003639221191406s, acquire-count=1, language=None, thread-identifier=(35008, 35148), compute-name=) - Retrieving connection
[0m23:45:22.004758 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=None, name=list_bronze_sal, idle-time=0.009003639221191406s, acquire-count=1, language=None, thread-identifier=(35008, 35148), compute-name=) - Checking idleness
[0m23:45:22.005767 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=None, name=list_bronze_sal, idle-time=0.01001286506652832s, acquire-count=1, language=None, thread-identifier=(35008, 35148), compute-name=) - Retrieving connection
[0m23:45:22.005767 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m23:45:22.006754 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m23:45:22.006754 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m23:45:22.006754 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:45:22.308839 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a5-8866-1b15-9be5-865a12f56b28) - Created
[0m23:45:23.044461 [debug] [ThreadPool]: SQL status: OK in 1.040 seconds
[0m23:45:23.051333 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a5-8866-1b15-9be5-865a12f56b28, command-id=01eff0a5-8875-1537-a9a1-ec1825c94dce) - Closing
[0m23:45:23.059908 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=01eff0a5-8866-1b15-9be5-865a12f56b28, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(35008, 35148), compute-name=) - Released connection
[0m23:45:23.061906 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=01eff0a5-8866-1b15-9be5-865a12f56b28, name=list_bronze_sal, idle-time=0.0009992122650146484s, acquire-count=0, language=None, thread-identifier=(35008, 35148), compute-name=) - Checking idleness
[0m23:45:23.062907 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_bronze_sal, now list_workspace_default)
[0m23:45:23.062907 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=01eff0a5-8866-1b15-9be5-865a12f56b28, name=list_workspace_default, idle-time=0.002998828887939453s, acquire-count=0, language=None, thread-identifier=(35008, 35148), compute-name=) - Reusing connection previously named list_bronze_sal
[0m23:45:23.062907 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=01eff0a5-8866-1b15-9be5-865a12f56b28, name=list_workspace_default, idle-time=0.002998828887939453s, acquire-count=1, language=None, thread-identifier=(35008, 35148), compute-name=) - Acquired connection on thread (35008, 35148), using default compute resource
[0m23:45:23.065907 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=01eff0a5-8866-1b15-9be5-865a12f56b28, name=list_workspace_default, idle-time=0.005999088287353516s, acquire-count=1, language=None, thread-identifier=(35008, 35148), compute-name=) - Checking idleness
[0m23:45:23.066908 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=01eff0a5-8866-1b15-9be5-865a12f56b28, name=list_workspace_default, idle-time=0.0069997310638427734s, acquire-count=1, language=None, thread-identifier=(35008, 35148), compute-name=) - Retrieving connection
[0m23:45:23.066908 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m23:45:23.067906 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_workspace_default"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'workspace'
      and table_schema = 'default'
    
  
[0m23:45:23.466525 [debug] [ThreadPool]: SQL status: OK in 0.400 seconds
[0m23:45:23.469539 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a5-8866-1b15-9be5-865a12f56b28, command-id=01eff0a5-88e8-1ec9-8d2e-9993c3faa678) - Closing
[0m23:45:23.470514 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1497897553056, session-id=01eff0a5-8866-1b15-9be5-865a12f56b28, name=list_workspace_default, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(35008, 35148), compute-name=) - Released connection
[0m23:45:23.471526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c5a144d1-32bf-4a4f-b66a-3e4420c31373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CC1A6E440>]}
[0m23:45:23.471526 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=2.7525265216827393s, acquire-count=1, language=None, thread-identifier=(35008, 31776), compute-name=) - Checking idleness
[0m23:45:23.472558 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=2.7535581588745117s, acquire-count=1, language=None, thread-identifier=(35008, 31776), compute-name=) - Retrieving connection
[0m23:45:23.473540 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=2.754539728164673s, acquire-count=1, language=None, thread-identifier=(35008, 31776), compute-name=) - Checking idleness
[0m23:45:23.473540 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=2.754539728164673s, acquire-count=1, language=None, thread-identifier=(35008, 31776), compute-name=) - Retrieving connection
[0m23:45:23.474540 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:45:23.474540 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:45:23.475539 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(35008, 31776), compute-name=) - Released connection
[0m23:45:23.478170 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:45:23.479182 [info ] [Thread-1 (]: 1 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m23:45:23.480182 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(35008, 16764), compute-name=) - Creating connection
[0m23:45:23.481183 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m23:45:23.481183 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Acquired connection on thread (35008, 16764), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m23:45:23.482198 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:45:23.488212 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:45:23.490195 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:45:23.559485 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:45:23.562485 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08030509948730469s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Checking idleness
[0m23:45:23.562485 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08130121231079102s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Retrieving connection
[0m23:45:23.563484 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08230090141296387s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Checking idleness
[0m23:45:23.563484 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08230090141296387s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Retrieving connection
[0m23:45:23.564504 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m23:45:23.564504 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:45:23.565483 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_customer`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m23:45:23.565483 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:45:23.854576 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0a5-8955-1c75-9c1a-bf0210052629) - Created
[0m23:45:29.905420 [debug] [Thread-1 (]: SQL status: OK in 6.340 seconds
[0m23:45:29.907422 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, command-id=01eff0a5-8961-1022-bb34-5fa7abc11813) - Closing
[0m23:45:30.051598 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(35008, 16764), compute-name=) - Released connection
[0m23:45:30.053583 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(35008, 16764), compute-name=) - Released connection
[0m23:45:30.055583 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5a144d1-32bf-4a4f-b66a-3e4420c31373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CA3D3B190>]}
[0m23:45:30.056584 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 6.57s]
[0m23:45:30.058572 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:45:30.058572 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:45:30.059591 [info ] [Thread-1 (]: 2 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m23:45:30.060414 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.006830930709838867s, acquire-count=0, language=sql, thread-identifier=(35008, 16764), compute-name=) - Checking idleness
[0m23:45:30.061432 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m23:45:30.061432 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007848739624023438s, acquire-count=0, language=sql, thread-identifier=(35008, 16764), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m23:45:30.062431 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007848739624023438s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Acquired connection on thread (35008, 16764), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m23:45:30.062431 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:45:30.066441 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:45:30.068441 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:45:30.076455 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:45:30.080057 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.026473283767700195s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Checking idleness
[0m23:45:30.081074 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.02749013900756836s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Retrieving connection
[0m23:45:30.081074 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:45:30.082087 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m23:45:33.406887 [debug] [Thread-1 (]: SQL status: OK in 3.320 seconds
[0m23:45:33.408875 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, command-id=01eff0a5-8d17-1aca-a200-7f30f0c0fda0) - Closing
[0m23:45:33.410889 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(35008, 16764), compute-name=) - Released connection
[0m23:45:33.410889 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(35008, 16764), compute-name=) - Released connection
[0m23:45:33.411872 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5a144d1-32bf-4a4f-b66a-3e4420c31373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CA3D3B190>]}
[0m23:45:33.412898 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 3.35s]
[0m23:45:33.414879 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:45:33.415873 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_transaction
[0m23:45:33.415873 [info ] [Thread-1 (]: 3 of 3 START sql incremental model default.stg_bakehouse_sales_transaction ..... [RUN]
[0m23:45:33.416869 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.005980014801025391s, acquire-count=0, language=sql, thread-identifier=(35008, 16764), compute-name=) - Checking idleness
[0m23:45:33.417876 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_franchises, now model.dbt_italy.stg_bakehouse_sales_transaction)
[0m23:45:33.417876 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_transaction, idle-time=0.006987094879150391s, acquire-count=0, language=sql, thread-identifier=(35008, 16764), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:45:33.418871 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_transaction, idle-time=0.007982492446899414s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Acquired connection on thread (35008, 16764), using default compute resource for model '`workspace`.`default`.`stg_bakehouse_sales_transaction`'
[0m23:45:33.418871 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_transaction
[0m23:45:33.423875 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_transaction"
[0m23:45:33.425872 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_transaction
[0m23:45:33.429873 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_transaction"
[0m23:45:33.441342 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_transaction, idle-time=0.028379440307617188s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Checking idleness
[0m23:45:33.442336 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_transaction, idle-time=0.031447410583496094s, acquire-count=1, language=sql, thread-identifier=(35008, 16764), compute-name=) - Retrieving connection
[0m23:45:33.443335 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transaction"
[0m23:45:33.444349 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transaction: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transaction"} */

  
    
        create or replace table `workspace`.`default`.`stg_bakehouse_sales_transaction`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`

  
[0m23:45:33.969835 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transaction"} */

  
    
        create or replace table `workspace`.`default`.`stg_bakehouse_sales_transaction`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`

  
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:837)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:659)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:504)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:724)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:504)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:91)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:195)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:617)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:729)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:738)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:617)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:615)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:71)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:481)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:467)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:517)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:807)
	... 43 more
, operation-id=01eff0a5-8f18-177f-ac85-4c0eefce8e20
[0m23:45:33.970836 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_transaction, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(35008, 16764), compute-name=) - Released connection
[0m23:45:33.976842 [debug] [Thread-1 (]: Database Error in model stg_bakehouse_sales_transaction (models\bronze\stg_bakehouse_sales_transaction.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
  compiled code at target\run\dbt_italy\models\bronze\stg_bakehouse_sales_transaction.sql
[0m23:45:33.977843 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1497888835088, session-id=01eff0a5-8955-1c75-9c1a-bf0210052629, name=model.dbt_italy.stg_bakehouse_sales_transaction, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(35008, 16764), compute-name=) - Released connection
[0m23:45:33.977843 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c5a144d1-32bf-4a4f-b66a-3e4420c31373', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CA3D3B190>]}
[0m23:45:33.978844 [error] [Thread-1 (]: 3 of 3 ERROR creating sql incremental model default.stg_bakehouse_sales_transaction  [[31mERROR[0m in 0.56s]
[0m23:45:33.980839 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_transaction
[0m23:45:33.981836 [debug] [Thread-4 (]: Marking all children of 'model.dbt_italy.stg_bakehouse_sales_transaction' to be skipped because of status 'error'.  Reason: Database Error in model stg_bakehouse_sales_transaction (models\bronze\stg_bakehouse_sales_transaction.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
  compiled code at target\run\dbt_italy\models\bronze\stg_bakehouse_sales_transaction.sql.
[0m23:45:33.982834 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=10.50729489326477s, acquire-count=0, language=None, thread-identifier=(35008, 31776), compute-name=) - Checking idleness
[0m23:45:33.983835 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=10.508296251296997s, acquire-count=0, language=None, thread-identifier=(35008, 31776), compute-name=) - Reusing connection previously named master
[0m23:45:33.983835 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=10.508296251296997s, acquire-count=1, language=None, thread-identifier=(35008, 31776), compute-name=) - Acquired connection on thread (35008, 31776), using default compute resource
[0m23:45:33.984834 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=10.509294986724854s, acquire-count=1, language=None, thread-identifier=(35008, 31776), compute-name=) - Checking idleness
[0m23:45:33.984834 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=None, name=master, idle-time=10.509294986724854s, acquire-count=1, language=None, thread-identifier=(35008, 31776), compute-name=) - Retrieving connection
[0m23:45:33.985834 [debug] [MainThread]: On master: ROLLBACK
[0m23:45:33.985834 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:45:34.504943 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a5-8f8b-1ec4-ad04-963811a25f11) - Created
[0m23:45:34.505949 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:45:34.506947 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=01eff0a5-8f8b-1ec4-ad04-963811a25f11, name=master, idle-time=0.0009984970092773438s, acquire-count=1, language=None, thread-identifier=(35008, 31776), compute-name=) - Checking idleness
[0m23:45:34.506947 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=01eff0a5-8f8b-1ec4-ad04-963811a25f11, name=master, idle-time=0.0009984970092773438s, acquire-count=1, language=None, thread-identifier=(35008, 31776), compute-name=) - Retrieving connection
[0m23:45:34.507931 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:45:34.507931 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:45:34.508947 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1497897458928, session-id=01eff0a5-8f8b-1ec4-ad04-963811a25f11, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(35008, 31776), compute-name=) - Released connection
[0m23:45:34.508947 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:45:34.509947 [debug] [MainThread]: On master: ROLLBACK
[0m23:45:34.509947 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:45:34.510946 [debug] [MainThread]: On master: Close
[0m23:45:34.510946 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a5-8f8b-1ec4-ad04-963811a25f11) - Closing
[0m23:45:34.632333 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m23:45:34.633333 [debug] [MainThread]: On list_bronze: Close
[0m23:45:34.633333 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a5-87b2-18e9-8417-722b7d6142fa) - Closing
[0m23:45:34.763474 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m23:45:34.764475 [debug] [MainThread]: On list_workspace_default: ROLLBACK
[0m23:45:34.764475 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:45:34.765468 [debug] [MainThread]: On list_workspace_default: Close
[0m23:45:34.765468 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a5-8866-1b15-9be5-865a12f56b28) - Closing
[0m23:45:34.912477 [debug] [MainThread]: Connection 'model.dbt_italy.stg_bakehouse_sales_transaction' was properly closed.
[0m23:45:34.913475 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_transaction: ROLLBACK
[0m23:45:34.914472 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:45:34.915472 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_transaction: Close
[0m23:45:34.915472 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a5-8955-1c75-9c1a-bf0210052629) - Closing
[0m23:45:35.039085 [info ] [MainThread]: 
[0m23:45:35.040073 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 14.32 seconds (14.32s).
[0m23:45:35.042175 [debug] [MainThread]: Command end result
[0m23:45:35.076631 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:45:35.082630 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:45:35.093266 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m23:45:35.094299 [info ] [MainThread]: 
[0m23:45:35.095282 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:45:35.096280 [info ] [MainThread]: 
[0m23:45:35.096280 [error] [MainThread]:   Database Error in model stg_bakehouse_sales_transaction (models\bronze\stg_bakehouse_sales_transaction.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
  compiled code at target\run\dbt_italy\models\bronze\stg_bakehouse_sales_transaction.sql
[0m23:45:35.098283 [info ] [MainThread]: 
[0m23:45:35.099279 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m23:45:35.101292 [debug] [MainThread]: Command `dbt run` failed at 23:45:35.100283 after 17.21 seconds
[0m23:45:35.101292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CA514E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CA5664580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015CC0A3B2B0>]}
[0m23:45:35.102284 [debug] [MainThread]: Flushing usage events
[0m23:45:35.775076 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:49:03.625400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAB934E140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DABACCA5C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DABACCA2C0>]}


============================== 23:49:03.630402 | 76649dac-06ba-49d8-a27f-2d49f8a620ad ==============================
[0m23:49:03.630402 [info ] [MainThread]: Running with dbt=1.9.2
[0m23:49:03.632671 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --full-refresh', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:49:04.357203 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:49:04.358203 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:49:04.359203 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:49:05.363912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '76649dac-06ba-49d8-a27f-2d49f8a620ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAD4C87310>]}
[0m23:49:05.400912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '76649dac-06ba-49d8-a27f-2d49f8a620ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAD4C87CD0>]}
[0m23:49:05.401912 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m23:49:05.845180 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m23:49:06.071591 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 2 files added, 2 files changed.
[0m23:49:06.072592 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\bronze\stg_bakehouse_sales_transactions.sql
[0m23:49:06.073592 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\bronze\stg_bakehouse_sales_transactions.yml
[0m23:49:06.074564 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\stg_bakehouse_sales_customer.yml
[0m23:49:06.075592 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\stg_bakehouse_sales_franchises.yml
[0m23:49:06.076592 [debug] [MainThread]: Partial parsing: deleted file: dbt_italy://models\bronze\stg_bakehouse_sales_transaction.sql
[0m23:49:06.489002 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m23:49:06.501581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '76649dac-06ba-49d8-a27f-2d49f8a620ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAD5DABDF0>]}
[0m23:49:06.588032 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:49:06.591031 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:49:06.616032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '76649dac-06ba-49d8-a27f-2d49f8a620ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAD5DAACB0>]}
[0m23:49:06.617033 [info ] [MainThread]: Found 3 models, 6 data tests, 2 sources, 608 macros
[0m23:49:06.617736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '76649dac-06ba-49d8-a27f-2d49f8a620ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAD5DAABF0>]}
[0m23:49:06.619747 [info ] [MainThread]: 
[0m23:49:06.620749 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:49:06.621539 [info ] [MainThread]: 
[0m23:49:06.622553 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(32976, 7812), compute-name=) - Creating connection
[0m23:49:06.623552 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:49:06.624553 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(32976, 7812), compute-name=) - Acquired connection on thread (32976, 7812), using default compute resource
[0m23:49:06.633056 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401005744, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(32976, 3568), compute-name=) - Creating connection
[0m23:49:06.634072 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m23:49:06.635071 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401005744, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(32976, 3568), compute-name=) - Acquired connection on thread (32976, 3568), using default compute resource
[0m23:49:06.636087 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401005744, session-id=None, name=list_bronze, idle-time=0.0010161399841308594s, acquire-count=1, language=None, thread-identifier=(32976, 3568), compute-name=) - Checking idleness
[0m23:49:06.636087 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401005744, session-id=None, name=list_bronze, idle-time=0.0010161399841308594s, acquire-count=1, language=None, thread-identifier=(32976, 3568), compute-name=) - Retrieving connection
[0m23:49:06.637069 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m23:49:06.637069 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m23:49:06.638070 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:49:06.976594 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a6-0e4a-16d8-8139-5ebb10632d81) - Created
[0m23:49:07.273888 [debug] [ThreadPool]: SQL status: OK in 0.640 seconds
[0m23:49:07.275889 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a6-0e4a-16d8-8139-5ebb10632d81, command-id=01eff0a6-0e58-198d-960d-7273fc2dd82f) - Closing
[0m23:49:07.276888 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401005744, session-id=01eff0a6-0e4a-16d8-8139-5ebb10632d81, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(32976, 3568), compute-name=) - Released connection
[0m23:49:07.277886 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401052432, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(32976, 3612), compute-name=) - Creating connection
[0m23:49:07.278886 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m23:49:07.278886 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401052432, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(32976, 3612), compute-name=) - Acquired connection on thread (32976, 3612), using default compute resource
[0m23:49:07.286917 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401052432, session-id=None, name=list_bronze_sal, idle-time=0.008031368255615234s, acquire-count=1, language=None, thread-identifier=(32976, 3612), compute-name=) - Checking idleness
[0m23:49:07.287895 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401052432, session-id=None, name=list_bronze_sal, idle-time=0.009009122848510742s, acquire-count=1, language=None, thread-identifier=(32976, 3612), compute-name=) - Retrieving connection
[0m23:49:07.287895 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401052432, session-id=None, name=list_bronze_sal, idle-time=0.009009122848510742s, acquire-count=1, language=None, thread-identifier=(32976, 3612), compute-name=) - Checking idleness
[0m23:49:07.288894 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401052432, session-id=None, name=list_bronze_sal, idle-time=0.009009122848510742s, acquire-count=1, language=None, thread-identifier=(32976, 3612), compute-name=) - Retrieving connection
[0m23:49:07.288894 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m23:49:07.288894 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m23:49:07.289903 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m23:49:07.289903 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:49:07.577713 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a6-0ea4-1eb0-916a-5f32c1239dc7) - Created
[0m23:49:08.179402 [debug] [ThreadPool]: SQL status: OK in 0.890 seconds
[0m23:49:08.186416 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a6-0ea4-1eb0-916a-5f32c1239dc7, command-id=01eff0a6-0eb4-1050-a52c-02a39f722de8) - Closing
[0m23:49:08.186416 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2039401052432, session-id=01eff0a6-0ea4-1eb0-916a-5f32c1239dc7, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(32976, 3612), compute-name=) - Released connection
[0m23:49:08.188408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '76649dac-06ba-49d8-a27f-2d49f8a620ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAB6FCBFA0>]}
[0m23:49:08.189397 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=1.5648436546325684s, acquire-count=1, language=None, thread-identifier=(32976, 7812), compute-name=) - Checking idleness
[0m23:49:08.189397 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=1.5648436546325684s, acquire-count=1, language=None, thread-identifier=(32976, 7812), compute-name=) - Retrieving connection
[0m23:49:08.190396 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=1.5658433437347412s, acquire-count=1, language=None, thread-identifier=(32976, 7812), compute-name=) - Checking idleness
[0m23:49:08.190396 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=1.5658433437347412s, acquire-count=1, language=None, thread-identifier=(32976, 7812), compute-name=) - Retrieving connection
[0m23:49:08.191397 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:49:08.191397 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:49:08.192396 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(32976, 7812), compute-name=) - Released connection
[0m23:49:08.195206 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:49:08.195206 [info ] [Thread-1 (]: 1 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m23:49:08.196217 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(32976, 31540), compute-name=) - Creating connection
[0m23:49:08.197223 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m23:49:08.197223 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Acquired connection on thread (32976, 31540), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m23:49:08.198221 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:49:08.205223 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:49:08.207219 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:49:08.280776 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:49:08.283774 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08655142784118652s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Checking idleness
[0m23:49:08.284774 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08655142784118652s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Retrieving connection
[0m23:49:08.284774 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08755183219909668s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Checking idleness
[0m23:49:08.285774 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08855175971984863s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Retrieving connection
[0m23:49:08.285774 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m23:49:08.286773 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:49:08.286773 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_customer`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m23:49:08.287773 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:49:08.560443 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0a6-0f3d-176b-a284-245431aabf2b) - Created
[0m23:49:13.665657 [debug] [Thread-1 (]: SQL status: OK in 5.380 seconds
[0m23:49:13.667657 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, command-id=01eff0a6-0f49-13f2-9380-455762d85d28) - Closing
[0m23:49:13.687163 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(32976, 31540), compute-name=) - Released connection
[0m23:49:13.688162 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(32976, 31540), compute-name=) - Released connection
[0m23:49:13.690163 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76649dac-06ba-49d8-a27f-2d49f8a620ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAB6F3B160>]}
[0m23:49:13.691163 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 5.49s]
[0m23:49:13.692761 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:49:13.692761 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:49:13.693760 [info ] [Thread-1 (]: 2 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m23:49:13.694756 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.006593942642211914s, acquire-count=0, language=sql, thread-identifier=(32976, 31540), compute-name=) - Checking idleness
[0m23:49:13.695767 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m23:49:13.696757 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0076045989990234375s, acquire-count=0, language=sql, thread-identifier=(32976, 31540), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m23:49:13.696757 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.008594274520874023s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Acquired connection on thread (32976, 31540), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m23:49:13.697778 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:49:13.700785 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:49:13.702766 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:49:13.705786 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:49:13.707760 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.018596887588500977s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Checking idleness
[0m23:49:13.707760 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.019598007202148438s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Retrieving connection
[0m23:49:13.707760 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:49:13.708760 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m23:49:17.219916 [debug] [Thread-1 (]: SQL status: OK in 3.510 seconds
[0m23:49:17.220917 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, command-id=01eff0a6-125a-1c86-b1e5-b37d27852b43) - Closing
[0m23:49:17.222915 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(32976, 31540), compute-name=) - Released connection
[0m23:49:17.222915 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(32976, 31540), compute-name=) - Released connection
[0m23:49:17.223903 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76649dac-06ba-49d8-a27f-2d49f8a620ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAB8F2D0F0>]}
[0m23:49:17.224914 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 3.53s]
[0m23:49:17.225884 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:49:17.226902 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:49:17.226902 [info ] [Thread-1 (]: 3 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_transactions . [RUN]
[0m23:49:17.227901 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.004985332489013672s, acquire-count=0, language=sql, thread-identifier=(32976, 31540), compute-name=) - Checking idleness
[0m23:49:17.228902 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_franchises, now model.dbt_italy.stg_bakehouse_sales_transactions)
[0m23:49:17.228902 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.005986213684082031s, acquire-count=0, language=sql, thread-identifier=(32976, 31540), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:49:17.229888 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.006972789764404297s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Acquired connection on thread (32976, 31540), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_transactions`'
[0m23:49:17.229888 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:49:17.233916 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:49:17.235900 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:49:17.238901 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:49:17.250234 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.027318239212036133s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Checking idleness
[0m23:49:17.252235 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.029319047927856445s, acquire-count=1, language=sql, thread-identifier=(32976, 31540), compute-name=) - Retrieving connection
[0m23:49:17.252235 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:49:17.253232 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_transactions`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`

  
[0m23:49:17.650133 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_transactions`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`

  
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:837)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:659)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:504)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:724)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:504)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:91)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:195)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:617)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:729)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:738)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:617)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:615)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:71)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:481)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:467)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:517)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:807)
	... 43 more
, operation-id=01eff0a6-1477-19d1-ab86-f1b03f8e7840
[0m23:49:17.652151 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(32976, 31540), compute-name=) - Released connection
[0m23:49:17.658162 [debug] [Thread-1 (]: Database Error in model stg_bakehouse_sales_transactions (models\bronze\stg_bakehouse_sales_transactions.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
  compiled code at target\run\dbt_italy\models\bronze\stg_bakehouse_sales_transactions.sql
[0m23:49:17.658162 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2039403761712, session-id=01eff0a6-0f3d-176b-a284-245431aabf2b, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(32976, 31540), compute-name=) - Released connection
[0m23:49:17.659162 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76649dac-06ba-49d8-a27f-2d49f8a620ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAD5EE9270>]}
[0m23:49:17.660162 [error] [Thread-1 (]: 3 of 3 ERROR creating sql incremental model bronze.sal.stg_bakehouse_sales_transactions  [[31mERROR[0m in 0.43s]
[0m23:49:17.660873 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:49:17.661890 [debug] [Thread-4 (]: Marking all children of 'model.dbt_italy.stg_bakehouse_sales_transactions' to be skipped because of status 'error'.  Reason: Database Error in model stg_bakehouse_sales_transactions (models\bronze\stg_bakehouse_sales_transactions.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
  compiled code at target\run\dbt_italy\models\bronze\stg_bakehouse_sales_transactions.sql.
[0m23:49:17.663886 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=9.471489191055298s, acquire-count=0, language=None, thread-identifier=(32976, 7812), compute-name=) - Checking idleness
[0m23:49:17.664894 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=9.47249722480774s, acquire-count=0, language=None, thread-identifier=(32976, 7812), compute-name=) - Reusing connection previously named master
[0m23:49:17.665887 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=9.47249722480774s, acquire-count=1, language=None, thread-identifier=(32976, 7812), compute-name=) - Acquired connection on thread (32976, 7812), using default compute resource
[0m23:49:17.665887 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=9.473490953445435s, acquire-count=1, language=None, thread-identifier=(32976, 7812), compute-name=) - Checking idleness
[0m23:49:17.665887 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=None, name=master, idle-time=9.473490953445435s, acquire-count=1, language=None, thread-identifier=(32976, 7812), compute-name=) - Retrieving connection
[0m23:49:17.666887 [debug] [MainThread]: On master: ROLLBACK
[0m23:49:17.667896 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:49:18.019448 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-14dd-13e4-885a-62d1bb2d519a) - Created
[0m23:49:18.020448 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:49:18.021446 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=01eff0a6-14dd-13e4-885a-62d1bb2d519a, name=master, idle-time=0.0009984970092773438s, acquire-count=1, language=None, thread-identifier=(32976, 7812), compute-name=) - Checking idleness
[0m23:49:18.021446 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=01eff0a6-14dd-13e4-885a-62d1bb2d519a, name=master, idle-time=0.0009984970092773438s, acquire-count=1, language=None, thread-identifier=(32976, 7812), compute-name=) - Retrieving connection
[0m23:49:18.022445 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:49:18.022445 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:49:18.023455 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2039402379296, session-id=01eff0a6-14dd-13e4-885a-62d1bb2d519a, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(32976, 7812), compute-name=) - Released connection
[0m23:49:18.023455 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:49:18.024453 [debug] [MainThread]: On master: ROLLBACK
[0m23:49:18.024453 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:49:18.024453 [debug] [MainThread]: On master: Close
[0m23:49:18.025446 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-14dd-13e4-885a-62d1bb2d519a) - Closing
[0m23:49:18.146937 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m23:49:18.148934 [debug] [MainThread]: On list_bronze: Close
[0m23:49:18.148934 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-0e4a-16d8-8139-5ebb10632d81) - Closing
[0m23:49:18.289039 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m23:49:18.290025 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m23:49:18.290025 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:49:18.291022 [debug] [MainThread]: On list_bronze_sal: Close
[0m23:49:18.291022 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-0ea4-1eb0-916a-5f32c1239dc7) - Closing
[0m23:49:18.427348 [debug] [MainThread]: Connection 'model.dbt_italy.stg_bakehouse_sales_transactions' was properly closed.
[0m23:49:18.429348 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_transactions: ROLLBACK
[0m23:49:18.429348 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:49:18.430349 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_transactions: Close
[0m23:49:18.431347 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-0f3d-176b-a284-245431aabf2b) - Closing
[0m23:49:18.567391 [info ] [MainThread]: 
[0m23:49:18.568389 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 11.94 seconds (11.94s).
[0m23:49:18.570397 [debug] [MainThread]: Command end result
[0m23:49:18.613935 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:49:18.619922 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:49:18.628918 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m23:49:18.629921 [info ] [MainThread]: 
[0m23:49:18.630932 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m23:49:18.631932 [info ] [MainThread]: 
[0m23:49:18.632931 [error] [MainThread]:   Database Error in model stg_bakehouse_sales_transactions (models\bronze\stg_bakehouse_sales_transactions.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `transactionID` cannot be resolved. Did you mean one of the following? [`franchiseID`, `city`, `district`, `latitude`, `longitude`]. SQLSTATE: 42703; line 19 pos 4
  compiled code at target\run\dbt_italy\models\bronze\stg_bakehouse_sales_transactions.sql
[0m23:49:18.634925 [info ] [MainThread]: 
[0m23:49:18.635918 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m23:49:18.639434 [debug] [MainThread]: Command `dbt run` failed at 23:49:18.638427 after 15.19 seconds
[0m23:49:18.640449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAB934E140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAD5C3A980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DAD60027D0>]}
[0m23:49:18.641487 [debug] [MainThread]: Flushing usage events
[0m23:49:19.336570 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:49:54.000130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D4A04E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D4B9CE5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D4B9CE2F0>]}


============================== 23:49:54.006149 | cc0d29ca-1ae2-4119-8091-b30d6d54d811 ==============================
[0m23:49:54.006149 [info ] [MainThread]: Running with dbt=1.9.2
[0m23:49:54.007148 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --full-refresh', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:49:54.691661 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:49:54.692666 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:49:54.692666 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:49:55.563514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cc0d29ca-1ae2-4119-8091-b30d6d54d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D48C58F10>]}
[0m23:49:55.601514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cc0d29ca-1ae2-4119-8091-b30d6d54d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D4CF62980>]}
[0m23:49:55.602515 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m23:49:56.002300 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m23:49:56.214755 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m23:49:56.215756 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\_bronze__sources.yml
[0m23:49:56.216733 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\stg_bakehouse_sales_transactions.sql
[0m23:49:56.671886 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m23:49:56.681886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cc0d29ca-1ae2-4119-8091-b30d6d54d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D66B5FEE0>]}
[0m23:49:56.768914 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:49:56.772915 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:49:56.797914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cc0d29ca-1ae2-4119-8091-b30d6d54d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D66BF5750>]}
[0m23:49:56.798915 [info ] [MainThread]: Found 3 models, 6 data tests, 3 sources, 608 macros
[0m23:49:56.799890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cc0d29ca-1ae2-4119-8091-b30d6d54d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D66BF5810>]}
[0m23:49:56.800915 [info ] [MainThread]: 
[0m23:49:56.801916 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:49:56.802914 [info ] [MainThread]: 
[0m23:49:56.803916 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(34196, 35648), compute-name=) - Creating connection
[0m23:49:56.803916 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:49:56.804915 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(34196, 35648), compute-name=) - Acquired connection on thread (34196, 35648), using default compute resource
[0m23:49:56.810914 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384043456, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(34196, 6848), compute-name=) - Creating connection
[0m23:49:56.810914 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m23:49:56.811914 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384043456, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(34196, 6848), compute-name=) - Acquired connection on thread (34196, 6848), using default compute resource
[0m23:49:56.811914 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384043456, session-id=None, name=list_bronze, idle-time=0.0009999275207519531s, acquire-count=1, language=None, thread-identifier=(34196, 6848), compute-name=) - Checking idleness
[0m23:49:56.812914 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384043456, session-id=None, name=list_bronze, idle-time=0.0009999275207519531s, acquire-count=1, language=None, thread-identifier=(34196, 6848), compute-name=) - Retrieving connection
[0m23:49:56.812914 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m23:49:56.813915 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m23:49:56.813915 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:49:57.180155 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a6-2c35-1e9e-ab1a-91cc79713c18) - Created
[0m23:49:57.428347 [debug] [ThreadPool]: SQL status: OK in 0.610 seconds
[0m23:49:57.430370 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a6-2c35-1e9e-ab1a-91cc79713c18, command-id=01eff0a6-2c42-1da3-82ed-527344a7aeec) - Closing
[0m23:49:57.431359 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384043456, session-id=01eff0a6-2c35-1e9e-ab1a-91cc79713c18, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(34196, 6848), compute-name=) - Released connection
[0m23:49:57.433337 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384039376, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(34196, 30956), compute-name=) - Creating connection
[0m23:49:57.433337 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m23:49:57.434340 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384039376, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(34196, 30956), compute-name=) - Acquired connection on thread (34196, 30956), using default compute resource
[0m23:49:57.442337 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384039376, session-id=None, name=list_bronze_sal, idle-time=0.007996797561645508s, acquire-count=1, language=None, thread-identifier=(34196, 30956), compute-name=) - Checking idleness
[0m23:49:57.443339 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384039376, session-id=None, name=list_bronze_sal, idle-time=0.008999347686767578s, acquire-count=1, language=None, thread-identifier=(34196, 30956), compute-name=) - Retrieving connection
[0m23:49:57.443339 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384039376, session-id=None, name=list_bronze_sal, idle-time=0.008999347686767578s, acquire-count=1, language=None, thread-identifier=(34196, 30956), compute-name=) - Checking idleness
[0m23:49:57.444342 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384039376, session-id=None, name=list_bronze_sal, idle-time=0.008999347686767578s, acquire-count=1, language=None, thread-identifier=(34196, 30956), compute-name=) - Retrieving connection
[0m23:49:57.444342 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m23:49:57.444342 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m23:49:57.445339 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m23:49:57.445339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:49:58.000560 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a6-2cab-1274-92cb-fbc6956d46e8) - Created
[0m23:49:58.474975 [debug] [ThreadPool]: SQL status: OK in 1.030 seconds
[0m23:49:58.481976 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a6-2cab-1274-92cb-fbc6956d46e8, command-id=01eff0a6-2cc0-14f6-a1bc-9c35de4f958e) - Closing
[0m23:49:58.482967 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1569384039376, session-id=01eff0a6-2cab-1274-92cb-fbc6956d46e8, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(34196, 30956), compute-name=) - Released connection
[0m23:49:58.484715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cc0d29ca-1ae2-4119-8091-b30d6d54d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D48CC3FA0>]}
[0m23:49:58.484715 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=1.679800271987915s, acquire-count=1, language=None, thread-identifier=(34196, 35648), compute-name=) - Checking idleness
[0m23:49:58.485747 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=1.6808323860168457s, acquire-count=1, language=None, thread-identifier=(34196, 35648), compute-name=) - Retrieving connection
[0m23:49:58.485747 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=1.6808323860168457s, acquire-count=1, language=None, thread-identifier=(34196, 35648), compute-name=) - Checking idleness
[0m23:49:58.486730 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=1.6818146705627441s, acquire-count=1, language=None, thread-identifier=(34196, 35648), compute-name=) - Retrieving connection
[0m23:49:58.486730 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:49:58.487729 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:49:58.487729 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(34196, 35648), compute-name=) - Released connection
[0m23:49:58.490216 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:49:58.491227 [info ] [Thread-1 (]: 1 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m23:49:58.492226 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(34196, 13032), compute-name=) - Creating connection
[0m23:49:58.492226 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m23:49:58.502599 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Acquired connection on thread (34196, 13032), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m23:49:58.503598 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:49:58.511599 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:49:58.516600 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:49:58.585160 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:49:58.588146 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08554625511169434s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Checking idleness
[0m23:49:58.589156 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08655643463134766s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Retrieving connection
[0m23:49:58.589156 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08655643463134766s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Checking idleness
[0m23:49:58.590143 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.08754324913024902s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Retrieving connection
[0m23:49:58.590143 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m23:49:58.591142 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:49:58.591142 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_customer`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m23:49:58.592159 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:49:59.135946 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9) - Created
[0m23:50:02.005670 [debug] [Thread-1 (]: SQL status: OK in 3.410 seconds
[0m23:50:02.007656 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, command-id=01eff0a6-2d6d-1ad2-9163-ac003577d786) - Closing
[0m23:50:02.036656 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(34196, 13032), compute-name=) - Released connection
[0m23:50:02.037651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(34196, 13032), compute-name=) - Released connection
[0m23:50:02.040654 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc0d29ca-1ae2-4119-8091-b30d6d54d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D4D483EB0>]}
[0m23:50:02.041654 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 3.55s]
[0m23:50:02.043661 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:50:02.043661 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:50:02.044665 [info ] [Thread-1 (]: 2 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m23:50:02.045661 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.00800943374633789s, acquire-count=0, language=sql, thread-identifier=(34196, 13032), compute-name=) - Checking idleness
[0m23:50:02.046661 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m23:50:02.046661 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.009009838104248047s, acquire-count=0, language=sql, thread-identifier=(34196, 13032), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m23:50:02.047660 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.010008811950683594s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Acquired connection on thread (34196, 13032), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m23:50:02.047660 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:50:02.052659 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:50:02.054663 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:50:02.063211 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:50:02.067218 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.029566049575805664s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Checking idleness
[0m23:50:02.068210 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.03055882453918457s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Retrieving connection
[0m23:50:02.069210 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:50:02.069210 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m23:50:04.832566 [debug] [Thread-1 (]: SQL status: OK in 2.760 seconds
[0m23:50:04.835564 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, command-id=01eff0a6-2f2d-1058-8797-d8eedd6386cd) - Closing
[0m23:50:04.837564 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(34196, 13032), compute-name=) - Released connection
[0m23:50:04.838566 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(34196, 13032), compute-name=) - Released connection
[0m23:50:04.840566 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc0d29ca-1ae2-4119-8091-b30d6d54d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D6696D060>]}
[0m23:50:04.841564 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 2.79s]
[0m23:50:04.843567 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:50:04.844564 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:50:04.845562 [info ] [Thread-1 (]: 3 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_transactions . [RUN]
[0m23:50:04.846562 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007996559143066406s, acquire-count=0, language=sql, thread-identifier=(34196, 13032), compute-name=) - Checking idleness
[0m23:50:04.847564 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_franchises, now model.dbt_italy.stg_bakehouse_sales_transactions)
[0m23:50:04.848576 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.010010242462158203s, acquire-count=0, language=sql, thread-identifier=(34196, 13032), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:50:04.848576 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.010010242462158203s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Acquired connection on thread (34196, 13032), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_transactions`'
[0m23:50:04.849579 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:50:04.856577 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:50:04.859575 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:50:04.868143 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:50:04.871144 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.032578468322753906s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Checking idleness
[0m23:50:04.873143 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.034577369689941406s, acquire-count=1, language=sql, thread-identifier=(34196, 13032), compute-name=) - Retrieving connection
[0m23:50:04.874143 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:50:04.874143 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */

  
    
        create or replace table `bronze`.`sal`.`stg_bakehouse_sales_transactions`
      
      using delta
      
      
      
      
      
      
      
      as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_transactions`

  
[0m23:50:12.262989 [debug] [Thread-1 (]: SQL status: OK in 7.390 seconds
[0m23:50:12.264989 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, command-id=01eff0a6-30d8-1a84-b3d7-f66ff27e3ada) - Closing
[0m23:50:12.469321 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(34196, 13032), compute-name=) - Released connection
[0m23:50:12.471322 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1568959639904, session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(34196, 13032), compute-name=) - Released connection
[0m23:50:12.471322 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc0d29ca-1ae2-4119-8091-b30d6d54d811', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D4A181420>]}
[0m23:50:12.472321 [info ] [Thread-1 (]: 3 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_transactions  [[32mOK[0m in 7.62s]
[0m23:50:12.474323 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:50:12.475321 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=13.987592220306396s, acquire-count=0, language=None, thread-identifier=(34196, 35648), compute-name=) - Checking idleness
[0m23:50:12.475321 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=13.987592220306396s, acquire-count=0, language=None, thread-identifier=(34196, 35648), compute-name=) - Reusing connection previously named master
[0m23:50:12.476826 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=13.989097595214844s, acquire-count=1, language=None, thread-identifier=(34196, 35648), compute-name=) - Acquired connection on thread (34196, 35648), using default compute resource
[0m23:50:12.476826 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=13.989097595214844s, acquire-count=1, language=None, thread-identifier=(34196, 35648), compute-name=) - Checking idleness
[0m23:50:12.477833 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=None, name=master, idle-time=13.99010443687439s, acquire-count=1, language=None, thread-identifier=(34196, 35648), compute-name=) - Retrieving connection
[0m23:50:12.477833 [debug] [MainThread]: On master: ROLLBACK
[0m23:50:12.478834 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:50:12.793635 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-3583-1b50-9a24-d19ecb34e22a) - Created
[0m23:50:12.795652 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:50:12.795652 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=01eff0a6-3583-1b50-9a24-d19ecb34e22a, name=master, idle-time=0.0010142326354980469s, acquire-count=1, language=None, thread-identifier=(34196, 35648), compute-name=) - Checking idleness
[0m23:50:12.796620 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=01eff0a6-3583-1b50-9a24-d19ecb34e22a, name=master, idle-time=0.0019826889038085938s, acquire-count=1, language=None, thread-identifier=(34196, 35648), compute-name=) - Retrieving connection
[0m23:50:12.796620 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:50:12.797633 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:50:12.798616 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1569386886864, session-id=01eff0a6-3583-1b50-9a24-d19ecb34e22a, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(34196, 35648), compute-name=) - Released connection
[0m23:50:12.798616 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:50:12.799635 [debug] [MainThread]: On master: ROLLBACK
[0m23:50:12.799635 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:50:12.800633 [debug] [MainThread]: On master: Close
[0m23:50:12.800633 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-3583-1b50-9a24-d19ecb34e22a) - Closing
[0m23:50:12.949885 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m23:50:12.950900 [debug] [MainThread]: On list_bronze: Close
[0m23:50:12.950900 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-2c35-1e9e-ab1a-91cc79713c18) - Closing
[0m23:50:13.236159 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m23:50:13.237155 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m23:50:13.238156 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:50:13.238156 [debug] [MainThread]: On list_bronze_sal: Close
[0m23:50:13.239153 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-2cab-1274-92cb-fbc6956d46e8) - Closing
[0m23:50:13.640728 [debug] [MainThread]: Connection 'model.dbt_italy.stg_bakehouse_sales_transactions' was properly closed.
[0m23:50:13.641747 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_transactions: ROLLBACK
[0m23:50:13.642737 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:50:13.642737 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_transactions: Close
[0m23:50:13.643743 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-2d60-1a1a-a80a-725b51d75dd9) - Closing
[0m23:50:13.842317 [info ] [MainThread]: 
[0m23:50:13.843318 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 17.04 seconds (17.04s).
[0m23:50:13.845318 [debug] [MainThread]: Command end result
[0m23:50:13.895861 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:50:13.902859 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:50:13.909857 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m23:50:13.910863 [info ] [MainThread]: 
[0m23:50:13.911859 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:50:13.911859 [info ] [MainThread]: 
[0m23:50:13.912859 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m23:50:13.914858 [debug] [MainThread]: Command `dbt run` succeeded at 23:50:13.914858 after 20.09 seconds
[0m23:50:13.915859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D4A04E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D4A1645E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016D4A181420>]}
[0m23:50:13.915859 [debug] [MainThread]: Flushing usage events
[0m23:50:14.493266 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:50:53.644123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E5E94E1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E602CE5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E602CE2F0>]}


============================== 23:50:53.649127 | 5a2c1f79-69f4-4c76-bf5f-db20f01fd523 ==============================
[0m23:50:53.649127 [info ] [MainThread]: Running with dbt=1.9.2
[0m23:50:53.649756 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m23:50:54.256357 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:50:54.257354 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:50:54.258334 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:50:55.134694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5a2c1f79-69f4-4c76-bf5f-db20f01fd523', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E5D454EE0>]}
[0m23:50:55.173210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5a2c1f79-69f4-4c76-bf5f-db20f01fd523', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E61C3EDA0>]}
[0m23:50:55.174215 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m23:50:55.587909 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m23:50:55.824650 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:50:55.825648 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:50:55.831686 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m23:50:55.895259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a2c1f79-69f4-4c76-bf5f-db20f01fd523', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E7B191930>]}
[0m23:50:55.983822 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:50:55.987825 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:50:56.014822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5a2c1f79-69f4-4c76-bf5f-db20f01fd523', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E7B141150>]}
[0m23:50:56.015822 [info ] [MainThread]: Found 3 models, 6 data tests, 3 sources, 608 macros
[0m23:50:56.016822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a2c1f79-69f4-4c76-bf5f-db20f01fd523', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E7B140F40>]}
[0m23:50:56.017824 [info ] [MainThread]: 
[0m23:50:56.018824 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:50:56.019735 [info ] [MainThread]: 
[0m23:50:56.020755 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6908, 28324), compute-name=) - Creating connection
[0m23:50:56.020755 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:50:56.021756 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(6908, 28324), compute-name=) - Acquired connection on thread (6908, 28324), using default compute resource
[0m23:50:56.029768 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145100352, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6908, 24096), compute-name=) - Creating connection
[0m23:50:56.030772 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m23:50:56.031771 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145100352, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(6908, 24096), compute-name=) - Acquired connection on thread (6908, 24096), using default compute resource
[0m23:50:56.032769 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145100352, session-id=None, name=list_bronze, idle-time=0.0009980201721191406s, acquire-count=1, language=None, thread-identifier=(6908, 24096), compute-name=) - Checking idleness
[0m23:50:56.033768 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145100352, session-id=None, name=list_bronze, idle-time=0.001996755599975586s, acquire-count=1, language=None, thread-identifier=(6908, 24096), compute-name=) - Retrieving connection
[0m23:50:56.033768 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m23:50:56.034770 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m23:50:56.035775 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:50:56.382582 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a6-4f7e-1ba7-8510-8ef744c23ac6) - Created
[0m23:50:56.640950 [debug] [ThreadPool]: SQL status: OK in 0.610 seconds
[0m23:50:56.642953 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a6-4f7e-1ba7-8510-8ef744c23ac6, command-id=01eff0a6-4f8b-1205-839d-acb5028926cf) - Closing
[0m23:50:56.644460 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145100352, session-id=01eff0a6-4f7e-1ba7-8510-8ef744c23ac6, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(6908, 24096), compute-name=) - Released connection
[0m23:50:56.646466 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145104768, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6908, 20304), compute-name=) - Creating connection
[0m23:50:56.646466 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m23:50:56.647468 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145104768, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(6908, 20304), compute-name=) - Acquired connection on thread (6908, 20304), using default compute resource
[0m23:50:56.662472 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145104768, session-id=None, name=list_bronze_sal, idle-time=0.014003515243530273s, acquire-count=1, language=None, thread-identifier=(6908, 20304), compute-name=) - Checking idleness
[0m23:50:56.663467 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145104768, session-id=None, name=list_bronze_sal, idle-time=0.015999555587768555s, acquire-count=1, language=None, thread-identifier=(6908, 20304), compute-name=) - Retrieving connection
[0m23:50:56.663467 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145104768, session-id=None, name=list_bronze_sal, idle-time=0.015999555587768555s, acquire-count=1, language=None, thread-identifier=(6908, 20304), compute-name=) - Checking idleness
[0m23:50:56.664471 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145104768, session-id=None, name=list_bronze_sal, idle-time=0.01700282096862793s, acquire-count=1, language=None, thread-identifier=(6908, 20304), compute-name=) - Retrieving connection
[0m23:50:56.665467 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m23:50:56.665467 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m23:50:56.665467 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m23:50:56.666484 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:50:56.958258 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a6-4fd6-174b-ad3e-da95a6deb2e9) - Created
[0m23:50:57.392056 [debug] [ThreadPool]: SQL status: OK in 0.730 seconds
[0m23:50:57.399029 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a6-4fd6-174b-ad3e-da95a6deb2e9, command-id=01eff0a6-4fe3-1004-a68a-955adf9b0cf1) - Closing
[0m23:50:57.400027 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1299145104768, session-id=01eff0a6-4fd6-174b-ad3e-da95a6deb2e9, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(6908, 20304), compute-name=) - Released connection
[0m23:50:57.402026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a2c1f79-69f4-4c76-bf5f-db20f01fd523', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E61CE1990>]}
[0m23:50:57.402026 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=1.3802707195281982s, acquire-count=1, language=None, thread-identifier=(6908, 28324), compute-name=) - Checking idleness
[0m23:50:57.403025 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=1.3812696933746338s, acquire-count=1, language=None, thread-identifier=(6908, 28324), compute-name=) - Retrieving connection
[0m23:50:57.403025 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=1.3812696933746338s, acquire-count=1, language=None, thread-identifier=(6908, 28324), compute-name=) - Checking idleness
[0m23:50:57.404028 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=1.3822729587554932s, acquire-count=1, language=None, thread-identifier=(6908, 28324), compute-name=) - Retrieving connection
[0m23:50:57.404028 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:50:57.405025 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:50:57.405025 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(6908, 28324), compute-name=) - Released connection
[0m23:50:57.407722 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:50:57.408734 [info ] [Thread-1 (]: 1 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m23:50:57.409738 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6908, 17424), compute-name=) - Creating connection
[0m23:50:57.409738 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m23:50:57.410735 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Acquired connection on thread (6908, 17424), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m23:50:57.410735 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:50:57.417736 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:50:57.420734 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:50:57.679351 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.26761674880981445s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:50:57.680326 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.2695903778076172s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:50:57.680326 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.2695903778076172s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:50:57.681320 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.2705845832824707s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:50:57.681320 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m23:50:57.682325 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:50:57.682325 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_customer'
  
[0m23:50:57.683322 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:50:58.219788 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9) - Created
[0m23:50:58.701169 [debug] [Thread-1 (]: SQL status: OK in 1.020 seconds
[0m23:50:58.703168 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-50ac-117f-8215-9cfddee26044) - Closing
[0m23:50:58.708150 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.4863433837890625s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:50:58.709156 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.4873495101928711s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:50:58.710149 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:50:58.710149 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m23:50:59.038743 [debug] [Thread-1 (]: SQL status: OK in 0.330 seconds
[0m23:50:59.041744 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-50f0-1e6d-b55e-524a4a04bb9d) - Closing
[0m23:50:59.051332 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.8295254707336426s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:50:59.052486 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.8306796550750732s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:50:59.052486 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:50:59.053311 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    create or replace temporary view `stg_bakehouse_sales_customer__dbt_tmp` as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m23:51:00.082761 [debug] [Thread-1 (]: SQL status: OK in 1.030 seconds
[0m23:51:00.083763 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-512c-12c4-a4ce-34276460c8b2) - Closing
[0m23:51:00.111756 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.8899500370025635s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:00.112758 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.8909516334533691s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:00.113759 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:00.114759 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m23:51:00.425579 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m23:51:00.428565 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-51cb-1a76-8fa7-3fdae752bf0f) - Closing
[0m23:51:00.431573 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=2.2097668647766113s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:00.432577 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=2.210771322250366s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:00.433575 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:00.433575 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `stg_bakehouse_sales_customer__dbt_tmp`
  
[0m23:51:00.848475 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m23:51:00.852058 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-51f4-1694-9223-8f6125a89636) - Closing
[0m23:51:00.861045 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:00.863057 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=2.6412503719329834s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:00.863057 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=2.6412503719329834s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:00.864057 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:00.864057 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_customer` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_customer__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m23:51:03.301899 [debug] [Thread-1 (]: SQL status: OK in 2.440 seconds
[0m23:51:03.303915 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-5236-146b-9eaa-ceb790b26e71) - Closing
[0m23:51:03.323900 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(6908, 17424), compute-name=) - Released connection
[0m23:51:03.324900 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(6908, 17424), compute-name=) - Released connection
[0m23:51:03.327900 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a2c1f79-69f4-4c76-bf5f-db20f01fd523', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E5D43B1C0>]}
[0m23:51:03.328899 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 5.92s]
[0m23:51:03.330259 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:51:03.330259 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:51:03.331272 [info ] [Thread-1 (]: 2 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m23:51:03.332883 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0072176456451416016s, acquire-count=0, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:03.333128 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m23:51:03.333128 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.008228540420532227s, acquire-count=0, language=sql, thread-identifier=(6908, 17424), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m23:51:03.334130 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.009230613708496094s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Acquired connection on thread (6908, 17424), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m23:51:03.334645 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:51:03.338187 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:03.340721 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:51:03.347756 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.02186417579650879s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:03.351768 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.025875329971313477s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:03.352745 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:03.352745 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_franchises'
  
[0m23:51:03.665048 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m23:51:03.668041 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-53b2-1839-9691-288eb3e8928b) - Closing
[0m23:51:03.672031 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.34713149070739746s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:03.672031 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.34713149070739746s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:03.673037 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:03.673037 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m23:51:03.910453 [debug] [Thread-1 (]: SQL status: OK in 0.240 seconds
[0m23:51:03.912463 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-53e2-1ea6-a956-0c385a556c05) - Closing
[0m23:51:03.914439 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.5895397663116455s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:03.914439 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.5895397663116455s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:03.915453 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:03.916453 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    create or replace temporary view `stg_bakehouse_sales_franchises__dbt_tmp` as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m23:51:04.737824 [debug] [Thread-1 (]: SQL status: OK in 0.820 seconds
[0m23:51:04.739826 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-5407-1c56-a39d-476dd23fc7e6) - Closing
[0m23:51:04.743823 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.4189233779907227s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:04.744822 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.419922113418579s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:04.744822 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:04.744822 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m23:51:04.971211 [debug] [Thread-1 (]: SQL status: OK in 0.230 seconds
[0m23:51:04.974198 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-5486-11a5-b77f-0f99198c91da) - Closing
[0m23:51:04.977196 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.652296543121338s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:04.977196 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.652296543121338s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:04.978198 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:04.978198 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `stg_bakehouse_sales_franchises__dbt_tmp`
  
[0m23:51:05.257661 [debug] [Thread-1 (]: SQL status: OK in 0.280 seconds
[0m23:51:05.260662 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-54a9-1fde-be40-601a8e4547e0) - Closing
[0m23:51:05.261635 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:05.264735 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.9388635158538818s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:05.264735 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.9398350715637207s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:05.265734 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:05.265734 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_franchises` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_franchises__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m23:51:08.773133 [debug] [Thread-1 (]: SQL status: OK in 3.510 seconds
[0m23:51:08.775136 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-54d6-127a-b5ca-99397ca6c41d) - Closing
[0m23:51:08.776108 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(6908, 17424), compute-name=) - Released connection
[0m23:51:08.777121 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(6908, 17424), compute-name=) - Released connection
[0m23:51:08.778103 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a2c1f79-69f4-4c76-bf5f-db20f01fd523', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E60290A00>]}
[0m23:51:08.778103 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 5.45s]
[0m23:51:08.780104 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:51:08.781106 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:51:08.781106 [info ] [Thread-1 (]: 3 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_transactions . [RUN]
[0m23:51:08.782103 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.004981517791748047s, acquire-count=0, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:08.782103 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_franchises, now model.dbt_italy.stg_bakehouse_sales_transactions)
[0m23:51:08.783103 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0059816837310791016s, acquire-count=0, language=sql, thread-identifier=(6908, 17424), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:51:08.783103 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0059816837310791016s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Acquired connection on thread (6908, 17424), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_transactions`'
[0m23:51:08.784119 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:51:08.790134 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:08.792109 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:51:08.797105 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.019983768463134766s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:08.799110 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.020986557006835938s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:08.799110 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:08.800108 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_transactions'
  
[0m23:51:09.173324 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m23:51:09.176321 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-56f5-1111-a2a4-fc8ab41037e6) - Closing
[0m23:51:09.180309 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.4021892547607422s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:09.180309 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.40318799018859863s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:09.181307 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:09.182308 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m23:51:09.555031 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m23:51:09.557068 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-572b-14f3-ac0e-80161fa5ff48) - Closing
[0m23:51:09.559039 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.7819180488586426s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:09.560054 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.7819180488586426s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:09.560054 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:09.561038 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */

  
    create or replace temporary view `stg_bakehouse_sales_transactions__dbt_tmp` as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_transactions`

  WHERE dateTime > (SELECT max(dt_ingestion_timestamp) from `bronze`.`sal`.`stg_bakehouse_sales_transactions`)

  
[0m23:51:10.684868 [debug] [Thread-1 (]: SQL status: OK in 1.120 seconds
[0m23:51:10.685875 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-5764-1aa7-b26c-2b0f5b2a033a) - Closing
[0m23:51:10.693875 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.9167537689208984s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:10.694868 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.9177472591400146s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:10.694868 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:10.695865 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `stg_bakehouse_sales_transactions__dbt_tmp`
  
[0m23:51:11.007973 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m23:51:11.010966 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-5812-18d5-91c0-d1396d28ca20) - Closing
[0m23:51:11.013964 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.236842393875122s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:11.014964 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.2378430366516113s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:11.014964 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:11.015962 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m23:51:11.303052 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m23:51:11.307053 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-5843-1757-aa46-9641091ad738) - Closing
[0m23:51:11.311052 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:11.313051 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.5359294414520264s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Checking idleness
[0m23:51:11.314052 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.5359294414520264s, acquire-count=1, language=sql, thread-identifier=(6908, 17424), compute-name=) - Retrieving connection
[0m23:51:11.314052 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:11.315055 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
insert into table `bronze`.`sal`.`stg_bakehouse_sales_transactions` (`transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp`)
select `transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp` from `stg_bakehouse_sales_transactions__dbt_tmp`

[0m23:51:13.703763 [debug] [Thread-1 (]: SQL status: OK in 2.390 seconds
[0m23:51:13.705745 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, command-id=01eff0a6-5870-1556-a7da-ed4e03e5a8e0) - Closing
[0m23:51:13.707750 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(6908, 17424), compute-name=) - Released connection
[0m23:51:13.707750 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1299146493760, session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(6908, 17424), compute-name=) - Released connection
[0m23:51:13.708747 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a2c1f79-69f4-4c76-bf5f-db20f01fd523', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E5E7B8730>]}
[0m23:51:13.709746 [info ] [Thread-1 (]: 3 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_transactions  [[32mOK[0m in 4.93s]
[0m23:51:13.710744 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:51:13.711741 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=16.306715965270996s, acquire-count=0, language=None, thread-identifier=(6908, 28324), compute-name=) - Checking idleness
[0m23:51:13.712744 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=16.307718515396118s, acquire-count=0, language=None, thread-identifier=(6908, 28324), compute-name=) - Reusing connection previously named master
[0m23:51:13.713746 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=16.307718515396118s, acquire-count=1, language=None, thread-identifier=(6908, 28324), compute-name=) - Acquired connection on thread (6908, 28324), using default compute resource
[0m23:51:13.713746 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=16.308720350265503s, acquire-count=1, language=None, thread-identifier=(6908, 28324), compute-name=) - Checking idleness
[0m23:51:13.713746 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=None, name=master, idle-time=16.308720350265503s, acquire-count=1, language=None, thread-identifier=(6908, 28324), compute-name=) - Retrieving connection
[0m23:51:13.714745 [debug] [MainThread]: On master: ROLLBACK
[0m23:51:13.714745 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:51:14.031974 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-5a03-1b6a-b899-b8886d15a420) - Created
[0m23:51:14.032974 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:51:14.033975 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=01eff0a6-5a03-1b6a-b899-b8886d15a420, name=master, idle-time=0.001001119613647461s, acquire-count=1, language=None, thread-identifier=(6908, 28324), compute-name=) - Checking idleness
[0m23:51:14.033975 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=01eff0a6-5a03-1b6a-b899-b8886d15a420, name=master, idle-time=0.001001119613647461s, acquire-count=1, language=None, thread-identifier=(6908, 28324), compute-name=) - Retrieving connection
[0m23:51:14.034973 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:51:14.034973 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:51:14.035973 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1299145036016, session-id=01eff0a6-5a03-1b6a-b899-b8886d15a420, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(6908, 28324), compute-name=) - Released connection
[0m23:51:14.035973 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:51:14.036975 [debug] [MainThread]: On master: ROLLBACK
[0m23:51:14.036975 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:51:14.037973 [debug] [MainThread]: On master: Close
[0m23:51:14.037973 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-5a03-1b6a-b899-b8886d15a420) - Closing
[0m23:51:14.183714 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m23:51:14.184715 [debug] [MainThread]: On list_bronze: Close
[0m23:51:14.185713 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-4f7e-1ba7-8510-8ef744c23ac6) - Closing
[0m23:51:14.304982 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m23:51:14.306966 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m23:51:14.306966 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:51:14.307970 [debug] [MainThread]: On list_bronze_sal: Close
[0m23:51:14.307970 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-4fd6-174b-ad3e-da95a6deb2e9) - Closing
[0m23:51:14.488015 [debug] [MainThread]: Connection 'model.dbt_italy.stg_bakehouse_sales_transactions' was properly closed.
[0m23:51:14.489014 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_transactions: ROLLBACK
[0m23:51:14.490019 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:51:14.490019 [debug] [MainThread]: On model.dbt_italy.stg_bakehouse_sales_transactions: Close
[0m23:51:14.491013 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-5096-1c83-9438-b4aa5e501ab9) - Closing
[0m23:51:14.639872 [info ] [MainThread]: 
[0m23:51:14.641874 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 18.62 seconds (18.62s).
[0m23:51:14.642870 [debug] [MainThread]: Command end result
[0m23:51:14.669968 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:51:14.675904 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:51:14.683432 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m23:51:14.684430 [info ] [MainThread]: 
[0m23:51:14.685271 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:51:14.686284 [info ] [MainThread]: 
[0m23:51:14.687301 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m23:51:14.689288 [debug] [MainThread]: Command `dbt run` succeeded at 23:51:14.689288 after 21.21 seconds
[0m23:51:14.690289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E5E94E1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E61C3EDA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012E5EE91750>]}
[0m23:51:14.691289 [debug] [MainThread]: Flushing usage events
[0m23:51:15.344413 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:51:24.743109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8ED54E110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8EEED26B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8EEED23B0>]}


============================== 23:51:24.747107 | f7418b9b-3ed3-4ae8-b4e2-bd7971ceeb10 ==============================
[0m23:51:24.747107 [info ] [MainThread]: Running with dbt=1.9.2
[0m23:51:24.749115 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m23:51:25.394588 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:51:25.396587 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:51:25.396587 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:51:26.368428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f7418b9b-3ed3-4ae8-b4e2-bd7971ceeb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B888E77130>]}
[0m23:51:26.415947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f7418b9b-3ed3-4ae8-b4e2-bd7971ceeb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8F05FEEC0>]}
[0m23:51:26.416950 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m23:51:26.842037 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m23:51:27.096357 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:51:27.098357 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:51:27.111352 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m23:51:27.157351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f7418b9b-3ed3-4ae8-b4e2-bd7971ceeb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B889E91A50>]}
[0m23:51:27.249874 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:51:27.252872 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:51:27.302207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f7418b9b-3ed3-4ae8-b4e2-bd7971ceeb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B889E93910>]}
[0m23:51:27.303208 [info ] [MainThread]: Found 3 models, 6 data tests, 3 sources, 608 macros
[0m23:51:27.307208 [info ] [MainThread]: 
[0m23:51:27.308207 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:51:27.309208 [info ] [MainThread]: 
[0m23:51:27.309208 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(27712, 8412), compute-name=) - Creating connection
[0m23:51:27.310208 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:51:27.310208 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(27712, 8412), compute-name=) - Acquired connection on thread (27712, 8412), using default compute resource
[0m23:51:27.316217 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099489120, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(27712, 35816), compute-name=) - Creating connection
[0m23:51:27.316217 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m23:51:27.317213 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099489120, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(27712, 35816), compute-name=) - Acquired connection on thread (27712, 35816), using default compute resource
[0m23:51:27.317213 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099489120, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(27712, 35816), compute-name=) - Checking idleness
[0m23:51:27.318207 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099489120, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(27712, 35816), compute-name=) - Retrieving connection
[0m23:51:27.318207 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m23:51:27.318207 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m23:51:27.319207 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:51:27.872245 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a6-6241-1613-bbca-5013439ef5e8) - Created
[0m23:51:28.183519 [debug] [ThreadPool]: SQL status: OK in 0.860 seconds
[0m23:51:28.186513 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a6-6241-1613-bbca-5013439ef5e8, command-id=01eff0a6-624e-1eee-aa65-cf3accf9089d) - Closing
[0m23:51:28.187515 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099489120, session-id=01eff0a6-6241-1613-bbca-5013439ef5e8, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(27712, 35816), compute-name=) - Released connection
[0m23:51:28.190515 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099488736, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(27712, 1568), compute-name=) - Creating connection
[0m23:51:28.190515 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m23:51:28.191517 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099488736, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(27712, 1568), compute-name=) - Acquired connection on thread (27712, 1568), using default compute resource
[0m23:51:28.204053 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099488736, session-id=None, name=list_bronze_sal, idle-time=0.012536287307739258s, acquire-count=1, language=None, thread-identifier=(27712, 1568), compute-name=) - Checking idleness
[0m23:51:28.206030 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099488736, session-id=None, name=list_bronze_sal, idle-time=0.014513254165649414s, acquire-count=1, language=None, thread-identifier=(27712, 1568), compute-name=) - Retrieving connection
[0m23:51:28.206030 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099488736, session-id=None, name=list_bronze_sal, idle-time=0.014513254165649414s, acquire-count=1, language=None, thread-identifier=(27712, 1568), compute-name=) - Checking idleness
[0m23:51:28.207030 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099488736, session-id=None, name=list_bronze_sal, idle-time=0.015513420104980469s, acquire-count=1, language=None, thread-identifier=(27712, 1568), compute-name=) - Retrieving connection
[0m23:51:28.208027 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m23:51:28.208027 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m23:51:28.209026 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m23:51:28.210030 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:51:28.618115 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a6-62ac-12e1-9183-b4f1d436f7d1) - Created
[0m23:51:29.103292 [debug] [ThreadPool]: SQL status: OK in 0.890 seconds
[0m23:51:29.109259 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a6-62ac-12e1-9183-b4f1d436f7d1, command-id=01eff0a6-62c1-12da-85e9-1f9883f1c655) - Closing
[0m23:51:29.110277 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1892099488736, session-id=01eff0a6-62ac-12e1-9183-b4f1d436f7d1, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(27712, 1568), compute-name=) - Released connection
[0m23:51:29.111260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f7418b9b-3ed3-4ae8-b4e2-bd7971ceeb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8EC1CBFA0>]}
[0m23:51:29.112258 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=1.8020493984222412s, acquire-count=1, language=None, thread-identifier=(27712, 8412), compute-name=) - Checking idleness
[0m23:51:29.112258 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=1.8020493984222412s, acquire-count=1, language=None, thread-identifier=(27712, 8412), compute-name=) - Retrieving connection
[0m23:51:29.113258 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=1.8030498027801514s, acquire-count=1, language=None, thread-identifier=(27712, 8412), compute-name=) - Checking idleness
[0m23:51:29.113258 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=1.8030498027801514s, acquire-count=1, language=None, thread-identifier=(27712, 8412), compute-name=) - Retrieving connection
[0m23:51:29.113258 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:51:29.114258 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:51:29.115272 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(27712, 8412), compute-name=) - Released connection
[0m23:51:29.117257 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:51:29.118258 [info ] [Thread-1 (]: 1 of 9 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m23:51:29.119257 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(27712, 26440), compute-name=) - Creating connection
[0m23:51:29.119257 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m23:51:29.120262 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Acquired connection on thread (27712, 26440), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m23:51:29.120262 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:51:29.344435 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:29.347204 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:51:29.384226 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.26195693016052246s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:29.386225 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.26496434211730957s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:29.386225 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.265963077545166s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:29.387224 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.26696228981018066s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:29.387224 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m23:51:29.388225 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:29.388225 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_customer'
  
[0m23:51:29.389226 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:51:29.888025 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0a6-6374-1997-b2ea-1435411957e1) - Created
[0m23:51:30.305171 [debug] [Thread-1 (]: SQL status: OK in 0.920 seconds
[0m23:51:30.308173 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-638b-1d18-ad75-962569b1a9b7) - Closing
[0m23:51:30.314204 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.42517948150634766s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:30.314204 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.42517948150634766s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:30.315180 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:30.315180 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m23:51:30.655371 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m23:51:30.658352 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-63cd-179e-bf8f-42f6b312d5f8) - Closing
[0m23:51:30.669353 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.7803292274475098s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:30.670354 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.7813293933868408s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:30.670354 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:30.671353 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    create or replace temporary view `stg_bakehouse_sales_customer__dbt_tmp` as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m23:51:32.963455 [debug] [Thread-1 (]: SQL status: OK in 2.290 seconds
[0m23:51:32.965453 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6403-170a-bfd3-7ce61fd0300d) - Closing
[0m23:51:32.998456 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.1094319820404053s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:32.999463 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.1104393005371094s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:33.000460 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:33.001461 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m23:51:33.222717 [debug] [Thread-1 (]: SQL status: OK in 0.220 seconds
[0m23:51:33.225718 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-655c-1f83-9a96-3d3c600c83af) - Closing
[0m23:51:33.229715 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.339691638946533s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:33.229715 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.3406903743743896s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:33.230714 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:33.230714 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `stg_bakehouse_sales_customer__dbt_tmp`
  
[0m23:51:33.526780 [debug] [Thread-1 (]: SQL status: OK in 0.300 seconds
[0m23:51:33.529788 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-657f-1e4d-b09a-0cf82dfbdbc3) - Closing
[0m23:51:33.540799 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:33.543779 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.654755115509033s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:33.545779 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.6557531356811523s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:33.545779 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m23:51:33.546776 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_customer` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_customer__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m23:51:35.978318 [debug] [Thread-1 (]: SQL status: OK in 2.430 seconds
[0m23:51:35.980319 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-65b0-1586-baca-6f5667eb43dc) - Closing
[0m23:51:36.007355 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:36.008357 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:36.010947 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7418b9b-3ed3-4ae8-b4e2-bd7971ceeb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B88A171FC0>]}
[0m23:51:36.011932 [info ] [Thread-1 (]: 1 of 9 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 6.89s]
[0m23:51:36.013913 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m23:51:36.014912 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:51:36.015912 [info ] [Thread-1 (]: 2 of 9 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m23:51:36.017917 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.008558273315429688s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:36.018912 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m23:51:36.018912 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.010555267333984375s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m23:51:36.019914 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.01155710220336914s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Acquired connection on thread (27712, 26440), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m23:51:36.020918 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:51:36.025912 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:36.027915 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:51:36.035945 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0275881290435791s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:36.036947 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.02859044075012207s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:36.037942 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:36.038914 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_franchises'
  
[0m23:51:36.493325 [debug] [Thread-1 (]: SQL status: OK in 0.450 seconds
[0m23:51:36.496369 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-672c-1ab5-bdc6-14d99115b87a) - Closing
[0m23:51:36.499371 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.4910144805908203s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:36.500368 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.49201107025146484s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:36.500368 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:36.501368 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m23:51:36.722467 [debug] [Thread-1 (]: SQL status: OK in 0.220 seconds
[0m23:51:36.725452 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6773-110f-94b1-a3338ee46d86) - Closing
[0m23:51:36.727468 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.719111442565918s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:36.727468 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.719111442565918s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:36.728485 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:36.728485 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    create or replace temporary view `stg_bakehouse_sales_franchises__dbt_tmp` as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m23:51:37.082207 [debug] [Thread-1 (]: SQL status: OK in 0.350 seconds
[0m23:51:37.084214 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6795-13c4-9b8a-16484264c544) - Closing
[0m23:51:37.088211 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.0788514614105225s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:37.088211 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.0798540115356445s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:37.089212 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:37.089212 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m23:51:37.504145 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m23:51:37.507451 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-67cd-1339-95a7-551cc93e69ca) - Closing
[0m23:51:37.510846 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.5024893283843994s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:37.510846 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.5024893283843994s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:37.511924 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:37.511924 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `stg_bakehouse_sales_franchises__dbt_tmp`
  
[0m23:51:37.786486 [debug] [Thread-1 (]: SQL status: OK in 0.270 seconds
[0m23:51:37.790467 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-680c-1fe0-a9d8-646d41c24e64) - Closing
[0m23:51:37.791468 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:37.793469 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.785111904144287s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:37.794467 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.7861104011535645s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:37.794467 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m23:51:37.795467 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_franchises` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_franchises__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m23:51:40.287797 [debug] [Thread-1 (]: SQL status: OK in 2.490 seconds
[0m23:51:40.289795 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6847-1753-a73b-7e240b5dc73e) - Closing
[0m23:51:40.291765 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:40.291765 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:40.292766 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7418b9b-3ed3-4ae8-b4e2-bd7971ceeb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B88A171C00>]}
[0m23:51:40.293766 [info ] [Thread-1 (]: 2 of 9 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 4.28s]
[0m23:51:40.295473 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:51:40.295473 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:51:40.296470 [info ] [Thread-1 (]: 3 of 9 START sql incremental model bronze.sal.stg_bakehouse_sales_transactions . [RUN]
[0m23:51:40.297467 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.005702972412109375s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:40.298467 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_franchises, now model.dbt_italy.stg_bakehouse_sales_transactions)
[0m23:51:40.298467 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.006702423095703125s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_franchises
[0m23:51:40.299467 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.00770258903503418s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Acquired connection on thread (27712, 26440), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_transactions`'
[0m23:51:40.299467 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:51:40.305530 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:40.308505 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:51:40.319017 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.027252912521362305s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:40.320017 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.028252601623535156s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:40.321016 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:40.321016 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_transactions'
  
[0m23:51:41.129104 [debug] [Thread-1 (]: SQL status: OK in 0.810 seconds
[0m23:51:41.132103 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-69b9-1ea7-9ac5-f50304080c2b) - Closing
[0m23:51:41.136105 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.8433377742767334s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:41.137107 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.8443403244018555s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:41.137107 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:41.138096 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m23:51:41.366877 [debug] [Thread-1 (]: SQL status: OK in 0.230 seconds
[0m23:51:41.369887 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6a36-145f-89fb-8c59be589b43) - Closing
[0m23:51:41.370898 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.0791337490081787s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:41.371900 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.0801353454589844s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:41.371900 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:41.372884 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */

  
    create or replace temporary view `stg_bakehouse_sales_transactions__dbt_tmp` as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_transactions`

  WHERE dateTime > (SELECT max(dt_ingestion_timestamp) from `bronze`.`sal`.`stg_bakehouse_sales_transactions`)

  
[0m23:51:41.892513 [debug] [Thread-1 (]: SQL status: OK in 0.520 seconds
[0m23:51:41.894496 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6a59-1f5c-99f3-64ca06f44637) - Closing
[0m23:51:41.903484 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.6117196083068848s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:41.904484 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.6127197742462158s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:41.904484 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:41.905483 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `stg_bakehouse_sales_transactions__dbt_tmp`
  
[0m23:51:42.198884 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m23:51:42.201882 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6aab-1597-826f-61c4362c3ff4) - Closing
[0m23:51:42.204894 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.9131295680999756s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:42.205893 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.914128065109253s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:42.205893 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:42.205893 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m23:51:42.437339 [debug] [Thread-1 (]: SQL status: OK in 0.230 seconds
[0m23:51:42.440338 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6ad9-1fd8-b7db-65879395598e) - Closing
[0m23:51:42.444324 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:42.446313 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.1545486450195312s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:42.447325 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.1555604934692383s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:42.448323 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m23:51:42.448323 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
insert into table `bronze`.`sal`.`stg_bakehouse_sales_transactions` (`transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp`)
select `transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp` from `stg_bakehouse_sales_transactions__dbt_tmp`

[0m23:51:45.208665 [debug] [Thread-1 (]: SQL status: OK in 2.760 seconds
[0m23:51:45.210668 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6afe-1488-94d9-177678424fe8) - Closing
[0m23:51:45.212669 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:45.212669 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:45.213676 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f7418b9b-3ed3-4ae8-b4e2-bd7971ceeb10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B88A1D38B0>]}
[0m23:51:45.214677 [info ] [Thread-1 (]: 3 of 9 OK created sql incremental model bronze.sal.stg_bakehouse_sales_transactions  [[32mOK[0m in 4.92s]
[0m23:51:45.215676 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:51:45.215676 [debug] [Thread-1 (]: Began running node test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf
[0m23:51:45.216677 [info ] [Thread-1 (]: 4 of 9 START test not_null_stg_bakehouse_sales_customer_customerID ............. [RUN]
[0m23:51:45.217677 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0050084590911865234s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:45.218681 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_transactions, now test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf)
[0m23:51:45.218681 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf, idle-time=0.006012678146362305s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_transactions
[0m23:51:45.218681 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf, idle-time=0.006012678146362305s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Acquired connection on thread (27712, 26440), using default compute resource for model 'None'
[0m23:51:45.219680 [debug] [Thread-1 (]: Began compiling node test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf
[0m23:51:45.230202 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf"
[0m23:51:45.236298 [debug] [Thread-1 (]: Began executing node test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf
[0m23:51:45.254892 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf"
[0m23:51:45.258874 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf, idle-time=0.046205759048461914s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:45.259879 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf, idle-time=0.047210693359375s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:45.260877 [debug] [Thread-1 (]: Using databricks connection "test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf"
[0m23:51:45.260877 [debug] [Thread-1 (]: On test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customerID
from `bronze`.`sal`.`stg_bakehouse_sales_customer`
where customerID is null



      
    ) dbt_internal_test
[0m23:51:45.721629 [debug] [Thread-1 (]: SQL status: OK in 0.460 seconds
[0m23:51:45.736693 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6cab-19f4-a55b-4f9623568cad) - Closing
[0m23:51:45.739691 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:45.740692 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:45.740692 [info ] [Thread-1 (]: 4 of 9 PASS not_null_stg_bakehouse_sales_customer_customerID ................... [[32mPASS[0m in 0.52s]
[0m23:51:45.742701 [debug] [Thread-1 (]: Finished running node test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf
[0m23:51:45.742701 [debug] [Thread-1 (]: Began running node test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79
[0m23:51:45.743690 [info ] [Thread-1 (]: 5 of 9 START test unique_stg_bakehouse_sales_customer_customerID ............... [RUN]
[0m23:51:45.744711 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf, idle-time=0.004019498825073242s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:45.744711 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf, now test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79)
[0m23:51:45.745691 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79, idle-time=0.0049991607666015625s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Reusing connection previously named test.dbt_italy.not_null_stg_bakehouse_sales_customer_customerID.a67723efaf
[0m23:51:45.746691 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79, idle-time=0.0049991607666015625s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Acquired connection on thread (27712, 26440), using default compute resource for model 'None'
[0m23:51:45.746691 [debug] [Thread-1 (]: Began compiling node test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79
[0m23:51:45.753695 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79"
[0m23:51:45.756561 [debug] [Thread-1 (]: Began executing node test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79
[0m23:51:45.759575 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79"
[0m23:51:45.762572 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79, idle-time=0.021879911422729492s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:45.763576 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79, idle-time=0.022884607315063477s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:45.764578 [debug] [Thread-1 (]: Using databricks connection "test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79"
[0m23:51:45.766596 [debug] [Thread-1 (]: On test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customerID as unique_field,
    count(*) as n_records

from `bronze`.`sal`.`stg_bakehouse_sales_customer`
where customerID is not null
group by customerID
having count(*) > 1



      
    ) dbt_internal_test
[0m23:51:46.570038 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m23:51:46.573042 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6cf8-1e43-8dcd-7b7ae030e19d) - Closing
[0m23:51:46.574033 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:46.575027 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:46.575027 [error] [Thread-1 (]: 5 of 9 FAIL 300 unique_stg_bakehouse_sales_customer_customerID ................. [[31mFAIL 300[0m in 0.83s]
[0m23:51:46.577015 [debug] [Thread-1 (]: Finished running node test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79
[0m23:51:46.577015 [debug] [Thread-1 (]: Began running node test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990
[0m23:51:46.578009 [debug] [Thread-4 (]: Marking all children of 'test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79' to be skipped because of status 'fail'.  Reason: Got 300 results, configured to fail if != 0.
[0m23:51:46.578009 [info ] [Thread-1 (]: 6 of 9 START test not_null_stg_bakehouse_sales_franchises_franchiseID .......... [RUN]
[0m23:51:46.580009 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79, idle-time=0.004982471466064453s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:46.581010 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79, now test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990)
[0m23:51:46.581010 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990, idle-time=0.0059833526611328125s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Reusing connection previously named test.dbt_italy.unique_stg_bakehouse_sales_customer_customerID.9da57f6c79
[0m23:51:46.582012 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990, idle-time=0.006985187530517578s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Acquired connection on thread (27712, 26440), using default compute resource for model 'None'
[0m23:51:46.583010 [debug] [Thread-1 (]: Began compiling node test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990
[0m23:51:46.588013 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990"
[0m23:51:46.592030 [debug] [Thread-1 (]: Began executing node test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990
[0m23:51:46.596009 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990"
[0m23:51:46.608699 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990, idle-time=0.03367209434509277s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:46.610699 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990, idle-time=0.03567218780517578s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:46.611696 [debug] [Thread-1 (]: Using databricks connection "test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990"
[0m23:51:46.611696 [debug] [Thread-1 (]: On test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select franchiseID
from `bronze`.`sal`.`stg_bakehouse_sales_franchises`
where franchiseID is null



      
    ) dbt_internal_test
[0m23:51:47.145156 [debug] [Thread-1 (]: SQL status: OK in 0.530 seconds
[0m23:51:47.148168 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6d79-1b81-bc14-773878da4679) - Closing
[0m23:51:47.149159 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:47.150157 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:47.151174 [info ] [Thread-1 (]: 6 of 9 PASS not_null_stg_bakehouse_sales_franchises_franchiseID ................ [[32mPASS[0m in 0.57s]
[0m23:51:47.152159 [debug] [Thread-1 (]: Finished running node test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990
[0m23:51:47.152159 [debug] [Thread-1 (]: Began running node test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08
[0m23:51:47.153160 [info ] [Thread-1 (]: 7 of 9 START test unique_stg_bakehouse_sales_franchises_franchiseID ............ [RUN]
[0m23:51:47.154160 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990, idle-time=0.004003047943115234s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:47.154160 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990, now test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08)
[0m23:51:47.155161 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08, idle-time=0.005003213882446289s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Reusing connection previously named test.dbt_italy.not_null_stg_bakehouse_sales_franchises_franchiseID.905e2c5990
[0m23:51:47.155161 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08, idle-time=0.005003213882446289s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Acquired connection on thread (27712, 26440), using default compute resource for model 'None'
[0m23:51:47.156160 [debug] [Thread-1 (]: Began compiling node test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08
[0m23:51:47.162163 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08"
[0m23:51:47.166157 [debug] [Thread-1 (]: Began executing node test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08
[0m23:51:47.169157 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08"
[0m23:51:47.171157 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08, idle-time=0.020999908447265625s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:47.172161 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08, idle-time=0.0220034122467041s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:47.173159 [debug] [Thread-1 (]: Using databricks connection "test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08"
[0m23:51:47.173159 [debug] [Thread-1 (]: On test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    franchiseID as unique_field,
    count(*) as n_records

from `bronze`.`sal`.`stg_bakehouse_sales_franchises`
where franchiseID is not null
group by franchiseID
having count(*) > 1



      
    ) dbt_internal_test
[0m23:51:47.934096 [debug] [Thread-1 (]: SQL status: OK in 0.760 seconds
[0m23:51:47.937092 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6dd0-174f-a272-8dccc4691f86) - Closing
[0m23:51:47.937606 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:47.938616 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:47.938616 [error] [Thread-1 (]: 7 of 9 FAIL 48 unique_stg_bakehouse_sales_franchises_franchiseID ............... [[31mFAIL 48[0m in 0.79s]
[0m23:51:47.939715 [debug] [Thread-1 (]: Finished running node test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08
[0m23:51:47.940735 [debug] [Thread-1 (]: Began running node test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e
[0m23:51:47.940735 [debug] [Thread-4 (]: Marking all children of 'test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08' to be skipped because of status 'fail'.  Reason: Got 48 results, configured to fail if != 0.
[0m23:51:47.941745 [info ] [Thread-1 (]: 8 of 9 START test not_null_stg_bakehouse_sales_transactions_transactionID ...... [RUN]
[0m23:51:47.942728 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08, idle-time=0.0041124820709228516s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:47.943745 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08, now test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e)
[0m23:51:47.943745 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e, idle-time=0.005129337310791016s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Reusing connection previously named test.dbt_italy.unique_stg_bakehouse_sales_franchises_franchiseID.fa6d34bb08
[0m23:51:47.944745 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e, idle-time=0.005129337310791016s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Acquired connection on thread (27712, 26440), using default compute resource for model 'None'
[0m23:51:47.944745 [debug] [Thread-1 (]: Began compiling node test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e
[0m23:51:47.949737 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e"
[0m23:51:47.962427 [debug] [Thread-1 (]: Began executing node test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e
[0m23:51:47.966427 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e"
[0m23:51:47.969427 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e, idle-time=0.029810190200805664s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:47.969427 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e, idle-time=0.030811548233032227s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:47.970427 [debug] [Thread-1 (]: Using databricks connection "test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e"
[0m23:51:47.970427 [debug] [Thread-1 (]: On test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select transactionID
from `bronze`.`sal`.`stg_bakehouse_sales_transactions`
where transactionID is null



      
    ) dbt_internal_test
[0m23:51:48.475198 [debug] [Thread-1 (]: SQL status: OK in 0.500 seconds
[0m23:51:48.479199 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6e48-1a11-af20-cd6ff1f507e9) - Closing
[0m23:51:48.480199 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:48.480199 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:48.481190 [info ] [Thread-1 (]: 8 of 9 PASS not_null_stg_bakehouse_sales_transactions_transactionID ............ [[32mPASS[0m in 0.54s]
[0m23:51:48.482183 [debug] [Thread-1 (]: Finished running node test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e
[0m23:51:48.483185 [debug] [Thread-1 (]: Began running node test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6
[0m23:51:48.483185 [info ] [Thread-1 (]: 9 of 9 START test unique_stg_bakehouse_sales_transactions_transactionID ........ [RUN]
[0m23:51:48.484180 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e, idle-time=0.003981113433837891s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:48.485189 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e, now test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6)
[0m23:51:48.485189 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6, idle-time=0.004990577697753906s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Reusing connection previously named test.dbt_italy.not_null_stg_bakehouse_sales_transactions_transactionID.73ca675c5e
[0m23:51:48.486197 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6, idle-time=0.005998373031616211s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Acquired connection on thread (27712, 26440), using default compute resource for model 'None'
[0m23:51:48.486197 [debug] [Thread-1 (]: Began compiling node test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6
[0m23:51:48.490212 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6"
[0m23:51:48.493183 [debug] [Thread-1 (]: Began executing node test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6
[0m23:51:48.495196 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6"
[0m23:51:48.497182 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6, idle-time=0.0169830322265625s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Checking idleness
[0m23:51:48.497182 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6, idle-time=0.0169830322265625s, acquire-count=1, language=sql, thread-identifier=(27712, 26440), compute-name=) - Retrieving connection
[0m23:51:48.498194 [debug] [Thread-1 (]: Using databricks connection "test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6"
[0m23:51:48.498194 [debug] [Thread-1 (]: On test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    transactionID as unique_field,
    count(*) as n_records

from `bronze`.`sal`.`stg_bakehouse_sales_transactions`
where transactionID is not null
group by transactionID
having count(*) > 1



      
    ) dbt_internal_test
[0m23:51:49.034444 [debug] [Thread-1 (]: SQL status: OK in 0.540 seconds
[0m23:51:49.037450 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a6-6374-1997-b2ea-1435411957e1, command-id=01eff0a6-6e99-127d-94de-977a81c53efd) - Closing
[0m23:51:49.038440 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:49.039439 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1892102374256, session-id=01eff0a6-6374-1997-b2ea-1435411957e1, name=test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6, idle-time=0.0009996891021728516s, acquire-count=0, language=sql, thread-identifier=(27712, 26440), compute-name=) - Released connection
[0m23:51:49.039439 [info ] [Thread-1 (]: 9 of 9 PASS unique_stg_bakehouse_sales_transactions_transactionID .............. [[32mPASS[0m in 0.56s]
[0m23:51:49.040437 [debug] [Thread-1 (]: Finished running node test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6
[0m23:51:49.041941 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=19.926669597625732s, acquire-count=0, language=None, thread-identifier=(27712, 8412), compute-name=) - Checking idleness
[0m23:51:49.042948 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=19.9276762008667s, acquire-count=0, language=None, thread-identifier=(27712, 8412), compute-name=) - Reusing connection previously named master
[0m23:51:49.042948 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=19.9276762008667s, acquire-count=1, language=None, thread-identifier=(27712, 8412), compute-name=) - Acquired connection on thread (27712, 8412), using default compute resource
[0m23:51:49.043949 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=19.92867660522461s, acquire-count=1, language=None, thread-identifier=(27712, 8412), compute-name=) - Checking idleness
[0m23:51:49.043949 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=None, name=master, idle-time=19.92867660522461s, acquire-count=1, language=None, thread-identifier=(27712, 8412), compute-name=) - Retrieving connection
[0m23:51:49.044964 [debug] [MainThread]: On master: ROLLBACK
[0m23:51:49.044964 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:51:49.361520 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-6f0e-1484-bac3-2d9931b2d492) - Created
[0m23:51:49.363532 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:51:49.363532 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=01eff0a6-6f0e-1484-bac3-2d9931b2d492, name=master, idle-time=0.0010082721710205078s, acquire-count=1, language=None, thread-identifier=(27712, 8412), compute-name=) - Checking idleness
[0m23:51:49.363532 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=01eff0a6-6f0e-1484-bac3-2d9931b2d492, name=master, idle-time=0.0010082721710205078s, acquire-count=1, language=None, thread-identifier=(27712, 8412), compute-name=) - Retrieving connection
[0m23:51:49.364540 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m23:51:49.364540 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m23:51:49.365539 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1892099366800, session-id=01eff0a6-6f0e-1484-bac3-2d9931b2d492, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(27712, 8412), compute-name=) - Released connection
[0m23:51:49.366540 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:51:49.366540 [debug] [MainThread]: On master: ROLLBACK
[0m23:51:49.366540 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:51:49.367539 [debug] [MainThread]: On master: Close
[0m23:51:49.367539 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-6f0e-1484-bac3-2d9931b2d492) - Closing
[0m23:51:49.491553 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m23:51:49.492565 [debug] [MainThread]: On list_bronze: Close
[0m23:51:49.492565 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-6241-1613-bbca-5013439ef5e8) - Closing
[0m23:51:49.623459 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m23:51:49.624458 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m23:51:49.624458 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:51:49.625459 [debug] [MainThread]: On list_bronze_sal: Close
[0m23:51:49.625459 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-62ac-12e1-9183-b4f1d436f7d1) - Closing
[0m23:51:49.762199 [debug] [MainThread]: Connection 'test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6' was properly closed.
[0m23:51:49.763193 [debug] [MainThread]: On test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6: ROLLBACK
[0m23:51:49.764188 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m23:51:49.764188 [debug] [MainThread]: On test.dbt_italy.unique_stg_bakehouse_sales_transactions_transactionID.b70ae93aa6: Close
[0m23:51:49.765204 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a6-6374-1997-b2ea-1435411957e1) - Closing
[0m23:51:49.895898 [info ] [MainThread]: 
[0m23:51:49.896895 [info ] [MainThread]: Finished running 3 incremental models, 6 data tests in 0 hours 0 minutes and 22.59 seconds (22.59s).
[0m23:51:49.898896 [debug] [MainThread]: Command end result
[0m23:51:49.934904 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m23:51:49.939908 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m23:51:49.949423 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m23:51:49.950423 [info ] [MainThread]: 
[0m23:51:49.951421 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m23:51:49.952423 [info ] [MainThread]: 
[0m23:51:49.953421 [error] [MainThread]: [31mFailure in test unique_stg_bakehouse_sales_customer_customerID (models\bronze\stg_bakehouse_sales_customer.yml)[0m
[0m23:51:49.954421 [error] [MainThread]:   Got 300 results, configured to fail if != 0
[0m23:51:49.954421 [info ] [MainThread]: 
[0m23:51:49.955422 [info ] [MainThread]:   compiled code at target\compiled\dbt_italy\models\bronze\stg_bakehouse_sales_customer.yml\unique_stg_bakehouse_sales_customer_customerID.sql
[0m23:51:49.956421 [info ] [MainThread]: 
[0m23:51:49.957423 [error] [MainThread]: [31mFailure in test unique_stg_bakehouse_sales_franchises_franchiseID (models\bronze\stg_bakehouse_sales_franchises.yml)[0m
[0m23:51:49.958425 [error] [MainThread]:   Got 48 results, configured to fail if != 0
[0m23:51:49.958425 [info ] [MainThread]: 
[0m23:51:49.959714 [info ] [MainThread]:   compiled code at target\compiled\dbt_italy\models\bronze\stg_bakehouse_sales_franchises.yml\unique_stg_bakehouse_sales_franchises_franchiseID.sql
[0m23:51:49.960720 [info ] [MainThread]: 
[0m23:51:49.961730 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=2 SKIP=0 TOTAL=9
[0m23:51:49.964267 [debug] [MainThread]: Command `dbt build` failed at 23:51:49.964267 after 25.39 seconds
[0m23:51:49.964772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8ED54E110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8EEE23E20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B8EEE23820>]}
[0m23:51:49.965779 [debug] [MainThread]: Flushing usage events
[0m23:51:50.582543 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:03:43.534771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE3E44E200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE3FDCA680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE3FDCA380>]}


============================== 00:03:43.538774 | 8e3d2262-1c20-4b3b-8603-3adfe0ed4b14 ==============================
[0m00:03:43.538774 [info ] [MainThread]: Running with dbt=1.9.2
[0m00:03:43.540341 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m00:03:44.202976 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m00:03:44.203978 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m00:03:44.203978 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m00:03:45.178602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8e3d2262-1c20-4b3b-8603-3adfe0ed4b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE3E5652D0>]}
[0m00:03:45.220620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8e3d2262-1c20-4b3b-8603-3adfe0ed4b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE41258AC0>]}
[0m00:03:45.222630 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m00:03:45.665953 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m00:03:45.924265 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m00:03:45.926242 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\silver\eph_bakehouse_sales_franchises_deduplicated.sql
[0m00:03:46.304243 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m00:03:46.317243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e3d2262-1c20-4b3b-8603-3adfe0ed4b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE5AF64B50>]}
[0m00:03:46.507291 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m00:03:46.510292 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m00:03:46.553564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e3d2262-1c20-4b3b-8603-3adfe0ed4b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE5AD83EE0>]}
[0m00:03:46.554563 [info ] [MainThread]: Found 4 models, 6 data tests, 3 sources, 608 macros
[0m00:03:46.555562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e3d2262-1c20-4b3b-8603-3adfe0ed4b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE5AD83E80>]}
[0m00:03:46.557588 [info ] [MainThread]: 
[0m00:03:46.558574 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:03:46.559569 [info ] [MainThread]: 
[0m00:03:46.560569 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29240, 35244), compute-name=) - Creating connection
[0m00:03:46.561570 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m00:03:46.562572 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29240, 35244), compute-name=) - Acquired connection on thread (29240, 35244), using default compute resource
[0m00:03:46.570568 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848357557472, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29240, 34760), compute-name=) - Creating connection
[0m00:03:46.571571 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m00:03:46.571571 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848357557472, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29240, 34760), compute-name=) - Acquired connection on thread (29240, 34760), using default compute resource
[0m00:03:46.572567 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848357557472, session-id=None, name=list_bronze, idle-time=0.000995635986328125s, acquire-count=1, language=None, thread-identifier=(29240, 34760), compute-name=) - Checking idleness
[0m00:03:46.573071 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848357557472, session-id=None, name=list_bronze, idle-time=0.0015006065368652344s, acquire-count=1, language=None, thread-identifier=(29240, 34760), compute-name=) - Retrieving connection
[0m00:03:46.573071 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m00:03:46.574077 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m00:03:46.574077 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:03:47.265051 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a8-1abe-1c7a-b49e-84da8ca7aca5) - Created
[0m00:04:49.059145 [debug] [ThreadPool]: SQL status: OK in 62.490 seconds
[0m00:04:49.061146 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a8-1abe-1c7a-b49e-84da8ca7aca5, command-id=01eff0a8-3ecb-1b8d-988c-939bdcf1cf9a) - Closing
[0m00:04:49.061146 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848357557472, session-id=01eff0a8-1abe-1c7a-b49e-84da8ca7aca5, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29240, 34760), compute-name=) - Released connection
[0m00:04:49.063146 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848358815632, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29240, 34548), compute-name=) - Creating connection
[0m00:04:49.064145 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m00:04:49.065144 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848358815632, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29240, 34548), compute-name=) - Acquired connection on thread (29240, 34548), using default compute resource
[0m00:04:49.073721 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848358815632, session-id=None, name=list_bronze_sal, idle-time=0.009575366973876953s, acquire-count=1, language=None, thread-identifier=(29240, 34548), compute-name=) - Checking idleness
[0m00:04:49.074721 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848358815632, session-id=None, name=list_bronze_sal, idle-time=0.010576009750366211s, acquire-count=1, language=None, thread-identifier=(29240, 34548), compute-name=) - Retrieving connection
[0m00:04:49.075721 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848358815632, session-id=None, name=list_bronze_sal, idle-time=0.010576009750366211s, acquire-count=1, language=None, thread-identifier=(29240, 34548), compute-name=) - Checking idleness
[0m00:04:49.075721 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848358815632, session-id=None, name=list_bronze_sal, idle-time=0.011575937271118164s, acquire-count=1, language=None, thread-identifier=(29240, 34548), compute-name=) - Retrieving connection
[0m00:04:49.076722 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m00:04:49.076722 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m00:04:49.077722 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m00:04:49.077722 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:04:49.507679 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a8-3fef-1166-b5e3-b8f178a22043) - Created
[0m00:04:52.041099 [debug] [ThreadPool]: SQL status: OK in 2.960 seconds
[0m00:04:52.048100 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a8-3fef-1166-b5e3-b8f178a22043, command-id=01eff0a8-400a-12b9-8349-488d4f3004a3) - Closing
[0m00:04:52.049099 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1848358815632, session-id=01eff0a8-3fef-1166-b5e3-b8f178a22043, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29240, 34548), compute-name=) - Released connection
[0m00:04:52.050099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e3d2262-1c20-4b3b-8603-3adfe0ed4b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE3D0C3FA0>]}
[0m00:04:52.051099 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=65.48852729797363s, acquire-count=1, language=None, thread-identifier=(29240, 35244), compute-name=) - Checking idleness
[0m00:04:52.051099 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=65.48852729797363s, acquire-count=1, language=None, thread-identifier=(29240, 35244), compute-name=) - Retrieving connection
[0m00:04:52.052099 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=65.4895269870758s, acquire-count=1, language=None, thread-identifier=(29240, 35244), compute-name=) - Checking idleness
[0m00:04:52.052099 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=65.4895269870758s, acquire-count=1, language=None, thread-identifier=(29240, 35244), compute-name=) - Retrieving connection
[0m00:04:52.053099 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m00:04:52.054098 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m00:04:52.054098 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29240, 35244), compute-name=) - Released connection
[0m00:04:52.056137 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:04:52.057137 [info ] [Thread-1 (]: 1 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m00:04:52.058137 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29240, 6848), compute-name=) - Creating connection
[0m00:04:52.059137 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m00:04:52.060136 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Acquired connection on thread (29240, 6848), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m00:04:52.060136 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:04:52.070683 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:04:52.072723 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:04:52.134725 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.07358789443969727s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:04:52.135724 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.07558774948120117s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:04:52.136723 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.07658696174621582s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:04:52.137723 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.07758688926696777s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:04:52.138723 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m00:04:52.138723 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:04:52.139723 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_customer'
  
[0m00:04:52.140724 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m00:04:52.468376 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed) - Created
[0m00:04:53.152256 [debug] [Thread-1 (]: SQL status: OK in 1.010 seconds
[0m00:04:53.155251 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-41c8-1cc2-b942-11093ab720e4) - Closing
[0m00:04:53.160269 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.6908912658691406s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:04:53.161269 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.6918911933898926s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:04:53.162238 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:04:53.162238 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m00:04:53.929402 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m00:04:53.932402 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-4232-19f8-8de9-cf5ed1055efc) - Closing
[0m00:04:53.945402 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.4760246276855469s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:04:53.946403 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.4770257472991943s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:04:53.946403 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:04:53.947401 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    create or replace temporary view `stg_bakehouse_sales_customer__dbt_tmp` as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m00:04:57.031425 [debug] [Thread-1 (]: SQL status: OK in 3.080 seconds
[0m00:04:57.032425 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-42aa-14c8-befa-e5bf86446f4f) - Closing
[0m00:04:57.061478 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.592100143432617s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:04:57.062476 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.593097925186157s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:04:57.063473 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:04:57.064472 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m00:04:57.553121 [debug] [Thread-1 (]: SQL status: OK in 0.490 seconds
[0m00:04:57.556121 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-4486-18a2-85df-bc5ffb51a337) - Closing
[0m00:04:57.560120 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=5.090742349624634s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:04:57.561159 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=5.0917816162109375s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:04:57.561159 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:04:57.562159 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `stg_bakehouse_sales_customer__dbt_tmp`
  
[0m00:04:58.054083 [debug] [Thread-1 (]: SQL status: OK in 0.490 seconds
[0m00:04:58.057083 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-44d1-1a9f-9d0d-2ef25827c8eb) - Closing
[0m00:04:58.067122 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:04:58.069123 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=5.599745035171509s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:04:58.070123 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=5.60074520111084s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:04:58.070123 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:04:58.071123 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_customer` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_customer__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m00:05:12.364395 [debug] [Thread-1 (]: SQL status: OK in 14.290 seconds
[0m00:05:12.366396 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-451f-186e-9b8f-ce63466cac5f) - Closing
[0m00:05:12.532676 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Released connection
[0m00:05:12.533675 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Released connection
[0m00:05:12.535674 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e3d2262-1c20-4b3b-8603-3adfe0ed4b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE3D03AEF0>]}
[0m00:05:12.536675 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 20.48s]
[0m00:05:12.537674 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:05:12.538673 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:05:12.538673 [info ] [Thread-1 (]: 2 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m00:05:12.539673 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.005998134613037109s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:12.540673 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m00:05:12.540673 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.006998300552368164s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m00:05:12.541674 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007999181747436523s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Acquired connection on thread (29240, 6848), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m00:05:12.541674 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:05:12.544676 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:12.546675 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:05:12.557264 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.02304983139038086s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:12.558852 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.025177478790283203s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:12.559393 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:12.560436 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_franchises'
  
[0m00:05:13.011727 [debug] [Thread-1 (]: SQL status: OK in 0.450 seconds
[0m00:05:13.014731 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-4dc1-1aa0-857e-c317c2f27eb0) - Closing
[0m00:05:13.020730 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.48705458641052246s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:13.022727 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.48905229568481445s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:13.023733 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:13.024727 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m00:05:13.378667 [debug] [Thread-1 (]: SQL status: OK in 0.350 seconds
[0m00:05:13.382716 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-4e09-1954-ad30-31bae6f1e265) - Closing
[0m00:05:13.384715 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.8510398864746094s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:13.385710 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.8520350456237793s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:13.386712 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:13.387710 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    create or replace temporary view `stg_bakehouse_sales_franchises__dbt_tmp` as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m00:05:14.521098 [debug] [Thread-1 (]: SQL status: OK in 1.130 seconds
[0m00:05:14.523091 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-4e40-14df-bd4d-0217878ac809) - Closing
[0m00:05:14.527095 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.993420124053955s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:14.528098 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.9944229125976562s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:14.529093 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:14.530096 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m00:05:14.829159 [debug] [Thread-1 (]: SQL status: OK in 0.300 seconds
[0m00:05:14.832156 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-4eee-1812-8b52-26bab576e2c3) - Closing
[0m00:05:14.836156 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.302481174468994s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:14.837156 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.303480625152588s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:14.838154 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:14.839155 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `stg_bakehouse_sales_franchises__dbt_tmp`
  
[0m00:05:15.159880 [debug] [Thread-1 (]: SQL status: OK in 0.320 seconds
[0m00:05:15.162881 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-4f1d-1856-a1fd-d0f391f1790d) - Closing
[0m00:05:15.163880 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:15.166880 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.6322054862976074s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:15.167883 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.6342082023620605s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:15.167883 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:15.168885 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_franchises` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_franchises__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m00:05:23.639937 [debug] [Thread-1 (]: SQL status: OK in 8.470 seconds
[0m00:05:23.640938 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-4f4f-1bac-975a-ed0d77b39fbd) - Closing
[0m00:05:23.778480 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Released connection
[0m00:05:23.779479 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Released connection
[0m00:05:23.780479 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e3d2262-1c20-4b3b-8603-3adfe0ed4b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE5B20BB20>]}
[0m00:05:23.781478 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 11.24s]
[0m00:05:23.783478 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:05:23.783478 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:05:23.784477 [info ] [Thread-1 (]: 3 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_transactions . [RUN]
[0m00:05:23.785476 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.005997657775878906s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:23.786476 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_franchises, now model.dbt_italy.stg_bakehouse_sales_transactions)
[0m00:05:23.786476 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.006997585296630859s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:05:23.787476 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.007997751235961914s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Acquired connection on thread (29240, 6848), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_transactions`'
[0m00:05:23.787476 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:05:23.793478 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:23.796523 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:05:23.806527 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.02704763412475586s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:23.808522 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.028044462203979492s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:23.808522 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:23.808522 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_transactions'
  
[0m00:05:24.222917 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m00:05:24.224915 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-5476-1823-8d0a-1002043a0353) - Closing
[0m00:05:24.226918 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.44743895530700684s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:24.227916 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.4484372138977051s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:24.227916 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:24.228915 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m00:05:24.551735 [debug] [Thread-1 (]: SQL status: OK in 0.320 seconds
[0m00:05:24.554734 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-54b5-1dad-8379-90152f907211) - Closing
[0m00:05:24.556733 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.7772538661956787s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:24.558729 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.7792503833770752s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:24.558729 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:24.559735 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */

  
    create or replace temporary view `stg_bakehouse_sales_transactions__dbt_tmp` as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_transactions`

  WHERE dateTime > (SELECT max(dt_ingestion_timestamp) from `bronze`.`sal`.`stg_bakehouse_sales_transactions`)

  
[0m00:05:25.704876 [debug] [Thread-1 (]: SQL status: OK in 1.140 seconds
[0m00:05:25.706878 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-54e8-1aa9-9347-82c9513d23cc) - Closing
[0m00:05:25.715469 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.935990333557129s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:25.717465 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.937986135482788s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:25.717465 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:25.718463 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `stg_bakehouse_sales_transactions__dbt_tmp`
  
[0m00:05:26.123024 [debug] [Thread-1 (]: SQL status: OK in 0.400 seconds
[0m00:05:26.127024 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-5599-12a1-9b7c-40201b43f359) - Closing
[0m00:05:26.131021 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.351541757583618s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:26.133017 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.352541923522949s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:26.133017 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:26.134017 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m00:05:26.427388 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m00:05:26.432389 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-55d8-10bf-9b8d-ab0e58eda9ac) - Closing
[0m00:05:26.440392 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:26.444375 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.6648964881896973s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:26.446377 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.666898488998413s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Retrieving connection
[0m00:05:26.447377 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:26.449383 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
insert into table `bronze`.`sal`.`stg_bakehouse_sales_transactions` (`transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp`)
select `transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp` from `stg_bakehouse_sales_transactions__dbt_tmp`

[0m00:05:33.111324 [debug] [Thread-1 (]: SQL status: OK in 6.660 seconds
[0m00:05:33.113326 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, command-id=01eff0a8-5608-17bf-bcac-d8668a4c84ff) - Closing
[0m00:05:33.255549 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Released connection
[0m00:05:33.256544 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Released connection
[0m00:05:33.257544 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e3d2262-1c20-4b3b-8603-3adfe0ed4b14', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE5B20BB20>]}
[0m00:05:33.258545 [info ] [Thread-1 (]: 3 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_transactions  [[32mOK[0m in 9.47s]
[0m00:05:33.260545 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:05:33.261550 [debug] [Thread-1 (]: Began running node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:05:33.262544 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.006000041961669922s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Checking idleness
[0m00:05:33.263548 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_transactions, now model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated)
[0m00:05:33.264548 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.008004188537597656s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:05:33.265549 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.009004831314086914s, acquire-count=1, language=sql, thread-identifier=(29240, 6848), compute-name=) - Acquired connection on thread (29240, 6848), using default compute resource for model 'None'
[0m00:05:33.266547 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:05:33.271550 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated"
[0m00:05:33.276545 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Released connection
[0m00:05:33.279009 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1848349172704, session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29240, 6848), compute-name=) - Released connection
[0m00:05:33.280217 [debug] [Thread-1 (]: Finished running node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:05:33.281814 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=41.227715492248535s, acquire-count=0, language=None, thread-identifier=(29240, 35244), compute-name=) - Checking idleness
[0m00:05:33.282855 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=41.22875642776489s, acquire-count=0, language=None, thread-identifier=(29240, 35244), compute-name=) - Reusing connection previously named master
[0m00:05:33.283903 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=41.229804277420044s, acquire-count=1, language=None, thread-identifier=(29240, 35244), compute-name=) - Acquired connection on thread (29240, 35244), using default compute resource
[0m00:05:33.285899 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=41.23180079460144s, acquire-count=1, language=None, thread-identifier=(29240, 35244), compute-name=) - Checking idleness
[0m00:05:33.286904 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=None, name=master, idle-time=41.23280596733093s, acquire-count=1, language=None, thread-identifier=(29240, 35244), compute-name=) - Retrieving connection
[0m00:05:33.287899 [debug] [MainThread]: On master: ROLLBACK
[0m00:05:33.287899 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:05:33.705448 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a8-5a4b-1c1d-bd00-660ae1f461bc) - Created
[0m00:05:33.706448 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:05:33.706448 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=01eff0a8-5a4b-1c1d-bd00-660ae1f461bc, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29240, 35244), compute-name=) - Checking idleness
[0m00:05:33.707442 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=01eff0a8-5a4b-1c1d-bd00-660ae1f461bc, name=master, idle-time=0.0009944438934326172s, acquire-count=1, language=None, thread-identifier=(29240, 35244), compute-name=) - Retrieving connection
[0m00:05:33.708486 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m00:05:33.709483 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m00:05:33.709483 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1848360051968, session-id=01eff0a8-5a4b-1c1d-bd00-660ae1f461bc, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29240, 35244), compute-name=) - Released connection
[0m00:05:33.710482 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:05:33.711487 [debug] [MainThread]: On master: ROLLBACK
[0m00:05:33.712482 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:05:33.713484 [debug] [MainThread]: On master: Close
[0m00:05:33.714483 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a8-5a4b-1c1d-bd00-660ae1f461bc) - Closing
[0m00:05:33.849742 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m00:05:33.850743 [debug] [MainThread]: On list_bronze: Close
[0m00:05:33.851743 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a8-1abe-1c7a-b49e-84da8ca7aca5) - Closing
[0m00:05:33.999391 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m00:05:34.000391 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m00:05:34.002385 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:05:34.003386 [debug] [MainThread]: On list_bronze_sal: Close
[0m00:05:34.004387 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a8-3fef-1166-b5e3-b8f178a22043) - Closing
[0m00:05:34.141695 [debug] [MainThread]: Connection 'model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated' was properly closed.
[0m00:05:34.142697 [debug] [MainThread]: On model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated: ROLLBACK
[0m00:05:34.143694 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:05:34.144697 [debug] [MainThread]: On model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated: Close
[0m00:05:34.145693 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a8-41ba-1bfb-a28d-30f6a35834ed) - Closing
[0m00:05:34.339960 [info ] [MainThread]: 
[0m00:05:34.341957 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 1 minutes and 47.78 seconds (107.78s).
[0m00:05:34.353115 [debug] [MainThread]: Command end result
[0m00:05:34.385114 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m00:05:34.390112 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m00:05:34.397115 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m00:05:34.397115 [info ] [MainThread]: 
[0m00:05:34.398113 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:05:34.399116 [info ] [MainThread]: 
[0m00:05:34.400113 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m00:05:34.402115 [debug] [MainThread]: Command `dbt run` succeeded at 00:05:34.402115 after 111.02 seconds
[0m00:05:34.403114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE3E44E200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE3E5935B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AE5AD638B0>]}
[0m00:05:34.403114 [debug] [MainThread]: Flushing usage events
[0m00:05:35.068657 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:05:43.550600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F4564E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F46FCA5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F46FCA2F0>]}


============================== 00:05:43.555596 | b7089cce-3e82-4be9-b0c5-0968abc07b2d ==============================
[0m00:05:43.555596 [info ] [MainThread]: Running with dbt=1.9.2
[0m00:05:43.556596 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'dbt_italy', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m00:05:44.376281 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m00:05:44.377281 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m00:05:44.378279 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m00:05:45.634044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b7089cce-3e82-4be9-b0c5-0968abc07b2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F45781D50>]}
[0m00:05:45.686795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b7089cce-3e82-4be9-b0c5-0968abc07b2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F489836A0>]}
[0m00:05:45.687403 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m00:05:46.197389 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m00:05:46.496081 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m00:05:46.497078 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\silver\eph_bakehouse_sales_franchises_deduplicated.yml
[0m00:05:46.608611 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_bakehouse_sales_franchises_deduplicated' in the 'models' section of file 'models\silver\eph_bakehouse_sales_franchises_deduplicated.yml'
[0m00:05:46.725162 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_italy.unique_stg_bakehouse_sales_franchises_deduplicated_franchiseID.edd57efa29' (models\silver\eph_bakehouse_sales_franchises_deduplicated.yml) depends on a node named 'stg_bakehouse_sales_franchises_deduplicated' in package '' which was not found
[0m00:05:46.727175 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_italy.not_null_stg_bakehouse_sales_franchises_deduplicated_franchiseID.6c4e1f85cf' (models\silver\eph_bakehouse_sales_franchises_deduplicated.yml) depends on a node named 'stg_bakehouse_sales_franchises_deduplicated' in package '' which was not found
[0m00:05:46.801722 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m00:05:46.821695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7089cce-3e82-4be9-b0c5-0968abc07b2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F6206D870>]}
[0m00:05:47.024041 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m00:05:47.028081 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m00:05:47.053663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7089cce-3e82-4be9-b0c5-0968abc07b2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F61E8FDC0>]}
[0m00:05:47.054662 [info ] [MainThread]: Found 4 models, 6 data tests, 3 sources, 608 macros
[0m00:05:47.055664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7089cce-3e82-4be9-b0c5-0968abc07b2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F61E8F520>]}
[0m00:05:47.057663 [info ] [MainThread]: 
[0m00:05:47.058665 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:05:47.059665 [info ] [MainThread]: 
[0m00:05:47.060664 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29316, 29924), compute-name=) - Creating connection
[0m00:05:47.060664 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m00:05:47.061662 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29316, 29924), compute-name=) - Acquired connection on thread (29316, 29924), using default compute resource
[0m00:05:47.068662 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407313168, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29316, 27900), compute-name=) - Creating connection
[0m00:05:47.069662 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m00:05:47.069662 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407313168, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29316, 27900), compute-name=) - Acquired connection on thread (29316, 27900), using default compute resource
[0m00:05:47.071666 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407313168, session-id=None, name=list_bronze, idle-time=0.0020029544830322266s, acquire-count=1, language=None, thread-identifier=(29316, 27900), compute-name=) - Checking idleness
[0m00:05:47.072665 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407313168, session-id=None, name=list_bronze, idle-time=0.0030024051666259766s, acquire-count=1, language=None, thread-identifier=(29316, 27900), compute-name=) - Retrieving connection
[0m00:05:47.073663 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m00:05:47.073663 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m00:05:47.074666 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:05:47.384261 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a8-6275-1fee-a12f-edab6373c0b2) - Created
[0m00:05:47.698720 [debug] [ThreadPool]: SQL status: OK in 0.620 seconds
[0m00:05:47.700686 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a8-6275-1fee-a12f-edab6373c0b2, command-id=01eff0a8-6281-1701-a075-76957bf5b1fe) - Closing
[0m00:05:47.701690 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407313168, session-id=01eff0a8-6275-1fee-a12f-edab6373c0b2, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29316, 27900), compute-name=) - Released connection
[0m00:05:47.703689 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407302368, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29316, 19844), compute-name=) - Creating connection
[0m00:05:47.703689 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m00:05:47.704688 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407302368, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(29316, 19844), compute-name=) - Acquired connection on thread (29316, 19844), using default compute resource
[0m00:05:47.713719 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407302368, session-id=None, name=list_bronze_sal, idle-time=0.009031057357788086s, acquire-count=1, language=None, thread-identifier=(29316, 19844), compute-name=) - Checking idleness
[0m00:05:47.714721 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407302368, session-id=None, name=list_bronze_sal, idle-time=0.010032415390014648s, acquire-count=1, language=None, thread-identifier=(29316, 19844), compute-name=) - Retrieving connection
[0m00:05:47.714721 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407302368, session-id=None, name=list_bronze_sal, idle-time=0.010032415390014648s, acquire-count=1, language=None, thread-identifier=(29316, 19844), compute-name=) - Checking idleness
[0m00:05:47.715719 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407302368, session-id=None, name=list_bronze_sal, idle-time=0.011031389236450195s, acquire-count=1, language=None, thread-identifier=(29316, 19844), compute-name=) - Retrieving connection
[0m00:05:47.716705 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m00:05:47.716705 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m00:05:47.717706 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m00:05:47.717706 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:05:48.043508 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0a8-62d6-1b5a-855c-e11d48747600) - Created
[0m00:05:48.458905 [debug] [ThreadPool]: SQL status: OK in 0.740 seconds
[0m00:05:48.467884 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0a8-62d6-1b5a-855c-e11d48747600, command-id=01eff0a8-62e6-1564-a0a4-56c9cf3d273d) - Closing
[0m00:05:48.469887 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2677407302368, session-id=01eff0a8-62d6-1b5a-855c-e11d48747600, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29316, 19844), compute-name=) - Released connection
[0m00:05:48.472884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7089cce-3e82-4be9-b0c5-0968abc07b2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F441C3FA0>]}
[0m00:05:48.473885 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=1.4122231006622314s, acquire-count=1, language=None, thread-identifier=(29316, 29924), compute-name=) - Checking idleness
[0m00:05:48.473885 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=1.4122231006622314s, acquire-count=1, language=None, thread-identifier=(29316, 29924), compute-name=) - Retrieving connection
[0m00:05:48.474888 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=1.4132254123687744s, acquire-count=1, language=None, thread-identifier=(29316, 29924), compute-name=) - Checking idleness
[0m00:05:48.474888 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=1.4132254123687744s, acquire-count=1, language=None, thread-identifier=(29316, 29924), compute-name=) - Retrieving connection
[0m00:05:48.475887 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m00:05:48.475887 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m00:05:48.476884 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29316, 29924), compute-name=) - Released connection
[0m00:05:48.480090 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:05:48.481090 [info ] [Thread-1 (]: 1 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m00:05:48.482089 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(29316, 33332), compute-name=) - Creating connection
[0m00:05:48.483088 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m00:05:48.484107 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Acquired connection on thread (29316, 33332), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m00:05:48.484107 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:05:48.492091 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:05:48.495092 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:05:48.535157 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.05206799507141113s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:48.537142 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.05405306816101074s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:48.537142 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.05405306816101074s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:48.538157 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0550689697265625s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:48.539128 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m00:05:48.540129 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:05:48.541128 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_customer'
  
[0m00:05:48.541128 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m00:05:48.823525 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff) - Created
[0m00:05:49.260796 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m00:05:49.264804 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-635d-1e15-b2ba-f3cc2905378f) - Closing
[0m00:05:49.274802 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.4492762088775635s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:49.276805 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.4512789249420166s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:49.277800 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:05:49.278796 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m00:05:49.586647 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m00:05:49.590649 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-63a3-1286-b466-019ea1960b68) - Closing
[0m00:05:49.605673 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.7801470756530762s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:49.607680 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.7811548709869385s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:49.607680 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:05:49.608654 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    create or replace temporary view `stg_bakehouse_sales_customer__dbt_tmp` as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m00:05:50.322125 [debug] [Thread-1 (]: SQL status: OK in 0.710 seconds
[0m00:05:50.323101 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-63d5-166e-af2b-858ffbf930a2) - Closing
[0m00:05:50.348727 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.5222041606903076s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:50.348727 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.5232012271881104s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:50.349728 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:05:50.350716 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m00:05:50.583358 [debug] [Thread-1 (]: SQL status: OK in 0.230 seconds
[0m00:05:50.586365 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-6445-1d39-85e8-61793cae2f63) - Closing
[0m00:05:50.589358 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.7638318538665771s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:50.590345 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.7638318538665771s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:50.590345 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:05:50.591340 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `stg_bakehouse_sales_customer__dbt_tmp`
  
[0m00:05:50.910195 [debug] [Thread-1 (]: SQL status: OK in 0.320 seconds
[0m00:05:50.912193 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-646b-1208-b87a-eec97a4dd439) - Closing
[0m00:05:50.920163 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:05:50.922161 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=2.096634864807129s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:50.923164 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=2.0976381301879883s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:50.924162 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:05:50.924162 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_customer` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_customer__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m00:05:53.780465 [debug] [Thread-1 (]: SQL status: OK in 2.850 seconds
[0m00:05:53.781462 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-649e-18f1-9d15-217a02118a89) - Closing
[0m00:05:53.811462 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Released connection
[0m00:05:53.812461 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Released connection
[0m00:05:53.814461 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7089cce-3e82-4be9-b0c5-0968abc07b2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F61E60250>]}
[0m00:05:53.815462 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 5.33s]
[0m00:05:53.817462 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:05:53.817462 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:05:53.818462 [info ] [Thread-1 (]: 2 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m00:05:53.819461 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.006999969482421875s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:53.820461 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m00:05:53.820461 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007999897003173828s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m00:05:53.821477 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.009015321731567383s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Acquired connection on thread (29316, 33332), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m00:05:53.821477 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:05:53.828465 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:53.831464 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:05:53.838505 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.026043176651000977s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:53.839505 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.02704310417175293s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:53.840505 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:53.840505 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_franchises'
  
[0m00:05:54.178829 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m00:05:54.180830 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-665b-10b8-a364-fe6d77e5c5e5) - Closing
[0m00:05:54.182831 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.37036991119384766s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:54.183830 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.371368408203125s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:54.183830 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:54.184829 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m00:05:54.439071 [debug] [Thread-1 (]: SQL status: OK in 0.250 seconds
[0m00:05:54.442070 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-668f-1b9f-aa2b-22644f5f0079) - Closing
[0m00:05:54.444071 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.6306090354919434s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:54.444071 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.6316101551055908s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:54.445069 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:54.446070 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    create or replace temporary view `stg_bakehouse_sales_franchises__dbt_tmp` as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m00:05:55.037271 [debug] [Thread-1 (]: SQL status: OK in 0.590 seconds
[0m00:05:55.039274 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-66b7-11fe-8e02-54d5c7fe00df) - Closing
[0m00:05:55.043272 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.2308108806610107s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:55.044272 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.2318108081817627s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:55.045272 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:55.046274 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m00:05:55.288424 [debug] [Thread-1 (]: SQL status: OK in 0.240 seconds
[0m00:05:55.291430 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-6713-12c2-a923-ec40f29935a2) - Closing
[0m00:05:55.295440 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.4829785823822021s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:55.296452 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.4839909076690674s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:55.297789 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:55.297789 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `stg_bakehouse_sales_franchises__dbt_tmp`
  
[0m00:05:55.603999 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m00:05:55.606000 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-6739-19ac-b8de-8bb620d6dd22) - Closing
[0m00:05:55.607856 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:55.608865 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.796403408050537s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:55.609990 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.7975282669067383s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:55.609990 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:05:55.611000 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_franchises` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_franchises__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m00:05:58.544552 [debug] [Thread-1 (]: SQL status: OK in 2.930 seconds
[0m00:05:58.545552 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-6768-1719-943e-8ffd8c90fe4a) - Closing
[0m00:05:58.548556 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Released connection
[0m00:05:58.549552 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Released connection
[0m00:05:58.551059 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7089cce-3e82-4be9-b0c5-0968abc07b2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F468B6C50>]}
[0m00:05:58.552072 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 4.73s]
[0m00:05:58.554070 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:05:58.554070 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:05:58.555069 [info ] [Thread-1 (]: 3 of 3 START sql incremental model bronze.sal.stg_bakehouse_sales_transactions . [RUN]
[0m00:05:58.557069 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0075168609619140625s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:58.558068 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_franchises, now model.dbt_italy.stg_bakehouse_sales_transactions)
[0m00:05:58.558068 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.00851583480834961s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:05:58.559073 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.009520530700683594s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Acquired connection on thread (29316, 33332), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_transactions`'
[0m00:05:58.560070 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:05:58.571067 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:58.574071 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:05:58.580067 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.03051471710205078s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:58.581070 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.031517744064331055s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:58.582076 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:58.583069 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_transactions'
  
[0m00:05:58.994206 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m00:05:58.996206 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-692f-11c7-9b54-6faf282976ac) - Closing
[0m00:05:59.000206 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.4506540298461914s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:59.001208 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.45165538787841797s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:59.002215 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:59.002215 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m00:05:59.234865 [debug] [Thread-1 (]: SQL status: OK in 0.230 seconds
[0m00:05:59.236872 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-696e-1a5c-b6f5-f3a9f4e4815b) - Closing
[0m00:05:59.239868 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.6893200874328613s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:59.239868 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.6903154850006104s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:59.240868 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:59.241868 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */

  
    create or replace temporary view `stg_bakehouse_sales_transactions__dbt_tmp` as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_transactions`

  WHERE dateTime > (SELECT max(dt_ingestion_timestamp) from `bronze`.`sal`.`stg_bakehouse_sales_transactions`)

  
[0m00:05:59.907254 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m00:05:59.909279 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-6992-1c0b-9edf-1be5a4ec00bf) - Closing
[0m00:05:59.915284 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.3657317161560059s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:05:59.916283 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.3667304515838623s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:05:59.916283 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:05:59.917340 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `stg_bakehouse_sales_transactions__dbt_tmp`
  
[0m00:06:00.295673 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m00:06:00.297675 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-6a03-1344-902f-5a13e485add7) - Closing
[0m00:06:00.299674 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.7501215934753418s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:06:00.300674 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.751122236251831s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:06:00.300674 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:06:00.301687 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m00:06:00.632445 [debug] [Thread-1 (]: SQL status: OK in 0.330 seconds
[0m00:06:00.634459 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-6a3b-14e2-980c-3c6096c3d067) - Closing
[0m00:06:00.638482 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:06:00.640471 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.09091854095459s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:06:00.641472 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.09091854095459s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Retrieving connection
[0m00:06:00.641472 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:06:00.642476 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
insert into table `bronze`.`sal`.`stg_bakehouse_sales_transactions` (`transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp`)
select `transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp` from `stg_bakehouse_sales_transactions__dbt_tmp`

[0m00:06:02.879070 [debug] [Thread-1 (]: SQL status: OK in 2.240 seconds
[0m00:06:02.880078 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, command-id=01eff0a8-6a69-13a6-abcc-d40e11bc5ba5) - Closing
[0m00:06:02.882070 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Released connection
[0m00:06:02.883052 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Released connection
[0m00:06:02.883052 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7089cce-3e82-4be9-b0c5-0968abc07b2d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F62052020>]}
[0m00:06:02.884051 [info ] [Thread-1 (]: 3 of 3 OK created sql incremental model bronze.sal.stg_bakehouse_sales_transactions  [[32mOK[0m in 4.33s]
[0m00:06:02.885051 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:06:02.886052 [debug] [Thread-1 (]: Began running node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:06:02.886052 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0029997825622558594s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Checking idleness
[0m00:06:02.887051 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_transactions, now model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated)
[0m00:06:02.888054 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.005002260208129883s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:06:02.888054 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.005002260208129883s, acquire-count=1, language=sql, thread-identifier=(29316, 33332), compute-name=) - Acquired connection on thread (29316, 33332), using default compute resource for model 'None'
[0m00:06:02.889051 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:06:02.893051 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated"
[0m00:06:02.894838 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Released connection
[0m00:06:02.894838 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2677407089184, session-id=01eff0a8-6351-1445-bb19-8de18794b6ff, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(29316, 33332), compute-name=) - Released connection
[0m00:06:02.895841 [debug] [Thread-1 (]: Finished running node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:06:02.897351 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=14.420467376708984s, acquire-count=0, language=None, thread-identifier=(29316, 29924), compute-name=) - Checking idleness
[0m00:06:02.897856 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=14.420972347259521s, acquire-count=0, language=None, thread-identifier=(29316, 29924), compute-name=) - Reusing connection previously named master
[0m00:06:02.897856 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=14.420972347259521s, acquire-count=1, language=None, thread-identifier=(29316, 29924), compute-name=) - Acquired connection on thread (29316, 29924), using default compute resource
[0m00:06:02.898863 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=14.421978950500488s, acquire-count=1, language=None, thread-identifier=(29316, 29924), compute-name=) - Checking idleness
[0m00:06:02.899368 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=None, name=master, idle-time=14.422484636306763s, acquire-count=1, language=None, thread-identifier=(29316, 29924), compute-name=) - Retrieving connection
[0m00:06:02.899873 [debug] [MainThread]: On master: ROLLBACK
[0m00:06:02.899873 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:06:03.427427 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a8-6c04-172e-9456-96c0d0181523) - Created
[0m00:06:03.428424 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:06:03.429423 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=01eff0a8-6c04-172e-9456-96c0d0181523, name=master, idle-time=0.0009989738464355469s, acquire-count=1, language=None, thread-identifier=(29316, 29924), compute-name=) - Checking idleness
[0m00:06:03.429423 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=01eff0a8-6c04-172e-9456-96c0d0181523, name=master, idle-time=0.0009989738464355469s, acquire-count=1, language=None, thread-identifier=(29316, 29924), compute-name=) - Retrieving connection
[0m00:06:03.430441 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m00:06:03.431441 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m00:06:03.431441 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2677407281312, session-id=01eff0a8-6c04-172e-9456-96c0d0181523, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(29316, 29924), compute-name=) - Released connection
[0m00:06:03.432441 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:06:03.433426 [debug] [MainThread]: On master: ROLLBACK
[0m00:06:03.433426 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:06:03.434441 [debug] [MainThread]: On master: Close
[0m00:06:03.434441 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a8-6c04-172e-9456-96c0d0181523) - Closing
[0m00:06:03.607630 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m00:06:03.608630 [debug] [MainThread]: On list_bronze: Close
[0m00:06:03.609630 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a8-6275-1fee-a12f-edab6373c0b2) - Closing
[0m00:06:03.777764 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m00:06:03.778765 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m00:06:03.779764 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:06:03.789394 [debug] [MainThread]: On list_bronze_sal: Close
[0m00:06:03.790380 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a8-62d6-1b5a-855c-e11d48747600) - Closing
[0m00:06:04.033967 [debug] [MainThread]: Connection 'model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated' was properly closed.
[0m00:06:04.033967 [debug] [MainThread]: On model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated: ROLLBACK
[0m00:06:04.034967 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:06:04.034967 [debug] [MainThread]: On model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated: Close
[0m00:06:04.035966 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0a8-6351-1445-bb19-8de18794b6ff) - Closing
[0m00:06:04.164003 [info ] [MainThread]: 
[0m00:06:04.165003 [info ] [MainThread]: Finished running 3 incremental models in 0 hours 0 minutes and 17.10 seconds (17.10s).
[0m00:06:04.167003 [debug] [MainThread]: Command end result
[0m00:06:04.193974 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m00:06:04.198971 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m00:06:04.206971 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m00:06:04.206971 [info ] [MainThread]: 
[0m00:06:04.207971 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:06:04.208973 [info ] [MainThread]: 
[0m00:06:04.209973 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m00:06:04.211971 [debug] [MainThread]: Command `dbt run` succeeded at 00:06:04.211971 after 20.87 seconds
[0m00:06:04.212973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F4564E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F620543D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026F62054670>]}
[0m00:06:04.213971 [debug] [MainThread]: Flushing usage events
[0m00:06:04.802935 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:22:01.905274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235D134E110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235D2CCA530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235D2CCA230>]}


============================== 00:22:01.910267 | de22cbc7-8ce5-4688-a60d-a69141dc7f49 ==============================
[0m00:22:01.910267 [info ] [MainThread]: Running with dbt=1.9.2
[0m00:22:01.911264 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'dbt_italy', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m00:22:02.546803 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m00:22:02.547791 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m00:22:02.547791 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m00:22:03.385408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de22cbc7-8ce5-4688-a60d-a69141dc7f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235CEF58F70>]}
[0m00:22:03.427354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'de22cbc7-8ce5-4688-a60d-a69141dc7f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235D4156980>]}
[0m00:22:03.428356 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m00:22:03.832168 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m00:22:04.035132 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m00:22:04.035132 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\silver\ent_sales_transactions.sql
[0m00:22:04.037126 [debug] [MainThread]: Partial parsing: added file: dbt_italy://models\silver\ent_sales_transactions.yml
[0m00:22:04.326269 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_bakehouse_sales_franchises_deduplicated' in the 'models' section of file 'models\silver\ent_sales_transactions.yml'
[0m00:22:04.393880 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_italy.unique_stg_bakehouse_sales_franchises_deduplicated_id_source_system_transaction_id.3940c02162' (models\silver\ent_sales_transactions.yml) depends on a node named 'stg_bakehouse_sales_franchises_deduplicated' in package '' which was not found
[0m00:22:04.396028 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_italy.not_null_stg_bakehouse_sales_franchises_deduplicated_id_source_system_transaction_id.c342d9b3e6' (models\silver\ent_sales_transactions.yml) depends on a node named 'stg_bakehouse_sales_franchises_deduplicated' in package '' which was not found
[0m00:22:04.449467 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m00:22:04.462990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'de22cbc7-8ce5-4688-a60d-a69141dc7f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235EDC75F90>]}
[0m00:22:04.546240 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m00:22:04.548747 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m00:22:04.573721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'de22cbc7-8ce5-4688-a60d-a69141dc7f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235EDED7430>]}
[0m00:22:04.574722 [info ] [MainThread]: Found 5 models, 6 data tests, 3 sources, 608 macros
[0m00:22:04.575723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de22cbc7-8ce5-4688-a60d-a69141dc7f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235EDED74C0>]}
[0m00:22:04.576730 [info ] [MainThread]: 
[0m00:22:04.577645 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:22:04.578666 [info ] [MainThread]: 
[0m00:22:04.579668 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(19900, 23508), compute-name=) - Creating connection
[0m00:22:04.579668 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m00:22:04.580659 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(19900, 23508), compute-name=) - Acquired connection on thread (19900, 23508), using default compute resource
[0m00:22:04.585654 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=None, name=list_workspace, idle-time=0s, acquire-count=0, language=None, thread-identifier=(19900, 29580), compute-name=) - Creating connection
[0m00:22:04.586646 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m00:22:04.588649 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=None, name=list_workspace, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(19900, 29580), compute-name=) - Acquired connection on thread (19900, 29580), using default compute resource
[0m00:22:04.591640 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=None, name=list_workspace, idle-time=0.0030329227447509766s, acquire-count=1, language=None, thread-identifier=(19900, 29580), compute-name=) - Checking idleness
[0m00:22:04.591640 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=None, name=list_workspace, idle-time=0.0039937496185302734s, acquire-count=1, language=None, thread-identifier=(19900, 29580), compute-name=) - Retrieving connection
[0m00:22:04.592641 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m00:22:04.592641 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m00:22:04.593639 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:22:05.547864 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b) - Created
[0m00:23:07.734229 [debug] [ThreadPool]: SQL status: OK in 63.140 seconds
[0m00:23:07.737220 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b, command-id=01eff0aa-cd46-1bc3-ba17-1072cfc11ab8) - Closing
[0m00:23:07.737220 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b, name=list_workspace, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(19900, 29580), compute-name=) - Released connection
[0m00:23:07.738218 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b, name=list_workspace, idle-time=0.0009984970092773438s, acquire-count=0, language=None, thread-identifier=(19900, 29580), compute-name=) - Checking idleness
[0m00:23:07.739215 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_workspace, now list_bronze)
[0m00:23:07.740214 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b, name=list_bronze, idle-time=0.0029942989349365234s, acquire-count=0, language=None, thread-identifier=(19900, 29580), compute-name=) - Reusing connection previously named list_workspace
[0m00:23:07.740214 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b, name=list_bronze, idle-time=0.0029942989349365234s, acquire-count=1, language=None, thread-identifier=(19900, 29580), compute-name=) - Acquired connection on thread (19900, 29580), using default compute resource
[0m00:23:07.741213 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b, name=list_bronze, idle-time=0.0039937496185302734s, acquire-count=1, language=None, thread-identifier=(19900, 29580), compute-name=) - Checking idleness
[0m00:23:07.742212 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b, name=list_bronze, idle-time=0.004992008209228516s, acquire-count=1, language=None, thread-identifier=(19900, 29580), compute-name=) - Retrieving connection
[0m00:23:07.742212 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m00:23:07.743211 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m00:23:08.102204 [debug] [ThreadPool]: SQL status: OK in 0.360 seconds
[0m00:23:08.104207 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b, command-id=01eff0aa-ce8c-11a4-a0de-7b56d639711b) - Closing
[0m00:23:08.105203 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645809312, session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(19900, 29580), compute-name=) - Released connection
[0m00:23:08.108196 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=None, name=list_bronze_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(19900, 30236), compute-name=) - Creating connection
[0m00:23:08.108196 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze_sal'
[0m00:23:08.109194 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=None, name=list_bronze_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(19900, 30236), compute-name=) - Acquired connection on thread (19900, 30236), using default compute resource
[0m00:23:08.117705 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=None, name=list_bronze_sal, idle-time=0.008511066436767578s, acquire-count=1, language=None, thread-identifier=(19900, 30236), compute-name=) - Checking idleness
[0m00:23:08.118709 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=None, name=list_bronze_sal, idle-time=0.00951528549194336s, acquire-count=1, language=None, thread-identifier=(19900, 30236), compute-name=) - Retrieving connection
[0m00:23:08.118709 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=None, name=list_bronze_sal, idle-time=0.00951528549194336s, acquire-count=1, language=None, thread-identifier=(19900, 30236), compute-name=) - Checking idleness
[0m00:23:08.119705 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=None, name=list_bronze_sal, idle-time=0.010511398315429688s, acquire-count=1, language=None, thread-identifier=(19900, 30236), compute-name=) - Retrieving connection
[0m00:23:08.120703 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m00:23:08.121250 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m00:23:08.121250 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m00:23:08.122255 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:23:08.569184 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7) - Created
[0m00:23:11.045062 [debug] [ThreadPool]: SQL status: OK in 2.920 seconds
[0m00:23:11.053042 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7, command-id=01eff0aa-cf10-1f07-8582-d0d1624374dc) - Closing
[0m00:23:11.054043 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(19900, 30236), compute-name=) - Released connection
[0m00:23:11.055041 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(19900, 30236), compute-name=) - Checking idleness
[0m00:23:11.056039 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_bronze_sal, now list_workspace_default)
[0m00:23:11.056039 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7, name=list_workspace_default, idle-time=0.001996278762817383s, acquire-count=0, language=None, thread-identifier=(19900, 30236), compute-name=) - Reusing connection previously named list_bronze_sal
[0m00:23:11.057035 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7, name=list_workspace_default, idle-time=0.002992868423461914s, acquire-count=1, language=None, thread-identifier=(19900, 30236), compute-name=) - Acquired connection on thread (19900, 30236), using default compute resource
[0m00:23:11.060042 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7, name=list_workspace_default, idle-time=0.0060002803802490234s, acquire-count=1, language=None, thread-identifier=(19900, 30236), compute-name=) - Checking idleness
[0m00:23:11.060042 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7, name=list_workspace_default, idle-time=0.0060002803802490234s, acquire-count=1, language=None, thread-identifier=(19900, 30236), compute-name=) - Retrieving connection
[0m00:23:11.061034 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m00:23:11.061034 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_workspace_default"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'workspace'
      and table_schema = 'default'
    
  
[0m00:23:11.618972 [debug] [ThreadPool]: SQL status: OK in 0.560 seconds
[0m00:23:11.621968 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7, command-id=01eff0aa-d08f-1f70-9ffd-9f5184f888e9) - Closing
[0m00:23:11.622967 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2430645806960, session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7, name=list_workspace_default, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(19900, 30236), compute-name=) - Released connection
[0m00:23:11.623965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de22cbc7-8ce5-4688-a60d-a69141dc7f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235CEFCFFA0>]}
[0m00:23:11.624970 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=67.0443115234375s, acquire-count=1, language=None, thread-identifier=(19900, 23508), compute-name=) - Checking idleness
[0m00:23:11.625963 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=67.04530429840088s, acquire-count=1, language=None, thread-identifier=(19900, 23508), compute-name=) - Retrieving connection
[0m00:23:11.626962 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=67.04630327224731s, acquire-count=1, language=None, thread-identifier=(19900, 23508), compute-name=) - Checking idleness
[0m00:23:11.626962 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=67.04630327224731s, acquire-count=1, language=None, thread-identifier=(19900, 23508), compute-name=) - Retrieving connection
[0m00:23:11.627960 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m00:23:11.627960 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m00:23:11.628959 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(19900, 23508), compute-name=) - Released connection
[0m00:23:11.633959 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:23:11.640857 [info ] [Thread-1 (]: 1 of 4 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m00:23:11.641895 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(19900, 5364), compute-name=) - Creating connection
[0m00:23:11.642896 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m00:23:11.642896 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Acquired connection on thread (19900, 5364), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m00:23:11.643892 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:23:11.653883 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:23:11.656877 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:23:11.708857 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.06495857238769531s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:11.709855 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.06695890426635742s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:11.710854 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.06795740127563477s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:11.711821 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0689249038696289s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:11.712822 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m00:23:11.713827 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:23:11.714819 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_customer'
  
[0m00:23:11.715815 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m00:23:12.050290 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567) - Created
[0m00:23:12.559327 [debug] [Thread-1 (]: SQL status: OK in 0.840 seconds
[0m00:23:12.562325 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-d11d-1bd3-a1aa-06fbd102b73d) - Closing
[0m00:23:12.569315 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.5180280208587646s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:12.570313 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.5190258026123047s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:12.571310 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:23:12.571310 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m00:23:13.356369 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m00:23:13.359160 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-d16d-1c5b-baaf-d4365fb0a9a8) - Closing
[0m00:23:13.372220 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.3199341297149658s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:13.373221 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=1.3219335079193115s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:13.374226 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:23:13.375217 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    create or replace temporary view `stg_bakehouse_sales_customer__dbt_tmp` as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m00:23:16.494140 [debug] [Thread-1 (]: SQL status: OK in 3.120 seconds
[0m00:23:16.496139 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-d1e8-17cb-8ecd-2206cdc094dc) - Closing
[0m00:23:16.527612 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.476324558258057s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:16.528612 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.477324724197388s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:16.528612 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:23:16.529610 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m00:23:16.920227 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m00:23:16.923224 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-d3ce-10fb-9db9-2eae40d38ffb) - Closing
[0m00:23:16.926220 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.874932289123535s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:16.927219 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.874932289123535s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:16.927219 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:23:16.928217 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `stg_bakehouse_sales_customer__dbt_tmp`
  
[0m00:23:17.442585 [debug] [Thread-1 (]: SQL status: OK in 0.510 seconds
[0m00:23:17.445580 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-d40a-163a-939c-128a582989ec) - Closing
[0m00:23:17.452581 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:23:17.454553 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=5.403265714645386s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:17.455550 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=5.40426230430603s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:17.456561 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:23:17.456561 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_customer` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_customer__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m00:23:31.254904 [debug] [Thread-1 (]: SQL status: OK in 13.800 seconds
[0m00:23:31.256901 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-d458-1489-ad05-37a30dd74ef1) - Closing
[0m00:23:31.415393 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Released connection
[0m00:23:31.416393 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Released connection
[0m00:23:31.419384 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de22cbc7-8ce5-4688-a60d-a69141dc7f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235EDE9D3C0>]}
[0m00:23:31.420502 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 19.77s]
[0m00:23:31.421428 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:23:31.421428 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:23:31.422387 [info ] [Thread-1 (]: 2 of 4 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m00:23:31.423386 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.005994081497192383s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:31.423386 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m00:23:31.424384 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007991313934326172s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m00:23:31.424384 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007991313934326172s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Acquired connection on thread (19900, 5364), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m00:23:31.425384 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:23:31.428379 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:23:31.430379 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:23:31.436901 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0205080509185791s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:31.437885 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.02149200439453125s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:31.438881 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:23:31.438881 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_franchises'
  
[0m00:23:31.836764 [debug] [Thread-1 (]: SQL status: OK in 0.400 seconds
[0m00:23:31.839755 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-dcaf-1263-9d71-9c419735e85f) - Closing
[0m00:23:31.842745 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.42635178565979004s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:31.843745 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.427351713180542s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:31.843745 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:23:31.844743 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m00:23:32.193184 [debug] [Thread-1 (]: SQL status: OK in 0.350 seconds
[0m00:23:32.196198 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-dced-1601-888f-3e6e72344a49) - Closing
[0m00:23:32.197206 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.7808129787445068s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:32.198206 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.7818129062652588s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:32.198206 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:23:32.199181 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    create or replace temporary view `stg_bakehouse_sales_franchises__dbt_tmp` as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m00:23:33.239317 [debug] [Thread-1 (]: SQL status: OK in 1.040 seconds
[0m00:23:33.241298 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-dd23-14f0-9522-0ba3c2abd054) - Closing
[0m00:23:33.245290 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.8278980255126953s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:33.245290 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.8288967609405518s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:33.246295 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:23:33.246295 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m00:23:33.556680 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m00:23:33.559677 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-ddc3-17be-8741-8fd9ceee59d5) - Closing
[0m00:23:33.563669 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.147275924682617s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:33.563669 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.147275924682617s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:33.564666 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:23:33.564666 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `stg_bakehouse_sales_franchises__dbt_tmp`
  
[0m00:23:33.874893 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m00:23:33.890874 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-ddf4-1931-8e9d-704752a3cdca) - Closing
[0m00:23:33.893870 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:23:33.896867 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.4794740676879883s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:33.896867 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.4804739952087402s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:33.897867 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:23:33.898865 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_franchises` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_franchises__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m00:23:38.084939 [debug] [Thread-1 (]: SQL status: OK in 4.190 seconds
[0m00:23:38.086930 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-de27-119e-a77c-162ea59c57c3) - Closing
[0m00:23:38.088926 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Released connection
[0m00:23:38.089924 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Released connection
[0m00:23:38.090924 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de22cbc7-8ce5-4688-a60d-a69141dc7f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235EDC90850>]}
[0m00:23:38.091922 [info ] [Thread-1 (]: 2 of 4 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 6.67s]
[0m00:23:38.092918 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:23:38.093918 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:23:38.093918 [info ] [Thread-1 (]: 3 of 4 START sql incremental model bronze.sal.stg_bakehouse_sales_transactions . [RUN]
[0m00:23:38.094918 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.004992961883544922s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:38.095916 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_franchises, now model.dbt_italy.stg_bakehouse_sales_transactions)
[0m00:23:38.095916 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.005991935729980469s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:23:38.096915 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.006990671157836914s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Acquired connection on thread (19900, 5364), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_transactions`'
[0m00:23:38.096915 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:23:38.104905 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:23:38.106905 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:23:38.111897 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.021973133087158203s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:38.112898 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.022973299026489258s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:38.112898 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:23:38.113896 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_transactions'
  
[0m00:23:38.529572 [debug] [Thread-1 (]: SQL status: OK in 0.420 seconds
[0m00:23:38.532564 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-e0ab-1851-bff0-007adfb96f64) - Closing
[0m00:23:38.535552 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.44562721252441406s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:38.536550 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.4466259479522705s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:38.536550 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:23:38.537545 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m00:23:38.844415 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m00:23:38.849412 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-e0ec-101f-8419-7470ccd03c5c) - Closing
[0m00:23:38.851407 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.7604818344116211s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:38.851407 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.7614822387695312s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:38.852405 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:23:38.852405 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */

  
    create or replace temporary view `stg_bakehouse_sales_transactions__dbt_tmp` as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_transactions`

  WHERE dateTime > (SELECT max(dt_ingestion_timestamp) from `bronze`.`sal`.`stg_bakehouse_sales_transactions`)

  
[0m00:23:40.141312 [debug] [Thread-1 (]: SQL status: OK in 1.290 seconds
[0m00:23:40.143313 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-e121-1c7f-aa3b-a9c3a5f58ee8) - Closing
[0m00:23:40.153816 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.063891649246216s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:40.154816 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.064892053604126s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:40.154816 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:23:40.155814 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `stg_bakehouse_sales_transactions__dbt_tmp`
  
[0m00:23:40.536419 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m00:23:40.538404 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-e1e8-1b2f-952d-5cdc3406b455) - Closing
[0m00:23:40.541413 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.4514882564544678s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:40.542409 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.452484607696533s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:40.542409 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:23:40.542409 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m00:23:40.870684 [debug] [Thread-1 (]: SQL status: OK in 0.330 seconds
[0m00:23:40.873672 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-e227-1bb7-810f-c0859156000a) - Closing
[0m00:23:40.877666 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:23:40.879661 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.7897369861602783s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:40.879661 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.7897369861602783s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:40.880662 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:23:40.880662 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
insert into table `bronze`.`sal`.`stg_bakehouse_sales_transactions` (`transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp`)
select `transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp` from `stg_bakehouse_sales_transactions__dbt_tmp`

[0m00:23:46.703123 [debug] [Thread-1 (]: SQL status: OK in 5.820 seconds
[0m00:23:46.705124 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-e25b-1fae-bfbe-d834fa553d34) - Closing
[0m00:23:46.868054 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Released connection
[0m00:23:46.869054 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Released connection
[0m00:23:46.870053 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de22cbc7-8ce5-4688-a60d-a69141dc7f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235EDC91480>]}
[0m00:23:46.871046 [info ] [Thread-1 (]: 3 of 4 OK created sql incremental model bronze.sal.stg_bakehouse_sales_transactions  [[32mOK[0m in 8.78s]
[0m00:23:46.872045 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:23:46.873047 [debug] [Thread-1 (]: Began running node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:23:46.874044 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0049896240234375s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:46.874044 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_transactions, now model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated)
[0m00:23:46.875042 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.005988359451293945s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:23:46.875042 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.005988359451293945s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Acquired connection on thread (19900, 5364), using default compute resource for model 'None'
[0m00:23:46.876040 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:23:46.880040 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated"
[0m00:23:46.883033 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Released connection
[0m00:23:46.883033 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Released connection
[0m00:23:46.884031 [debug] [Thread-1 (]: Finished running node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:23:46.885028 [debug] [Thread-1 (]: Began running node model.dbt_italy.ent_sales_transactions
[0m00:23:46.885028 [info ] [Thread-1 (]: 4 of 4 START sql incremental model default.ent_sales_transactions .............. [RUN]
[0m00:23:46.886027 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.002993345260620117s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:46.887028 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, now model.dbt_italy.ent_sales_transactions)
[0m00:23:46.888025 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.ent_sales_transactions, idle-time=0.004991769790649414s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Reusing connection previously named model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:23:46.889028 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.ent_sales_transactions, idle-time=0.004991769790649414s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Acquired connection on thread (19900, 5364), using default compute resource for model '`workspace`.`default`.`ent_sales_transactions`'
[0m00:23:46.889028 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.ent_sales_transactions
[0m00:23:46.905007 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.ent_sales_transactions"
[0m00:23:46.914814 [debug] [Thread-1 (]: Began executing node model.dbt_italy.ent_sales_transactions
[0m00:23:46.967319 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.ent_sales_transactions"
[0m00:23:46.975309 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.ent_sales_transactions, idle-time=0.09227538108825684s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Checking idleness
[0m00:23:46.976305 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.ent_sales_transactions, idle-time=0.09327173233032227s, acquire-count=1, language=sql, thread-identifier=(19900, 5364), compute-name=) - Retrieving connection
[0m00:23:46.977302 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.ent_sales_transactions"
[0m00:23:46.977302 [debug] [Thread-1 (]: On model.dbt_italy.ent_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.ent_sales_transactions"} */

  
    
        create or replace table `workspace`.`default`.`ent_sales_transactions`
      
      using delta
      
      
      
      
      
      
      
      as
      

with __dbt__cte__eph_bakehouse_sales_franchises_deduplicated as (


WITH stg_bakehouse_franchises
AS (
    SELECT
        franchiseID,
        name,
        city,
        district,
        zipcode,
        country,
        size,
        longitude,
        latitude,
        supplierID,
        dt_ingestion_timestamp,
        ROW_NUMBER() OVER (
            PARTITION BY franchiseID
            ORDER BY dt_ingestion_timestamp DESC
        ) AS row_number_franchiseID
    FROM `bronze`.`sal`.`stg_bakehouse_sales_franchises`
)
SELECT
    franchiseID,
    name,
    city,
    district,
    zipcode,
    country,
    size,
    longitude,
    latitude,
    supplierID,
    dt_ingestion_timestamp
FROM stg_bakehouse_franchises
WHERE row_number_franchiseID = 1
) SELECT
    transac.transactionID AS id_source_system_transaction_id,
    transac.customerID AS cd_customer_code,
    transac.franchiseID AS cd_franchise_code,
    transac.product AS gn_product_name,
    transac.quantity AS nm_quantity_of_product_sold_number,
    transac.unitPrice AS nm_price_per_unit_number,
    transac.totalPrice AS nm_total_price_number,
    transac.paymentMethod AS gn_payment_method,
    transac.cardNumber AS gn_card_number,
    franch.city AS gn_city_name,
    transac.dateTime AS dt_source_system_ingestion_timestamp
FROM `bronze`.`sal`.`stg_bakehouse_sales_transactions` transac
LEFT JOIN __dbt__cte__eph_bakehouse_sales_franchises_deduplicated franch
ON transac.franchiseID = franch.franchiseID
  
[0m00:23:57.395540 [debug] [Thread-1 (]: SQL status: OK in 10.420 seconds
[0m00:23:57.397539 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, command-id=01eff0aa-e5f5-1636-97a1-b0207086f609) - Closing
[0m00:23:57.634506 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.ent_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Released connection
[0m00:23:57.635508 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2430648046672, session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567, name=model.dbt_italy.ent_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(19900, 5364), compute-name=) - Released connection
[0m00:23:57.636500 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de22cbc7-8ce5-4688-a60d-a69141dc7f49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235D11913C0>]}
[0m00:23:57.637503 [info ] [Thread-1 (]: 4 of 4 OK created sql incremental model default.ent_sales_transactions ......... [[32mOK[0m in 10.75s]
[0m00:23:57.638497 [debug] [Thread-1 (]: Finished running node model.dbt_italy.ent_sales_transactions
[0m00:23:57.640494 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=46.01153492927551s, acquire-count=0, language=None, thread-identifier=(19900, 23508), compute-name=) - Checking idleness
[0m00:23:57.640494 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=46.01153492927551s, acquire-count=0, language=None, thread-identifier=(19900, 23508), compute-name=) - Reusing connection previously named master
[0m00:23:57.641494 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=46.012535095214844s, acquire-count=1, language=None, thread-identifier=(19900, 23508), compute-name=) - Acquired connection on thread (19900, 23508), using default compute resource
[0m00:23:57.642493 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=46.012535095214844s, acquire-count=1, language=None, thread-identifier=(19900, 23508), compute-name=) - Checking idleness
[0m00:23:57.642493 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=None, name=master, idle-time=46.0135338306427s, acquire-count=1, language=None, thread-identifier=(19900, 23508), compute-name=) - Retrieving connection
[0m00:23:57.642493 [debug] [MainThread]: On master: ROLLBACK
[0m00:23:57.643491 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:23:58.134456 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0aa-ec8e-11ec-adcc-5b32f54ab66d) - Created
[0m00:23:58.135458 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:23:58.136455 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=01eff0aa-ec8e-11ec-adcc-5b32f54ab66d, name=master, idle-time=0.0009975433349609375s, acquire-count=1, language=None, thread-identifier=(19900, 23508), compute-name=) - Checking idleness
[0m00:23:58.136455 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=01eff0aa-ec8e-11ec-adcc-5b32f54ab66d, name=master, idle-time=0.0009975433349609375s, acquire-count=1, language=None, thread-identifier=(19900, 23508), compute-name=) - Retrieving connection
[0m00:23:58.137465 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m00:23:58.137465 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m00:23:58.138433 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2430648274656, session-id=01eff0aa-ec8e-11ec-adcc-5b32f54ab66d, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(19900, 23508), compute-name=) - Released connection
[0m00:23:58.138433 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:23:58.139449 [debug] [MainThread]: On master: ROLLBACK
[0m00:23:58.139449 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:23:58.140447 [debug] [MainThread]: On master: Close
[0m00:23:58.140447 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0aa-ec8e-11ec-adcc-5b32f54ab66d) - Closing
[0m00:23:58.275163 [debug] [MainThread]: Connection 'list_bronze' was properly closed.
[0m00:23:58.276165 [debug] [MainThread]: On list_bronze: Close
[0m00:23:58.277160 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0aa-a93f-1d90-b751-2a4ad82d9d7b) - Closing
[0m00:23:58.440544 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m00:23:58.442540 [debug] [MainThread]: On list_workspace_default: ROLLBACK
[0m00:23:58.442540 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:23:58.443545 [debug] [MainThread]: On list_workspace_default: Close
[0m00:23:58.444537 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0aa-cefb-1562-9ea0-fcbb3c8c65e7) - Closing
[0m00:23:58.581634 [debug] [MainThread]: Connection 'model.dbt_italy.ent_sales_transactions' was properly closed.
[0m00:23:58.583633 [debug] [MainThread]: On model.dbt_italy.ent_sales_transactions: ROLLBACK
[0m00:23:58.583633 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:23:58.584627 [debug] [MainThread]: On model.dbt_italy.ent_sales_transactions: Close
[0m00:23:58.584627 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0aa-d110-1eea-a0ed-9dc5e0549567) - Closing
[0m00:23:58.712519 [info ] [MainThread]: 
[0m00:23:58.714517 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 1 minutes and 54.13 seconds (114.13s).
[0m00:23:58.716514 [debug] [MainThread]: Command end result
[0m00:23:58.766471 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m00:23:58.773601 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m00:23:58.781580 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m00:23:58.782582 [info ] [MainThread]: 
[0m00:23:58.783582 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:23:58.784576 [info ] [MainThread]: 
[0m00:23:58.785578 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m00:23:58.786587 [debug] [MainThread]: Command `dbt run` succeeded at 00:23:58.786587 after 117.21 seconds
[0m00:23:58.787572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235D134E110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235D1876AA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000235EDE5FB50>]}
[0m00:23:58.787572 [debug] [MainThread]: Flushing usage events
[0m00:23:59.669505 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:25:23.205102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002528964E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002528AFCE5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002528AFCE2F0>]}


============================== 00:25:23.210115 | a4f7503f-35be-4a86-8e3d-5866f783340f ==============================
[0m00:25:23.210115 [info ] [MainThread]: Running with dbt=1.9.2
[0m00:25:23.211122 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'dbt_italy', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:25:23.811558 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m00:25:23.811558 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m00:25:23.812534 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m00:25:24.616105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a4f7503f-35be-4a86-8e3d-5866f783340f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025288254F10>]}
[0m00:25:24.656628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a4f7503f-35be-4a86-8e3d-5866f783340f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000252A4D8FCD0>]}
[0m00:25:24.657627 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m00:25:25.076997 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m00:25:25.278628 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m00:25:25.279604 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\silver\eph_bakehouse_sales_franchises_deduplicated.yml
[0m00:25:25.280596 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\silver\ent_sales_transactions.yml
[0m00:25:25.336054 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_bakehouse_sales_franchises_deduplicated' in the 'models' section of file 'models\silver\eph_bakehouse_sales_franchises_deduplicated.yml'
[0m00:25:25.449539 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_italy.unique_stg_bakehouse_sales_franchises_deduplicated_franchiseID.edd57efa29' (models\silver\eph_bakehouse_sales_franchises_deduplicated.yml) depends on a node named 'stg_bakehouse_sales_franchises_deduplicated' in package '' which was not found
[0m00:25:25.451947 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_italy.not_null_stg_bakehouse_sales_franchises_deduplicated_franchiseID.6c4e1f85cf' (models\silver\eph_bakehouse_sales_franchises_deduplicated.yml) depends on a node named 'stg_bakehouse_sales_franchises_deduplicated' in package '' which was not found
[0m00:25:25.623511 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m00:25:25.634795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a4f7503f-35be-4a86-8e3d-5866f783340f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000252A5F7CF70>]}
[0m00:25:25.726703 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m00:25:25.730150 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m00:25:25.755135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a4f7503f-35be-4a86-8e3d-5866f783340f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000252A5D11660>]}
[0m00:25:25.756134 [info ] [MainThread]: Found 5 models, 8 data tests, 3 sources, 608 macros
[0m00:25:25.757118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a4f7503f-35be-4a86-8e3d-5866f783340f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000252A5D10370>]}
[0m00:25:25.758132 [info ] [MainThread]: 
[0m00:25:25.758786 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:25:25.759800 [info ] [MainThread]: 
[0m00:25:25.759800 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(13848, 28548), compute-name=) - Creating connection
[0m00:25:25.760798 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m00:25:25.760798 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(13848, 28548), compute-name=) - Acquired connection on thread (13848, 28548), using default compute resource
[0m00:25:25.766811 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=None, name=list_silver, idle-time=0s, acquire-count=0, language=None, thread-identifier=(13848, 19924), compute-name=) - Creating connection
[0m00:25:25.767822 [debug] [ThreadPool]: Acquiring new databricks connection 'list_silver'
[0m00:25:25.767822 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=None, name=list_silver, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(13848, 19924), compute-name=) - Acquired connection on thread (13848, 19924), using default compute resource
[0m00:25:25.768818 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=None, name=list_silver, idle-time=0.0009963512420654297s, acquire-count=1, language=None, thread-identifier=(13848, 19924), compute-name=) - Checking idleness
[0m00:25:25.768818 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=None, name=list_silver, idle-time=0.0009963512420654297s, acquire-count=1, language=None, thread-identifier=(13848, 19924), compute-name=) - Retrieving connection
[0m00:25:25.768818 [debug] [ThreadPool]: Using databricks connection "list_silver"
[0m00:25:25.769813 [debug] [ThreadPool]: On list_silver: GetSchemas(database=silver, schema=None)
[0m00:25:25.769813 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:25:26.121361 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd) - Created
[0m00:25:26.436287 [debug] [ThreadPool]: SQL status: OK in 0.670 seconds
[0m00:25:26.438284 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, command-id=01eff0ab-2121-1d10-b779-52623fbdba8e) - Closing
[0m00:25:26.439287 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=list_silver, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(13848, 19924), compute-name=) - Released connection
[0m00:25:26.439287 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=list_silver, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(13848, 19924), compute-name=) - Checking idleness
[0m00:25:26.440283 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_silver, now list_bronze)
[0m00:25:26.440283 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=list_bronze, idle-time=0.0009958744049072266s, acquire-count=0, language=None, thread-identifier=(13848, 19924), compute-name=) - Reusing connection previously named list_silver
[0m00:25:26.441279 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=list_bronze, idle-time=0.0019922256469726562s, acquire-count=1, language=None, thread-identifier=(13848, 19924), compute-name=) - Acquired connection on thread (13848, 19924), using default compute resource
[0m00:25:26.441279 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=list_bronze, idle-time=0.0019922256469726562s, acquire-count=1, language=None, thread-identifier=(13848, 19924), compute-name=) - Checking idleness
[0m00:25:26.442277 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=list_bronze, idle-time=0.0029904842376708984s, acquire-count=1, language=None, thread-identifier=(13848, 19924), compute-name=) - Retrieving connection
[0m00:25:26.442277 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m00:25:26.443279 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m00:25:26.694245 [debug] [ThreadPool]: SQL status: OK in 0.250 seconds
[0m00:25:26.696246 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, command-id=01eff0ab-214d-1d06-b394-e1caf9691f00) - Closing
[0m00:25:26.697244 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(13848, 19924), compute-name=) - Released connection
[0m00:25:26.698241 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=list_bronze, idle-time=0.0009989738464355469s, acquire-count=0, language=None, thread-identifier=(13848, 19924), compute-name=) - Checking idleness
[0m00:25:26.698241 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_bronze, now create_silver_sal)
[0m00:25:26.699240 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=create_silver_sal, idle-time=0.0029947757720947266s, acquire-count=0, language=None, thread-identifier=(13848, 19924), compute-name=) - Reusing connection previously named list_bronze
[0m00:25:26.699240 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=create_silver_sal, idle-time=0.0029947757720947266s, acquire-count=1, language=None, thread-identifier=(13848, 19924), compute-name=) - Acquired connection on thread (13848, 19924), using default compute resource
[0m00:25:26.700240 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=create_silver_sal, idle-time=0.0039942264556884766s, acquire-count=1, language=None, thread-identifier=(13848, 19924), compute-name=) - Checking idleness
[0m00:25:26.700240 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=create_silver_sal, idle-time=0.0039942264556884766s, acquire-count=2, language=None, thread-identifier=(13848, 19924), compute-name=) - Acquired connection on thread (13848, 19924), using default compute resource
[0m00:25:26.710253 [debug] [ThreadPool]: Creating schema "database: "silver"
schema: "sal"
"
[0m00:25:26.721274 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=create_silver_sal, idle-time=0.024027347564697266s, acquire-count=2, language=None, thread-identifier=(13848, 19924), compute-name=) - Checking idleness
[0m00:25:26.721274 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=create_silver_sal, idle-time=0.025028228759765625s, acquire-count=2, language=None, thread-identifier=(13848, 19924), compute-name=) - Retrieving connection
[0m00:25:26.722272 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=create_silver_sal, idle-time=0.026026248931884766s, acquire-count=2, language=None, thread-identifier=(13848, 19924), compute-name=) - Checking idleness
[0m00:25:26.722272 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=create_silver_sal, idle-time=0.026026248931884766s, acquire-count=2, language=None, thread-identifier=(13848, 19924), compute-name=) - Retrieving connection
[0m00:25:26.723270 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m00:25:26.723270 [debug] [ThreadPool]: Using databricks connection "create_silver_sal"
[0m00:25:26.724269 [debug] [ThreadPool]: On create_silver_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "create_silver_sal"} */
create schema if not exists `silver`.`sal`
  
[0m00:25:27.215664 [debug] [ThreadPool]: SQL status: OK in 0.490 seconds
[0m00:25:27.217668 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, command-id=01eff0ab-2179-15e4-9250-34872fe04f8b) - Closing
[0m00:25:27.218663 [debug] [ThreadPool]: Spark adapter: NotImplemented: commit
[0m00:25:27.218663 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=create_silver_sal, idle-time=0.5224173069000244s, acquire-count=1, language=None, thread-identifier=(13848, 19924), compute-name=) - Released connection
[0m00:25:27.219662 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553992512752, session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd, name=create_silver_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(13848, 19924), compute-name=) - Released connection
[0m00:25:27.221274 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=None, name=list_silver_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(13848, 18248), compute-name=) - Creating connection
[0m00:25:27.221274 [debug] [ThreadPool]: Acquiring new databricks connection 'list_silver_sal'
[0m00:25:27.222303 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=None, name=list_silver_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(13848, 18248), compute-name=) - Acquired connection on thread (13848, 18248), using default compute resource
[0m00:25:27.226311 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=None, name=list_silver_sal, idle-time=0.004008293151855469s, acquire-count=1, language=None, thread-identifier=(13848, 18248), compute-name=) - Checking idleness
[0m00:25:27.227832 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=None, name=list_silver_sal, idle-time=0.0055294036865234375s, acquire-count=1, language=None, thread-identifier=(13848, 18248), compute-name=) - Retrieving connection
[0m00:25:27.227832 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=None, name=list_silver_sal, idle-time=0.0055294036865234375s, acquire-count=1, language=None, thread-identifier=(13848, 18248), compute-name=) - Checking idleness
[0m00:25:27.227832 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=None, name=list_silver_sal, idle-time=0.0055294036865234375s, acquire-count=1, language=None, thread-identifier=(13848, 18248), compute-name=) - Retrieving connection
[0m00:25:27.228867 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m00:25:27.228867 [debug] [ThreadPool]: Using databricks connection "list_silver_sal"
[0m00:25:27.229842 [debug] [ThreadPool]: On list_silver_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_silver_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'silver'
      and table_schema = 'sal'
    
  
[0m00:25:27.229842 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:25:27.561255 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876) - Created
[0m00:25:27.918238 [debug] [ThreadPool]: SQL status: OK in 0.690 seconds
[0m00:25:27.924247 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876, command-id=01eff0ab-21f8-1ff7-9b5c-4b260b02075a) - Closing
[0m00:25:27.925255 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876, name=list_silver_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(13848, 18248), compute-name=) - Released connection
[0m00:25:27.926227 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876, name=list_silver_sal, idle-time=0.0009725093841552734s, acquire-count=0, language=None, thread-identifier=(13848, 18248), compute-name=) - Checking idleness
[0m00:25:27.926227 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_silver_sal, now list_bronze_sal)
[0m00:25:27.927222 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876, name=list_bronze_sal, idle-time=0.001967191696166992s, acquire-count=0, language=None, thread-identifier=(13848, 18248), compute-name=) - Reusing connection previously named list_silver_sal
[0m00:25:27.927222 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876, name=list_bronze_sal, idle-time=0.001967191696166992s, acquire-count=1, language=None, thread-identifier=(13848, 18248), compute-name=) - Acquired connection on thread (13848, 18248), using default compute resource
[0m00:25:27.929758 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876, name=list_bronze_sal, idle-time=0.004502773284912109s, acquire-count=1, language=None, thread-identifier=(13848, 18248), compute-name=) - Checking idleness
[0m00:25:27.930756 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876, name=list_bronze_sal, idle-time=0.005501270294189453s, acquire-count=1, language=None, thread-identifier=(13848, 18248), compute-name=) - Retrieving connection
[0m00:25:27.930756 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m00:25:27.931727 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m00:25:28.501665 [debug] [ThreadPool]: SQL status: OK in 0.570 seconds
[0m00:25:28.504663 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876, command-id=01eff0ab-2231-186d-a5d7-32b8b2137ff1) - Closing
[0m00:25:28.505681 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=2553996994368, session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(13848, 18248), compute-name=) - Released connection
[0m00:25:28.506664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a4f7503f-35be-4a86-8e3d-5866f783340f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002528CAF40D0>]}
[0m00:25:28.507657 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=2.746858835220337s, acquire-count=1, language=None, thread-identifier=(13848, 28548), compute-name=) - Checking idleness
[0m00:25:28.507657 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=2.746858835220337s, acquire-count=1, language=None, thread-identifier=(13848, 28548), compute-name=) - Retrieving connection
[0m00:25:28.508656 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=2.7478580474853516s, acquire-count=1, language=None, thread-identifier=(13848, 28548), compute-name=) - Checking idleness
[0m00:25:28.508656 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=2.7478580474853516s, acquire-count=1, language=None, thread-identifier=(13848, 28548), compute-name=) - Retrieving connection
[0m00:25:28.509658 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m00:25:28.509658 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m00:25:28.510655 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(13848, 28548), compute-name=) - Released connection
[0m00:25:28.513649 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:25:28.513649 [info ] [Thread-1 (]: 1 of 4 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m00:25:28.515653 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(13848, 35160), compute-name=) - Creating connection
[0m00:25:28.515653 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m00:25:28.516651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Acquired connection on thread (13848, 35160), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m00:25:28.516651 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:25:28.524642 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:25:28.526627 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:25:28.575123 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.05946993827819824s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:28.576123 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.060469865798950195s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:28.577125 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.06147193908691406s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:28.578097 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.06244349479675293s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:28.579110 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m00:25:28.579110 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:25:28.580104 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_customer'
  
[0m00:25:28.581087 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m00:25:28.856475 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f) - Created
[0m00:25:29.231732 [debug] [Thread-1 (]: SQL status: OK in 0.650 seconds
[0m00:25:29.234709 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-22bf-127f-9122-71631363871f) - Closing
[0m00:25:29.239718 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.3822450637817383s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:29.240730 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.383256196975708s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:29.240730 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:25:29.241727 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m00:25:29.489533 [debug] [Thread-1 (]: SQL status: OK in 0.250 seconds
[0m00:25:29.492532 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-22f9-176a-a0fd-7b8f5719a169) - Closing
[0m00:25:29.501547 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.6440732479095459s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:29.502545 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.6450715065002441s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:29.502545 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:25:29.503532 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    create or replace temporary view `stg_bakehouse_sales_customer__dbt_tmp` as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m00:25:32.598025 [debug] [Thread-1 (]: SQL status: OK in 3.090 seconds
[0m00:25:32.600036 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-2321-17c0-aed3-da731768795f) - Closing
[0m00:25:32.620020 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.7625460624694824s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:32.621016 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.763542890548706s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:32.622017 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:25:32.622017 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m00:25:32.916529 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m00:25:32.919576 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-24fe-1446-8444-480500144c9e) - Closing
[0m00:25:32.922561 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.0650880336761475s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:32.923573 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.0660998821258545s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:32.923573 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:25:32.924550 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `stg_bakehouse_sales_customer__dbt_tmp`
  
[0m00:25:33.218459 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m00:25:33.221483 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-252c-1574-baa3-46576a746184) - Closing
[0m00:25:33.229483 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:25:33.231469 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.373995304107666s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:33.232450 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=4.374976873397827s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:33.232450 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:25:33.233954 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_customer` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_customer__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m00:25:36.427404 [debug] [Thread-1 (]: SQL status: OK in 3.190 seconds
[0m00:25:36.430405 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-255b-1883-ba55-1912bc6007c2) - Closing
[0m00:25:36.452033 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Released connection
[0m00:25:36.452033 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Released connection
[0m00:25:36.454018 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4f7503f-35be-4a86-8e3d-5866f783340f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002528823B190>]}
[0m00:25:36.455031 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 7.94s]
[0m00:25:36.456256 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:25:36.457286 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:25:36.458282 [info ] [Thread-1 (]: 2 of 4 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m00:25:36.458282 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.00624847412109375s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:36.459267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m00:25:36.459267 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007233381271362305s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m00:25:36.460273 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.00823974609375s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Acquired connection on thread (13848, 35160), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m00:25:36.461265 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:25:36.465257 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:25:36.467254 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:25:36.472248 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.019216299057006836s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:36.472248 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.02021479606628418s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:36.473248 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:25:36.473248 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_franchises'
  
[0m00:25:36.800616 [debug] [Thread-1 (]: SQL status: OK in 0.330 seconds
[0m00:25:36.802603 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-274a-1065-a7e5-5cbbe48bafba) - Closing
[0m00:25:36.806601 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.3535900115966797s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:36.806601 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.3545675277709961s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:36.807597 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:25:36.807597 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m00:25:37.091652 [debug] [Thread-1 (]: SQL status: OK in 0.280 seconds
[0m00:25:37.093646 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-277d-1fa1-b2ae-bfa8544a3ced) - Closing
[0m00:25:37.095644 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.6436107158660889s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:37.095644 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.6436107158660889s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:37.096646 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:25:37.096646 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    create or replace temporary view `stg_bakehouse_sales_franchises__dbt_tmp` as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m00:25:37.931408 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m00:25:37.933420 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-27a9-1e37-8179-88f291116382) - Closing
[0m00:25:37.936411 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.4843776226043701s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:37.937413 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.4853794574737549s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:37.937413 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:25:37.938405 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m00:25:38.166421 [debug] [Thread-1 (]: SQL status: OK in 0.230 seconds
[0m00:25:38.169410 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-2829-1b9c-8eba-3c056a65fb55) - Closing
[0m00:25:38.173411 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.7213780879974365s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:38.173411 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.7213780879974365s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:38.174419 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:25:38.174419 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `stg_bakehouse_sales_franchises__dbt_tmp`
  
[0m00:25:38.464422 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m00:25:38.466554 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-284e-1794-81bc-01999fb76875) - Closing
[0m00:25:38.468623 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:25:38.470629 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.0185961723327637s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:38.470629 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.0185961723327637s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:38.471631 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:25:38.471631 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_franchises` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_franchises__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m00:25:43.132697 [debug] [Thread-1 (]: SQL status: OK in 4.660 seconds
[0m00:25:43.134706 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-287b-165b-b4b7-2e05165667fc) - Closing
[0m00:25:43.136698 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Released connection
[0m00:25:43.137697 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Released connection
[0m00:25:43.138695 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4f7503f-35be-4a86-8e3d-5866f783340f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002528823B190>]}
[0m00:25:43.139694 [info ] [Thread-1 (]: 2 of 4 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 6.68s]
[0m00:25:43.140693 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:25:43.141691 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:25:43.142693 [info ] [Thread-1 (]: 3 of 4 START sql incremental model bronze.sal.stg_bakehouse_sales_transactions . [RUN]
[0m00:25:43.144687 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.007988929748535156s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:43.144687 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_franchises, now model.dbt_italy.stg_bakehouse_sales_transactions)
[0m00:25:43.145689 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.00899052619934082s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:25:43.145689 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.00899052619934082s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Acquired connection on thread (13848, 35160), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_transactions`'
[0m00:25:43.146687 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:25:43.154198 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:25:43.156192 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:25:43.168179 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.03148078918457031s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:43.169180 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.032482147216796875s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:43.170175 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:25:43.172173 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_transactions'
  
[0m00:25:43.539824 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m00:25:43.542835 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-2b4f-11b8-b786-bc82888d623a) - Closing
[0m00:25:43.545819 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.4091215133666992s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:43.545819 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.4091215133666992s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:43.546823 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:25:43.546823 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m00:25:43.837335 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m00:25:43.840335 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-2b83-181b-b6ba-007bd23a85ee) - Closing
[0m00:25:43.841334 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.7046363353729248s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:43.842331 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.7056324481964111s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:43.842331 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:25:43.843325 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */

  
    create or replace temporary view `stg_bakehouse_sales_transactions__dbt_tmp` as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_transactions`

  WHERE dateTime > (SELECT max(dt_ingestion_timestamp) from `bronze`.`sal`.`stg_bakehouse_sales_transactions`)

  
[0m00:25:45.066379 [debug] [Thread-1 (]: SQL status: OK in 1.220 seconds
[0m00:25:45.067374 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-2baf-1b08-a619-6f08a79c9faf) - Closing
[0m00:25:45.074363 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.9376649856567383s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:45.074363 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.9376649856567383s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:45.075362 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:25:45.075362 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `stg_bakehouse_sales_transactions__dbt_tmp`
  
[0m00:25:45.412557 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m00:25:45.415554 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-2c6d-1b3a-abe8-f99910858c26) - Closing
[0m00:25:45.418564 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.2818663120269775s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:45.419562 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.2828636169433594s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:45.419562 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:25:45.420547 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m00:25:45.775383 [debug] [Thread-1 (]: SQL status: OK in 0.350 seconds
[0m00:25:45.779382 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-2ca1-169a-b271-11e72ffd14a2) - Closing
[0m00:25:45.785370 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:25:45.787366 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.650667667388916s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:45.788366 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.651667833328247s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:45.789365 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:25:45.789365 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
insert into table `bronze`.`sal`.`stg_bakehouse_sales_transactions` (`transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp`)
select `transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp` from `stg_bakehouse_sales_transactions__dbt_tmp`

[0m00:25:48.845266 [debug] [Thread-1 (]: SQL status: OK in 3.050 seconds
[0m00:25:48.847268 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-2cd8-1dc7-b2f7-8029f253f230) - Closing
[0m00:25:48.849260 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Released connection
[0m00:25:48.849260 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Released connection
[0m00:25:48.850258 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4f7503f-35be-4a86-8e3d-5866f783340f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000252A610A0E0>]}
[0m00:25:48.851258 [info ] [Thread-1 (]: 3 of 4 OK created sql incremental model bronze.sal.stg_bakehouse_sales_transactions  [[32mOK[0m in 5.71s]
[0m00:25:48.852255 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:25:48.853251 [debug] [Thread-1 (]: Began running node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:25:48.853251 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.003991603851318359s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:48.854249 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_transactions, now model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated)
[0m00:25:48.855265 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.004989147186279297s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:25:48.855265 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.006005525588989258s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Acquired connection on thread (13848, 35160), using default compute resource for model 'None'
[0m00:25:48.855265 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:25:48.859799 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated"
[0m00:25:48.861771 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Released connection
[0m00:25:48.862766 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Released connection
[0m00:25:48.863764 [debug] [Thread-1 (]: Finished running node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:25:48.865764 [debug] [Thread-1 (]: Began running node model.dbt_italy.ent_sales_transactions
[0m00:25:48.866766 [info ] [Thread-1 (]: 4 of 4 START sql incremental model silver.sal.ent_sales_transactions ........... [RUN]
[0m00:25:48.868343 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.005577564239501953s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:48.869350 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, now model.dbt_italy.ent_sales_transactions)
[0m00:25:48.869350 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.ent_sales_transactions, idle-time=0.006584644317626953s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Reusing connection previously named model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:25:48.870358 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.ent_sales_transactions, idle-time=0.007591724395751953s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Acquired connection on thread (13848, 35160), using default compute resource for model '`silver`.`sal`.`ent_sales_transactions`'
[0m00:25:48.870864 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.ent_sales_transactions
[0m00:25:48.881431 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.ent_sales_transactions"
[0m00:25:48.886414 [debug] [Thread-1 (]: Began executing node model.dbt_italy.ent_sales_transactions
[0m00:25:48.918371 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.ent_sales_transactions"
[0m00:25:48.921368 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.ent_sales_transactions, idle-time=0.0576024055480957s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Checking idleness
[0m00:25:48.921368 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.ent_sales_transactions, idle-time=0.05860257148742676s, acquire-count=1, language=sql, thread-identifier=(13848, 35160), compute-name=) - Retrieving connection
[0m00:25:48.922367 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.ent_sales_transactions"
[0m00:25:48.922367 [debug] [Thread-1 (]: On model.dbt_italy.ent_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.ent_sales_transactions"} */

  
    
        create or replace table `silver`.`sal`.`ent_sales_transactions`
      
      using delta
      
      
      
      
      
      
      
      as
      

with __dbt__cte__eph_bakehouse_sales_franchises_deduplicated as (


WITH stg_bakehouse_franchises
AS (
    SELECT
        franchiseID,
        name,
        city,
        district,
        zipcode,
        country,
        size,
        longitude,
        latitude,
        supplierID,
        dt_ingestion_timestamp,
        ROW_NUMBER() OVER (
            PARTITION BY franchiseID
            ORDER BY dt_ingestion_timestamp DESC
        ) AS row_number_franchiseID
    FROM `bronze`.`sal`.`stg_bakehouse_sales_franchises`
)
SELECT
    franchiseID,
    name,
    city,
    district,
    zipcode,
    country,
    size,
    longitude,
    latitude,
    supplierID,
    dt_ingestion_timestamp
FROM stg_bakehouse_franchises
WHERE row_number_franchiseID = 1
) SELECT
    transac.transactionID AS id_source_system_transaction_id,
    transac.customerID AS cd_customer_code,
    transac.franchiseID AS cd_franchise_code,
    transac.product AS gn_product_name,
    transac.quantity AS nm_quantity_of_product_sold_number,
    transac.unitPrice AS nm_price_per_unit_number,
    transac.totalPrice AS nm_total_price_number,
    transac.paymentMethod AS gn_payment_method,
    transac.cardNumber AS gn_card_number,
    franch.city AS gn_city_name,
    transac.dateTime AS dt_source_system_ingestion_timestamp
FROM `bronze`.`sal`.`stg_bakehouse_sales_transactions` transac
LEFT JOIN __dbt__cte__eph_bakehouse_sales_franchises_deduplicated franch
ON transac.franchiseID = franch.franchiseID
  
[0m00:25:52.786443 [debug] [Thread-1 (]: SQL status: OK in 3.860 seconds
[0m00:25:52.787447 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, command-id=01eff0ab-2eb7-1f40-9dd2-96e09844af54) - Closing
[0m00:25:52.795430 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.ent_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Released connection
[0m00:25:52.796435 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=2553994008832, session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f, name=model.dbt_italy.ent_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(13848, 35160), compute-name=) - Released connection
[0m00:25:52.797433 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4f7503f-35be-4a86-8e3d-5866f783340f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025289781420>]}
[0m00:25:52.798432 [info ] [Thread-1 (]: 4 of 4 OK created sql incremental model silver.sal.ent_sales_transactions ...... [[32mOK[0m in 3.93s]
[0m00:25:52.799432 [debug] [Thread-1 (]: Finished running node model.dbt_italy.ent_sales_transactions
[0m00:25:52.801423 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=24.29076886177063s, acquire-count=0, language=None, thread-identifier=(13848, 28548), compute-name=) - Checking idleness
[0m00:25:52.802427 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=24.291772603988647s, acquire-count=0, language=None, thread-identifier=(13848, 28548), compute-name=) - Reusing connection previously named master
[0m00:25:52.802427 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=24.291772603988647s, acquire-count=1, language=None, thread-identifier=(13848, 28548), compute-name=) - Acquired connection on thread (13848, 28548), using default compute resource
[0m00:25:52.803424 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=24.29276990890503s, acquire-count=1, language=None, thread-identifier=(13848, 28548), compute-name=) - Checking idleness
[0m00:25:52.803424 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=None, name=master, idle-time=24.29276990890503s, acquire-count=1, language=None, thread-identifier=(13848, 28548), compute-name=) - Retrieving connection
[0m00:25:52.804424 [debug] [MainThread]: On master: ROLLBACK
[0m00:25:52.804424 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:25:53.192194 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0ab-3136-143d-8968-6d2401162fa4) - Created
[0m00:25:53.194191 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:25:53.194191 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=01eff0ab-3136-143d-8968-6d2401162fa4, name=master, idle-time=0.0010104179382324219s, acquire-count=1, language=None, thread-identifier=(13848, 28548), compute-name=) - Checking idleness
[0m00:25:53.195189 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=01eff0ab-3136-143d-8968-6d2401162fa4, name=master, idle-time=0.0020084381103515625s, acquire-count=1, language=None, thread-identifier=(13848, 28548), compute-name=) - Retrieving connection
[0m00:25:53.196173 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m00:25:53.197173 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m00:25:53.197173 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=2553992513616, session-id=01eff0ab-3136-143d-8968-6d2401162fa4, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(13848, 28548), compute-name=) - Released connection
[0m00:25:53.198172 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:25:53.198172 [debug] [MainThread]: On master: ROLLBACK
[0m00:25:53.199189 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:25:53.199189 [debug] [MainThread]: On master: Close
[0m00:25:53.200187 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0ab-3136-143d-8968-6d2401162fa4) - Closing
[0m00:25:53.326625 [debug] [MainThread]: Connection 'create_silver_sal' was properly closed.
[0m00:25:53.327648 [debug] [MainThread]: On create_silver_sal: ROLLBACK
[0m00:25:53.328624 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:25:53.328624 [debug] [MainThread]: On create_silver_sal: Close
[0m00:25:53.329620 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0ab-210c-1d24-8c31-04a8a71121bd) - Closing
[0m00:25:53.461288 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m00:25:53.462793 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m00:25:53.463830 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:25:53.463830 [debug] [MainThread]: On list_bronze_sal: Close
[0m00:25:53.464818 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0ab-21e6-10c8-87e2-2f8069f1b876) - Closing
[0m00:25:53.597696 [debug] [MainThread]: Connection 'model.dbt_italy.ent_sales_transactions' was properly closed.
[0m00:25:53.599673 [debug] [MainThread]: On model.dbt_italy.ent_sales_transactions: ROLLBACK
[0m00:25:53.600672 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:25:53.600672 [debug] [MainThread]: On model.dbt_italy.ent_sales_transactions: Close
[0m00:25:53.601673 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0ab-22b2-1e1c-9f0b-e04d0b76f13f) - Closing
[0m00:25:53.738507 [info ] [MainThread]: 
[0m00:25:53.740508 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 27.98 seconds (27.98s).
[0m00:25:53.742500 [debug] [MainThread]: Command end result
[0m00:25:53.790830 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m00:25:53.797820 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m00:25:53.806813 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m00:25:53.807810 [info ] [MainThread]: 
[0m00:25:53.808805 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:25:53.809805 [info ] [MainThread]: 
[0m00:25:53.810804 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m00:25:53.812808 [debug] [MainThread]: Command `dbt run` succeeded at 00:25:53.812808 after 30.80 seconds
[0m00:25:53.813800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002528964E170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002528A8B65F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000252897645E0>]}
[0m00:25:53.813800 [debug] [MainThread]: Flushing usage events
[0m00:25:54.458575 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:31:11.555951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188F7F4E1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188F98CA5F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188F98CA2F0>]}


============================== 00:31:11.559977 | 0099f8c7-b33d-489d-a356-a9881533bb38 ==============================
[0m00:31:11.559977 [info ] [MainThread]: Running with dbt=1.9.2
[0m00:31:11.560963 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'dbt_italy', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\tbicocch\\DbtDatabricks\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m00:31:12.123880 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m00:31:12.123880 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m00:31:12.124878 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m00:31:12.920736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0099f8c7-b33d-489d-a356-a9881533bb38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000189015368C0>]}
[0m00:31:12.959693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0099f8c7-b33d-489d-a356-a9881533bb38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188FB282E60>]}
[0m00:31:12.960694 [info ] [MainThread]: Registered adapter: databricks=1.9.5
[0m00:31:13.371230 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m00:31:13.579159 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m00:31:13.580160 [debug] [MainThread]: Partial parsing: updated file: dbt_italy://models\bronze\stg_bakehouse_sales_customer.sql
[0m00:31:13.968564 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_italy.example
[0m00:31:13.979067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0099f8c7-b33d-489d-a356-a9881533bb38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000189026799F0>]}
[0m00:31:14.074352 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m00:31:14.078350 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m00:31:14.110335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0099f8c7-b33d-489d-a356-a9881533bb38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018902761870>]}
[0m00:31:14.111334 [info ] [MainThread]: Found 5 models, 8 data tests, 3 sources, 608 macros
[0m00:31:14.112331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0099f8c7-b33d-489d-a356-a9881533bb38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000189027618D0>]}
[0m00:31:14.113333 [info ] [MainThread]: 
[0m00:31:14.114336 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:31:14.115331 [info ] [MainThread]: 
[0m00:31:14.116329 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(28460, 10032), compute-name=) - Creating connection
[0m00:31:14.116329 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m00:31:14.117330 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(28460, 10032), compute-name=) - Acquired connection on thread (28460, 10032), using default compute resource
[0m00:31:14.123327 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=None, name=list_bronze, idle-time=0s, acquire-count=0, language=None, thread-identifier=(28460, 32008), compute-name=) - Creating connection
[0m00:31:14.124329 [debug] [ThreadPool]: Acquiring new databricks connection 'list_bronze'
[0m00:31:14.124329 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=None, name=list_bronze, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(28460, 32008), compute-name=) - Acquired connection on thread (28460, 32008), using default compute resource
[0m00:31:14.125323 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=None, name=list_bronze, idle-time=0.000993967056274414s, acquire-count=1, language=None, thread-identifier=(28460, 32008), compute-name=) - Checking idleness
[0m00:31:14.126329 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=None, name=list_bronze, idle-time=0.0019998550415039062s, acquire-count=1, language=None, thread-identifier=(28460, 32008), compute-name=) - Retrieving connection
[0m00:31:14.127324 [debug] [ThreadPool]: Using databricks connection "list_bronze"
[0m00:31:14.128323 [debug] [ThreadPool]: On list_bronze: GetSchemas(database=bronze, schema=None)
[0m00:31:14.129325 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:31:14.878554 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0ab-f105-11a0-8407-2318f780cfd1) - Created
[0m00:31:15.819219 [debug] [ThreadPool]: SQL status: OK in 1.690 seconds
[0m00:31:15.821221 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0ab-f105-11a0-8407-2318f780cfd1, command-id=01eff0ab-f11b-1692-bef1-82d90126b183) - Closing
[0m00:31:15.822220 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=01eff0ab-f105-11a0-8407-2318f780cfd1, name=list_bronze, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(28460, 32008), compute-name=) - Released connection
[0m00:31:15.823218 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=01eff0ab-f105-11a0-8407-2318f780cfd1, name=list_bronze, idle-time=0.000997781753540039s, acquire-count=0, language=None, thread-identifier=(28460, 32008), compute-name=) - Checking idleness
[0m00:31:15.823218 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_bronze, now list_silver)
[0m00:31:15.824218 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=01eff0ab-f105-11a0-8407-2318f780cfd1, name=list_silver, idle-time=0.001997232437133789s, acquire-count=0, language=None, thread-identifier=(28460, 32008), compute-name=) - Reusing connection previously named list_bronze
[0m00:31:15.824218 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=01eff0ab-f105-11a0-8407-2318f780cfd1, name=list_silver, idle-time=0.001997232437133789s, acquire-count=1, language=None, thread-identifier=(28460, 32008), compute-name=) - Acquired connection on thread (28460, 32008), using default compute resource
[0m00:31:15.825217 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=01eff0ab-f105-11a0-8407-2318f780cfd1, name=list_silver, idle-time=0.0029969215393066406s, acquire-count=1, language=None, thread-identifier=(28460, 32008), compute-name=) - Checking idleness
[0m00:31:15.825217 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=01eff0ab-f105-11a0-8407-2318f780cfd1, name=list_silver, idle-time=0.0029969215393066406s, acquire-count=1, language=None, thread-identifier=(28460, 32008), compute-name=) - Retrieving connection
[0m00:31:15.825217 [debug] [ThreadPool]: Using databricks connection "list_silver"
[0m00:31:15.826217 [debug] [ThreadPool]: On list_silver: GetSchemas(database=silver, schema=None)
[0m00:31:16.275270 [debug] [ThreadPool]: SQL status: OK in 0.450 seconds
[0m00:31:16.277285 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0ab-f105-11a0-8407-2318f780cfd1, command-id=01eff0ab-f1b0-1935-83dc-e9736c4a85bd) - Closing
[0m00:31:16.278281 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963707968, session-id=01eff0ab-f105-11a0-8407-2318f780cfd1, name=list_silver, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(28460, 32008), compute-name=) - Released connection
[0m00:31:16.280251 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=None, name=list_silver_sal, idle-time=0s, acquire-count=0, language=None, thread-identifier=(28460, 11008), compute-name=) - Creating connection
[0m00:31:16.280251 [debug] [ThreadPool]: Acquiring new databricks connection 'list_silver_sal'
[0m00:31:16.281250 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=None, name=list_silver_sal, idle-time=0.0s, acquire-count=1, language=None, thread-identifier=(28460, 11008), compute-name=) - Acquired connection on thread (28460, 11008), using default compute resource
[0m00:31:16.289274 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=None, name=list_silver_sal, idle-time=0.00802469253540039s, acquire-count=1, language=None, thread-identifier=(28460, 11008), compute-name=) - Checking idleness
[0m00:31:16.290256 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=None, name=list_silver_sal, idle-time=0.009006261825561523s, acquire-count=1, language=None, thread-identifier=(28460, 11008), compute-name=) - Retrieving connection
[0m00:31:16.290256 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=None, name=list_silver_sal, idle-time=0.009006261825561523s, acquire-count=1, language=None, thread-identifier=(28460, 11008), compute-name=) - Checking idleness
[0m00:31:16.291260 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=None, name=list_silver_sal, idle-time=0.010010480880737305s, acquire-count=1, language=None, thread-identifier=(28460, 11008), compute-name=) - Retrieving connection
[0m00:31:16.291260 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m00:31:16.291260 [debug] [ThreadPool]: Using databricks connection "list_silver_sal"
[0m00:31:16.292259 [debug] [ThreadPool]: On list_silver_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_silver_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'silver'
      and table_schema = 'sal'
    
  
[0m00:31:16.292259 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:31:16.579421 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4) - Created
[0m00:31:17.049699 [debug] [ThreadPool]: SQL status: OK in 0.760 seconds
[0m00:31:17.056695 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4, command-id=01eff0ab-f21a-135f-96de-197c4a0418e3) - Closing
[0m00:31:17.057708 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4, name=list_silver_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(28460, 11008), compute-name=) - Released connection
[0m00:31:17.058686 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4, name=list_silver_sal, idle-time=0.0009777545928955078s, acquire-count=0, language=None, thread-identifier=(28460, 11008), compute-name=) - Checking idleness
[0m00:31:17.059680 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_silver_sal, now list_bronze_sal)
[0m00:31:17.059680 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4, name=list_bronze_sal, idle-time=0.0019714832305908203s, acquire-count=0, language=None, thread-identifier=(28460, 11008), compute-name=) - Reusing connection previously named list_silver_sal
[0m00:31:17.060675 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4, name=list_bronze_sal, idle-time=0.0029671192169189453s, acquire-count=1, language=None, thread-identifier=(28460, 11008), compute-name=) - Acquired connection on thread (28460, 11008), using default compute resource
[0m00:31:17.064710 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4, name=list_bronze_sal, idle-time=0.007002353668212891s, acquire-count=1, language=None, thread-identifier=(28460, 11008), compute-name=) - Checking idleness
[0m00:31:17.065709 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4, name=list_bronze_sal, idle-time=0.008000850677490234s, acquire-count=1, language=None, thread-identifier=(28460, 11008), compute-name=) - Retrieving connection
[0m00:31:17.065709 [debug] [ThreadPool]: Using databricks connection "list_bronze_sal"
[0m00:31:17.066706 [debug] [ThreadPool]: On list_bronze_sal: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "connection_name": "list_bronze_sal"} */
select
      table_name,
      if(table_type in ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) as table_type,
      lower(data_source_format) as file_format,
      table_owner
    from `system`.`information_schema`.`tables`
    where table_catalog = 'bronze'
      and table_schema = 'sal'
    
  
[0m00:31:17.492280 [debug] [ThreadPool]: SQL status: OK in 0.430 seconds
[0m00:31:17.495277 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4, command-id=01eff0ab-f264-1c8a-9dd3-c7aa1946d214) - Closing
[0m00:31:17.497276 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=1687963698464, session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4, name=list_bronze_sal, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(28460, 11008), compute-name=) - Released connection
[0m00:31:17.498274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0099f8c7-b33d-489d-a356-a9881533bb38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188F6AC3FA0>]}
[0m00:31:17.499276 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=3.381946086883545s, acquire-count=1, language=None, thread-identifier=(28460, 10032), compute-name=) - Checking idleness
[0m00:31:17.500275 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=3.3829445838928223s, acquire-count=1, language=None, thread-identifier=(28460, 10032), compute-name=) - Retrieving connection
[0m00:31:17.501273 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=3.3839433193206787s, acquire-count=1, language=None, thread-identifier=(28460, 10032), compute-name=) - Checking idleness
[0m00:31:17.501273 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=3.3839433193206787s, acquire-count=1, language=None, thread-identifier=(28460, 10032), compute-name=) - Retrieving connection
[0m00:31:17.502272 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m00:31:17.502272 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m00:31:17.503273 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(28460, 10032), compute-name=) - Released connection
[0m00:31:17.506272 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:31:17.507269 [info ] [Thread-1 (]: 1 of 4 START sql incremental model bronze.sal.stg_bakehouse_sales_customer ..... [RUN]
[0m00:31:17.508270 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0s, acquire-count=0, language=None, thread-identifier=(28460, 2248), compute-name=) - Creating connection
[0m00:31:17.509285 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_italy.stg_bakehouse_sales_customer'
[0m00:31:17.510267 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Acquired connection on thread (28460, 2248), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_customer`'
[0m00:31:17.510267 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:31:17.525262 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:31:17.528259 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:31:17.581274 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.07098937034606934s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:17.582273 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.07298779487609863s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:17.583275 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0739893913269043s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:17.583275 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=None, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0739893913269043s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:17.584273 [debug] [Thread-1 (]: Spark adapter: NotImplemented: add_begin_query
[0m00:31:17.584273 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:31:17.585275 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_customer'
  
[0m00:31:17.586272 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m00:31:17.881603 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6) - Created
[0m00:31:18.237198 [debug] [Thread-1 (]: SQL status: OK in 0.650 seconds
[0m00:31:18.240184 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f2e0-1fc8-ac8e-75055a658243) - Closing
[0m00:31:18.246177 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.3635580539703369s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:18.247177 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.36455869674682617s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:18.247177 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:31:18.248176 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m00:31:18.498223 [debug] [Thread-1 (]: SQL status: OK in 0.250 seconds
[0m00:31:18.500837 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f319-101f-9e0e-4ffbd678a3eb) - Closing
[0m00:31:18.510864 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.6282453536987305s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:18.511869 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.6292498111724854s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:18.511869 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:31:18.512868 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */

  
    create or replace temporary view `stg_bakehouse_sales_customer__dbt_tmp` as
      

SELECT
      customerID,
      first_name,
      last_name,
      email_address,
      phone_number,
      address,
      city,
      state,
      country,
      continent,
      postal_zip_code,
      gender,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_customers`
  
[0m00:31:21.365289 [debug] [Thread-1 (]: SQL status: OK in 2.850 seconds
[0m00:31:21.367289 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f341-18fc-b417-8c22eb93d375) - Closing
[0m00:31:21.379289 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.4966704845428467s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:21.380289 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.4966704845428467s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:21.380289 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:31:21.380289 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_customer`
  
[0m00:31:21.618438 [debug] [Thread-1 (]: SQL status: OK in 0.240 seconds
[0m00:31:21.621439 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f4f6-1f84-a9c3-15ef3dfaac35) - Closing
[0m00:31:21.627435 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:31:21.629448 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.7468295097351074s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:21.629448 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=3.7468295097351074s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:21.630443 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_customer"
[0m00:31:21.630443 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_customer: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_customer"} */
insert overwrite table `bronze`.`sal`.`stg_bakehouse_sales_customer`
    
    select `customerID`, `first_name`, `last_name`, `email_address`, `phone_number`, `address`, `city`, `state`, `country`, `continent`, `postal_zip_code`, `gender`, `dt_ingestion_timestamp` from `stg_bakehouse_sales_customer__dbt_tmp`


[0m00:31:24.872386 [debug] [Thread-1 (]: SQL status: OK in 3.240 seconds
[0m00:31:24.874399 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f51d-171a-ab7c-2ee44bba0f12) - Closing
[0m00:31:24.893938 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Released connection
[0m00:31:24.893938 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Released connection
[0m00:31:24.895955 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0099f8c7-b33d-489d-a356-a9881533bb38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188F6A3B1C0>]}
[0m00:31:24.896954 [info ] [Thread-1 (]: 1 of 4 OK created sql incremental model bronze.sal.stg_bakehouse_sales_customer  [[32mOK[0m in 7.39s]
[0m00:31:24.898962 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_customer
[0m00:31:24.898962 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:31:24.899939 [info ] [Thread-1 (]: 2 of 4 START sql incremental model bronze.sal.stg_bakehouse_sales_franchises ... [RUN]
[0m00:31:24.900946 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_customer, idle-time=0.00700831413269043s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:24.900946 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_customer, now model.dbt_italy.stg_bakehouse_sales_franchises)
[0m00:31:24.901962 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.008023977279663086s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_customer
[0m00:31:24.901962 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.008023977279663086s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Acquired connection on thread (28460, 2248), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_franchises`'
[0m00:31:24.902968 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:31:24.905979 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:31:24.907949 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:31:24.915963 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.021044015884399414s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:24.916945 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.02300739288330078s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:24.916945 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:31:24.917960 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_franchises'
  
[0m00:31:25.253953 [debug] [Thread-1 (]: SQL status: OK in 0.330 seconds
[0m00:31:25.255932 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f713-1844-8065-86e3b92fef0d) - Closing
[0m00:31:25.259931 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.3659934997558594s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:25.260933 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.36699557304382324s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:25.260933 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:31:25.261949 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m00:31:25.482965 [debug] [Thread-1 (]: SQL status: OK in 0.220 seconds
[0m00:31:25.485978 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f747-1c88-8ae1-fcf4e1569ed6) - Closing
[0m00:31:25.486965 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.5930273532867432s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:25.487977 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.5940392017364502s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:25.487977 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:31:25.488956 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */

  
    create or replace temporary view `stg_bakehouse_sales_franchises__dbt_tmp` as
      

SELECT
      franchiseID,
      name,
      city,
      district,
      zipcode,
      country,
      size,
      longitude,
      latitude,
      supplierID,
      CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_franchises`
  
[0m00:31:26.350741 [debug] [Thread-1 (]: SQL status: OK in 0.860 seconds
[0m00:31:26.352744 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f769-1df0-94d0-a8a63a6ef55a) - Closing
[0m00:31:26.367731 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.4737930297851562s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:26.368732 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.4747943878173828s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:26.368732 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:31:26.369733 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_franchises`
  
[0m00:31:26.594996 [debug] [Thread-1 (]: SQL status: OK in 0.230 seconds
[0m00:31:26.598001 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f7f0-1bb0-9c5e-965725a8dc2d) - Closing
[0m00:31:26.602019 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.7070629596710205s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:26.602019 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=1.7080814838409424s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:26.603000 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:31:26.603000 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
describe table `stg_bakehouse_sales_franchises__dbt_tmp`
  
[0m00:31:26.937836 [debug] [Thread-1 (]: SQL status: OK in 0.330 seconds
[0m00:31:26.939845 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f814-1e9d-8f8f-c6ec5234fb9e) - Closing
[0m00:31:26.947808 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:31:26.950807 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.055882453918457s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:26.950807 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=2.0568692684173584s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:26.951813 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_franchises"
[0m00:31:26.951813 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_franchises: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_franchises"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
  

    merge
    into
        `bronze`.`sal`.`stg_bakehouse_sales_franchises` as DBT_INTERNAL_DEST
    using
        `stg_bakehouse_sales_franchises__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        FALSE
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m00:31:29.793963 [debug] [Thread-1 (]: SQL status: OK in 2.840 seconds
[0m00:31:29.794960 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f849-14d6-a0a0-d6566f23dc55) - Closing
[0m00:31:29.796957 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Released connection
[0m00:31:29.797945 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Released connection
[0m00:31:29.797945 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0099f8c7-b33d-489d-a356-a9881533bb38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188F6A3B1C0>]}
[0m00:31:29.798955 [info ] [Thread-1 (]: 2 of 4 OK created sql incremental model bronze.sal.stg_bakehouse_sales_franchises  [[32mOK[0m in 4.90s]
[0m00:31:29.799846 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:31:29.800876 [debug] [Thread-1 (]: Began running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:31:29.801381 [info ] [Thread-1 (]: 3 of 4 START sql incremental model bronze.sal.stg_bakehouse_sales_transactions . [RUN]
[0m00:31:29.803389 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_franchises, idle-time=0.004446506500244141s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:29.803389 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_franchises, now model.dbt_italy.stg_bakehouse_sales_transactions)
[0m00:31:29.804390 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.006445407867431641s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_franchises
[0m00:31:29.804390 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.006445407867431641s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Acquired connection on thread (28460, 2248), using default compute resource for model '`bronze`.`sal`.`stg_bakehouse_sales_transactions`'
[0m00:31:29.805389 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:31:29.812386 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:31:29.814381 [debug] [Thread-1 (]: Began executing node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:31:29.819382 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.02143716812133789s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:29.821379 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.023434162139892578s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:29.822379 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:31:29.824375 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'bronze' 
    AND schema_name = 'sal'
    AND table_name = 'stg_bakehouse_sales_transactions'
  
[0m00:31:30.188964 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m00:31:30.190959 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-f9ff-1f8d-883d-3ffc218840a4) - Closing
[0m00:31:30.194960 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.3960099220275879s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:30.194960 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.3970153331756592s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:30.195959 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:31:30.195959 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
SHOW TBLPROPERTIES `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m00:31:30.488794 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m00:31:30.491805 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fa38-1e5b-82e2-e8233326bb33) - Closing
[0m00:31:30.493775 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.6958305835723877s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:30.493775 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.6958305835723877s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:30.494772 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:31:30.494772 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */

  
    create or replace temporary view `stg_bakehouse_sales_transactions__dbt_tmp` as
      

SELECT
    transactionID,
    customerID,
    franchiseID,
    product,
    quantity,
    unitPrice,
    totalPrice,
    paymentMethod,
    cardNumber,
    dateTime,
    CURRENT_TIMESTAMP AS dt_ingestion_timestamp
FROM `samples`.`bakehouse`.`sales_transactions`

  WHERE dateTime > (SELECT max(dt_ingestion_timestamp) from `bronze`.`sal`.`stg_bakehouse_sales_transactions`)

  
[0m00:31:31.583697 [debug] [Thread-1 (]: SQL status: OK in 1.090 seconds
[0m00:31:31.585698 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fa66-1366-a9ef-9a2c868c4c8f) - Closing
[0m00:31:31.591700 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.793755054473877s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:31.592700 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=1.794754981994629s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:31.593702 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:31:31.593702 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `stg_bakehouse_sales_transactions__dbt_tmp`
  
[0m00:31:32.001601 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m00:31:32.004589 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fb1f-1e21-aee0-994740ded771) - Closing
[0m00:31:32.008100 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.2101552486419678s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:32.008100 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.2101552486419678s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:32.009101 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:31:32.009101 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
describe table `bronze`.`sal`.`stg_bakehouse_sales_transactions`
  
[0m00:31:32.361598 [debug] [Thread-1 (]: SQL status: OK in 0.350 seconds
[0m00:31:32.364596 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fb5e-1ef4-9fa7-127ffe11c5da) - Closing
[0m00:31:32.368575 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:31:32.370576 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.572631359100342s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:32.370576 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=2.572631359100342s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:32.371573 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.stg_bakehouse_sales_transactions"
[0m00:31:32.371573 [debug] [Thread-1 (]: On model.dbt_italy.stg_bakehouse_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.stg_bakehouse_sales_transactions"} */
insert into table `bronze`.`sal`.`stg_bakehouse_sales_transactions` (`transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp`)
select `transactionID`, `customerID`, `franchiseID`, `product`, `quantity`, `unitPrice`, `totalPrice`, `paymentMethod`, `cardNumber`, `dateTime`, `dt_ingestion_timestamp` from `stg_bakehouse_sales_transactions__dbt_tmp`

[0m00:31:35.295732 [debug] [Thread-1 (]: SQL status: OK in 2.920 seconds
[0m00:31:35.297702 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fb84-1d82-a1c0-8420d4d9f881) - Closing
[0m00:31:35.298721 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Released connection
[0m00:31:35.299715 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Released connection
[0m00:31:35.300724 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0099f8c7-b33d-489d-a356-a9881533bb38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018902BD7B50>]}
[0m00:31:35.300724 [info ] [Thread-1 (]: 3 of 4 OK created sql incremental model bronze.sal.stg_bakehouse_sales_transactions  [[32mOK[0m in 5.50s]
[0m00:31:35.302725 [debug] [Thread-1 (]: Finished running node model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:31:35.302725 [debug] [Thread-1 (]: Began running node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:31:35.303719 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.stg_bakehouse_sales_transactions, idle-time=0.004004001617431641s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:35.303719 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.stg_bakehouse_sales_transactions, now model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated)
[0m00:31:35.304720 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0050046443939208984s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Reusing connection previously named model.dbt_italy.stg_bakehouse_sales_transactions
[0m00:31:35.304720 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0050046443939208984s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Acquired connection on thread (28460, 2248), using default compute resource for model 'None'
[0m00:31:35.305719 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:31:35.309721 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated"
[0m00:31:35.311731 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Released connection
[0m00:31:35.312733 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Released connection
[0m00:31:35.312733 [debug] [Thread-1 (]: Finished running node model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:31:35.313720 [debug] [Thread-1 (]: Began running node model.dbt_italy.ent_sales_transactions
[0m00:31:35.314730 [info ] [Thread-1 (]: 4 of 4 START sql incremental model silver.sal.ent_sales_transactions ........... [RUN]
[0m00:31:35.314730 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, idle-time=0.0019965171813964844s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:35.316069 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated, now model.dbt_italy.ent_sales_transactions)
[0m00:31:35.317071 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=0.0043375492095947266s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Reusing connection previously named model.dbt_italy.eph_bakehouse_sales_franchises_deduplicated
[0m00:31:35.318069 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=0.005335807800292969s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Acquired connection on thread (28460, 2248), using default compute resource for model '`silver`.`sal`.`ent_sales_transactions`'
[0m00:31:35.319068 [debug] [Thread-1 (]: Began compiling node model.dbt_italy.ent_sales_transactions
[0m00:31:35.333062 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_italy.ent_sales_transactions"
[0m00:31:35.336059 [debug] [Thread-1 (]: Began executing node model.dbt_italy.ent_sales_transactions
[0m00:31:35.344060 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=0.0313267707824707s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:35.347054 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=0.03432059288024902s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:35.348059 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.ent_sales_transactions"
[0m00:31:35.349060 [debug] [Thread-1 (]: On model.dbt_italy.ent_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.ent_sales_transactions"} */
SELECT tag_name, tag_value
  FROM `system`.`information_schema`.`table_tags`
  WHERE catalog_name = 'silver' 
    AND schema_name = 'sal'
    AND table_name = 'ent_sales_transactions'
  
[0m00:31:35.693142 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m00:31:35.697164 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fd4b-145d-b063-3393eeac5636) - Closing
[0m00:31:35.701156 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=0.38842272758483887s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:35.702156 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=0.3894228935241699s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:35.702156 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.ent_sales_transactions"
[0m00:31:35.703155 [debug] [Thread-1 (]: On model.dbt_italy.ent_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.ent_sales_transactions"} */
SHOW TBLPROPERTIES `silver`.`sal`.`ent_sales_transactions`
  
[0m00:31:36.006471 [debug] [Thread-1 (]: SQL status: OK in 0.300 seconds
[0m00:31:36.009486 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fd81-14bb-bbac-b328f74bdd63) - Closing
[0m00:31:36.011468 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=0.698735237121582s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:36.012471 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=0.6997373104095459s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:36.013464 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.ent_sales_transactions"
[0m00:31:36.014974 [debug] [Thread-1 (]: On model.dbt_italy.ent_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.ent_sales_transactions"} */

  
    create or replace temporary view `ent_sales_transactions__dbt_tmp` as
      

with __dbt__cte__eph_bakehouse_sales_franchises_deduplicated as (


WITH stg_bakehouse_franchises
AS (
    SELECT
        franchiseID,
        name,
        city,
        district,
        zipcode,
        country,
        size,
        longitude,
        latitude,
        supplierID,
        dt_ingestion_timestamp,
        ROW_NUMBER() OVER (
            PARTITION BY franchiseID
            ORDER BY dt_ingestion_timestamp DESC
        ) AS row_number_franchiseID
    FROM `bronze`.`sal`.`stg_bakehouse_sales_franchises`
)
SELECT
    franchiseID,
    name,
    city,
    district,
    zipcode,
    country,
    size,
    longitude,
    latitude,
    supplierID,
    dt_ingestion_timestamp
FROM stg_bakehouse_franchises
WHERE row_number_franchiseID = 1
) SELECT
    transac.transactionID AS id_source_system_transaction_id,
    transac.customerID AS cd_customer_code,
    transac.franchiseID AS cd_franchise_code,
    transac.product AS gn_product_name,
    transac.quantity AS nm_quantity_of_product_sold_number,
    transac.unitPrice AS nm_price_per_unit_number,
    transac.totalPrice AS nm_total_price_number,
    transac.paymentMethod AS gn_payment_method,
    transac.cardNumber AS gn_card_number,
    franch.city AS gn_city_name,
    transac.dateTime AS dt_source_system_ingestion_timestamp
FROM `bronze`.`sal`.`stg_bakehouse_sales_transactions` transac
LEFT JOIN __dbt__cte__eph_bakehouse_sales_franchises_deduplicated franch
ON transac.franchiseID = franch.franchiseID
  
[0m00:31:36.339197 [debug] [Thread-1 (]: SQL status: OK in 0.320 seconds
[0m00:31:36.341196 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fdb1-1637-b06b-cc52a3c4c454) - Closing
[0m00:31:36.344194 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=1.0314607620239258s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:36.345199 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=1.0324656963348389s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:36.346198 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.ent_sales_transactions"
[0m00:31:36.346198 [debug] [Thread-1 (]: On model.dbt_italy.ent_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.ent_sales_transactions"} */
describe table `silver`.`sal`.`ent_sales_transactions`
  
[0m00:31:36.759594 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m00:31:36.762593 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fde3-1cf2-8a82-6704307fe57b) - Closing
[0m00:31:36.766604 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=1.4538702964782715s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:36.767595 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=1.4538702964782715s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:36.767595 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.ent_sales_transactions"
[0m00:31:36.768572 [debug] [Thread-1 (]: On model.dbt_italy.ent_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.ent_sales_transactions"} */
describe table `ent_sales_transactions__dbt_tmp`
  
[0m00:31:37.092866 [debug] [Thread-1 (]: SQL status: OK in 0.320 seconds
[0m00:31:37.095853 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fe23-1ac8-9794-a8a89c374df0) - Closing
[0m00:31:37.097847 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_italy.ent_sales_transactions"
[0m00:31:37.099848 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=1.7871150970458984s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Checking idleness
[0m00:31:37.100849 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=1.7881159782409668s, acquire-count=1, language=sql, thread-identifier=(28460, 2248), compute-name=) - Retrieving connection
[0m00:31:37.100849 [debug] [Thread-1 (]: Using databricks connection "model.dbt_italy.ent_sales_transactions"
[0m00:31:37.101847 [debug] [Thread-1 (]: On model.dbt_italy.ent_sales_transactions: /* {"app": "dbt", "dbt_version": "1.9.2", "dbt_databricks_version": "1.9.5", "databricks_sql_connector_version": "3.7.2", "profile_name": "dbt_italy", "target_name": "dev", "node_id": "model.dbt_italy.ent_sales_transactions"} */
-- back compat for old kwarg name
  
  
  
  
  
  
      
          
          
      
  

    merge
    into
        `silver`.`sal`.`ent_sales_transactions` as DBT_INTERNAL_DEST
    using
        `ent_sales_transactions__dbt_tmp` as DBT_INTERNAL_SOURCE
    on
        
              DBT_INTERNAL_SOURCE.id_source_system_transaction_id <=> DBT_INTERNAL_DEST.id_source_system_transaction_id
          
    when matched
        then update set
            *
    when not matched
        then insert
            *

[0m00:31:42.717382 [debug] [Thread-1 (]: SQL status: OK in 5.620 seconds
[0m00:31:42.720379 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, command-id=01eff0ab-fe56-1d61-98c0-b469febe0017) - Closing
[0m00:31:42.847544 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Released connection
[0m00:31:42.848545 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=1687944393008, session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6, name=model.dbt_italy.ent_sales_transactions, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(28460, 2248), compute-name=) - Released connection
[0m00:31:42.849543 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0099f8c7-b33d-489d-a356-a9881533bb38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000189027AFEE0>]}
[0m00:31:42.850542 [info ] [Thread-1 (]: 4 of 4 OK created sql incremental model silver.sal.ent_sales_transactions ...... [[32mOK[0m in 7.53s]
[0m00:31:42.852545 [debug] [Thread-1 (]: Finished running node model.dbt_italy.ent_sales_transactions
[0m00:31:42.853539 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=25.350265741348267s, acquire-count=0, language=None, thread-identifier=(28460, 10032), compute-name=) - Checking idleness
[0m00:31:42.854546 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=25.351272344589233s, acquire-count=0, language=None, thread-identifier=(28460, 10032), compute-name=) - Reusing connection previously named master
[0m00:31:42.854546 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=25.351272344589233s, acquire-count=1, language=None, thread-identifier=(28460, 10032), compute-name=) - Acquired connection on thread (28460, 10032), using default compute resource
[0m00:31:42.855542 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=25.35226845741272s, acquire-count=1, language=None, thread-identifier=(28460, 10032), compute-name=) - Checking idleness
[0m00:31:42.855542 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=None, name=master, idle-time=25.35226845741272s, acquire-count=1, language=None, thread-identifier=(28460, 10032), compute-name=) - Retrieving connection
[0m00:31:42.856543 [debug] [MainThread]: On master: ROLLBACK
[0m00:31:42.856543 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:31:43.154592 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0ac-01e4-17a3-9995-a57359a5ec78) - Created
[0m00:31:43.155591 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:31:43.156591 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=01eff0ac-01e4-17a3-9995-a57359a5ec78, name=master, idle-time=0.0010004043579101562s, acquire-count=1, language=None, thread-identifier=(28460, 10032), compute-name=) - Checking idleness
[0m00:31:43.156591 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=01eff0ac-01e4-17a3-9995-a57359a5ec78, name=master, idle-time=0.0010004043579101562s, acquire-count=1, language=None, thread-identifier=(28460, 10032), compute-name=) - Retrieving connection
[0m00:31:43.157593 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m00:31:43.157593 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m00:31:43.158588 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=1687963449616, session-id=01eff0ac-01e4-17a3-9995-a57359a5ec78, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(28460, 10032), compute-name=) - Released connection
[0m00:31:43.158588 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:31:43.159588 [debug] [MainThread]: On master: ROLLBACK
[0m00:31:43.159588 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:31:43.160587 [debug] [MainThread]: On master: Close
[0m00:31:43.160587 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0ac-01e4-17a3-9995-a57359a5ec78) - Closing
[0m00:31:43.314316 [debug] [MainThread]: Connection 'list_silver' was properly closed.
[0m00:31:43.316271 [debug] [MainThread]: On list_silver: Close
[0m00:31:43.316271 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0ab-f105-11a0-8407-2318f780cfd1) - Closing
[0m00:31:43.442581 [debug] [MainThread]: Connection 'list_bronze_sal' was properly closed.
[0m00:31:43.443580 [debug] [MainThread]: On list_bronze_sal: ROLLBACK
[0m00:31:43.444571 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:31:43.444571 [debug] [MainThread]: On list_bronze_sal: Close
[0m00:31:43.445576 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0ab-f20e-17eb-8983-67f319eb22c4) - Closing
[0m00:31:43.598071 [debug] [MainThread]: Connection 'model.dbt_italy.ent_sales_transactions' was properly closed.
[0m00:31:43.599070 [debug] [MainThread]: On model.dbt_italy.ent_sales_transactions: ROLLBACK
[0m00:31:43.600064 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m00:31:43.600064 [debug] [MainThread]: On model.dbt_italy.ent_sales_transactions: Close
[0m00:31:43.601064 [debug] [MainThread]: Databricks adapter: Connection(session-id=01eff0ab-f2d4-11ce-8d69-b40293339ca6) - Closing
[0m00:31:43.742181 [info ] [MainThread]: 
[0m00:31:43.743175 [info ] [MainThread]: Finished running 4 incremental models in 0 hours 0 minutes and 29.62 seconds (29.62s).
[0m00:31:43.745174 [debug] [MainThread]: Command end result
[0m00:31:43.785766 [debug] [MainThread]: Wrote artifact WritableManifest to dbt_italy\target\manifest.json
[0m00:31:43.793766 [debug] [MainThread]: Wrote artifact SemanticManifest to dbt_italy\target\semantic_manifest.json
[0m00:31:43.801760 [debug] [MainThread]: Wrote artifact RunExecutionResult to dbt_italy\target\run_results.json
[0m00:31:43.802760 [info ] [MainThread]: 
[0m00:31:43.803759 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:31:43.804758 [info ] [MainThread]: 
[0m00:31:43.805756 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m00:31:43.807764 [debug] [MainThread]: Command `dbt run` succeeded at 00:31:43.807764 after 32.42 seconds
[0m00:31:43.809754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188F7F4E1A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188F84916F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018902E16470>]}
[0m00:31:43.811759 [debug] [MainThread]: Flushing usage events
[0m00:31:44.926501 [debug] [MainThread]: An error was encountered while trying to flush usage events
